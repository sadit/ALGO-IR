[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "",
    "text": "Prefacio\nEl An√°lisis de algoritmos es una disciplina formativa enfocada en el desempe√±o de los algoritmos bajo una cierta entrada. Su estudio nos permite identificar el problema algor√≠tmico subyacente dentro de problemas reales, y por tanto, ser capaces de seleccionar, adaptar o construir una soluci√≥n eficiente y eficaz para dicho problema. Una soluci√≥n adecuada sobre una ingenua nos permite mejorar de manera significativa los recursos computacionales, que pueden llevar a reducci√≥n de costos de operaci√≥n en un sistema o la posibilidad de procesar grandes cantidades de informaci√≥n de manera m√°s eficiente.\nEl dise√±o, implementaci√≥n y an√°lisis de algoritmos es fundamental para formar el criterio del cient√≠fico de datos. Los conocimientos adquiridos servir√°n para obtener las herramientas y la intuici√≥n necesaria para plantear la soluci√≥n a un problema basado en un modelo de c√≥mputo y resolverlo de manera eficiente y escalable cuando sea posible.\nA lo largo de los temas se abordar√°n los algoritmos y estructuras de manera te√≥rica y pr√°ctica, y se motivar√° al estudiante a realizar sus propias implementaciones. Al terminar este curso, se pretende que el alumno sea competente para seleccionar, dise√±ar, implementar y analizar algoritmos sobre secuencias, conjuntos y estructuras de datos para resolver problemas optimizando los recursos disponibles, en particular, memoria y tiempo de c√≥mputo. Durante el curso se estudiaran problemas y algoritmos simples, que suelen formar parte de algoritmos m√°s complejos, y por lo tanto, si somos capaces de seleccionar adecuadamente estos bloques m√°s simples, afectaremos directamente el desempe√±o de los sistemas.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#contenido-del-libro",
    "href": "index.html#contenido-del-libro",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "Contenido del libro",
    "text": "Contenido del libro\nEste libro esta dise√±ado para ser impartido en un semestre de licenciatura o maestr√≠a con un enfoque experimental, de Ingenier√≠a en Computaci√≥n o Ciencias de la Computaci√≥n, as√≠ como Ciencia de Datos. Los algoritmos que se van develando desentra√±an los algoritmos cl√°sicos de Recuperaci√≥n de Informaci√≥n, algoritmos detr√°s de grandes m√°quinas de b√∫squeda, sistemas de informaci√≥n basados en similitud, retrieval augmented generation (RAG), as√≠ como de los m√©todos detr√°s de la aceleraci√≥n de otras t√©cnicas de an√°lisis de datos como agrupamiento y reducci√≥n de dimensi√≥n no-lineal.\n\nEl Cap.¬†1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos se dedica a revisar el lenguaje de programaci√≥n Julia, desde un punto de vista de alguien que podr√≠a no conocer el lenguaje, pero que definitivamente sabe programar y esta familiarizado con los conceptos generales de un lenguaje de programaci√≥n moderno.\nEl Cap.¬†2¬† Introducci√≥n al an√°lisis de algoritmos con Julia introduce los conceptos de an√°lisis asint√≥tico y compara ordenes de crecimiento con la idea de formar intuici√≥n.\nEn el Cap.¬†3¬† Estructuras de datos elementales nos encontramos con las estructuras de datos elementales como son las estructuras de datos lineales y de acceso aleatorio, y su organizaci√≥n en memoria.\nEl Cap.¬†4¬† Algoritmos de ordenamiento esta dedicado a algoritmos de ordenamiento en el modelo de comparaci√≥n, estudia algoritmos tanto de peor caso como aquellos que toman ventaja de la distribuci√≥n de entrada.\nEn el Cap.¬†5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n abordamos algoritmos de b√∫squeda en arreglos ordenados en el modelo de comparaci√≥n. De nueva cuenta se abordan algoritmos de peor caso y algoritmos que pueden sacar ventaja de instancias f√°ciles.\nFinalmente, el Cap.¬†6¬† Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas estudia algoritmos de intersecci√≥n de conjuntos, los cuales son la base de sistemas de informaci√≥n capaces de manipular cantidades enormes de datos.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#trabajo-en-progreso",
    "href": "index.html#trabajo-en-progreso",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "Trabajo en progreso",
    "text": "Trabajo en progreso\nEste libro es un trabajo en progreso, que se pretende t√©rminar durante el primer semestre de 2025, mientras se imparte el curso An√°lisis de algoritmos en la Maestr√≠a en Ciencia de Datos e Informaci√≥n de INFOTEC, M√©xico. El perfil de ingreso de la maestr√≠a es multidisciplinario, y esto es parte esencial del dise√±o de este libro.\nEn particular, los cap√≠tulos 1, 2, y 3 tienen un avance significativo, aunque no estan terminados. El resto de los cap√≠tulos ese encuentran en un estado incipiente.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "Licencia",
    "text": "Licencia\n\nEsta obra est√° bajo una Licencia Creative Commons Atribuci√≥n-CompartirIgual 4.0 Internacional",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "cap1-julia.html",
    "href": "cap1-julia.html",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "",
    "text": "1.1 El lenguaje de programaci√≥n Julia\nNuestro objetivo trabajar sobre algoritmos, por lo que cualquier lenguaje que pueda expresar todo lo computable, puede ser adecuado. Pero dado que nuestro enfoque ser√° experimental, y nuestra metodolog√≠a incluye medir la factibilidad y desempe√±o de cada algoritmo en t√©rminos reales, entonces necesitamos un lenguaje donde las instrucciones, los acceso a memoria, y la manipulaci√≥n de la misma sea controlable. En este caso, y mediando con la f√°cilidad de aprendizaje y la productividad, este curso utiliza el lenguaje de programaci√≥n Julia.1 Pero no hay porque preocuparse por aprender un nuevo lenguaje, el curso utiliza ejemplos en Julia y utiliza una variante de su sintaxis como pseudo-c√≥digo, pero las actividades se esperan tanto en Julia como en Python.\nAmbos lenguajes de programaci√≥n son f√°ciles de aprender y altamente productivos. Python es un lenguaje excelente para realizar prototipos, o para cuando existen bibliotecas que resuelvan el problema que se este enfrentando. Por otro lado, cuando se necesita control sobre las operaciones que se estan ejecutando, o la memoria que se aloja, Python no es un lenguaje que nos permita trabajar en ese sentido. Julia esta dise√±ado para ser veloz y a la vez mantener el din√°mismo que se espera de un lenguaje moderno, adicionalmente, es posible conocer los tipos de instrucciones que realmente se ejecutan, as√≠ como tambi√©n es posible controlar la alojaci√≥n de memoria, ya se mediante la utilizaci√≥n de patrones que as√≠ nos lo permitan, o mediante instrucciones que nos lo aseguren.\nEste curso esta escrito en Quarto, y se esperan reportes de de tareas y actividades tanto en Quarto https://quarto.org como en Jupyter https://jupyter.org/. La mayor√≠a de los ejemplos estar√°n empotrados en el sitio, y en principio, deber√≠an poder replicarse copiando, pegando, y ejecutando en una terminal de Julia.\nEs importante clarificar que este cap√≠tulo introducir√° el lenguaje de programaci√≥n Julia hasta el nivel que se requiere en este curso, ignorando una gran cantidad de capacidades que no son de inter√©s para nuestro curso. Se recomienda al alumno interesado la revisi√≥n del manual y la documentaci√≥n oficial para un estudio m√°s profundo del lenguaje.\nJulia es un lenguaje singular, es un lenguaje din√°mico y de alto nivel, tiene de tipado fuerte y compila a c√≥digo m√°quina para cada una de las instrucciones que se dan. Su interfaz m√°s com√∫n es un REPL o , esto es que puede ser utilizado de manera interactiva, adem√°s de la ejecuci√≥n en scripts o notebooks como los que estaremos usando para reportar.\nEs homoic√≥nico, que significa que la manera en que se representan sus programas coincide con las estructuras de datos b√°sicas, lo cual permite crear programas validos mediante programas. De manera pr√°ctica, tambi√©n le permite la reescritura de los programas utilizando otro programa utilizando macros, los cuales son funciones que modifican el c√≥digo y empiezan con el simbolo @. Estaremos viendo una serie de macros con prop√≥sitos muy espec√≠ficos, crear macros y la manipulaci√≥n autom√°tica de c√≥digo cae fuera de nuestro curso.\nEl lenguaje tiene estructuras de datos b√°sicas como rangos, vistas, tuplas, arreglos, estructuras, diccionarios, conjuntos, cadenas de caracteres, as√≠ como expresiones de c√≥digo como datos y controla la ejecuci√≥n mediante condicionales, ciclos y funciones. Tiene un sistema de tipos de datos muy poderoso, que le permite entre otras cosas generar c√≥digo espec√≠fico para dichos tipos. El c√≥digo se organiza en scripts, y a nivel l√≥gico en m√≥dulos y paquetes. Una de sus caracter√≠sticas importantes el despacho m√∫ltiple en las funciones, esto es, que para cada conjunto de tipos de argumentos, compilar√° una funci√≥n especializada. Este patr√≥n puede ser muy poderoso para escribir c√≥digo gen√©rico que pueda ser muy eficiente, a costa de m√∫ltiples c√≥digos de m√°quina para una funci√≥n. Esta estrateg√≠a tambi√©n viene con el problema que la primera vez que se ejecuta una funci√≥n con un conjunto espec√≠fico de tipos de argumentos, dicha funci√≥n ser√° especializada y compilada, lo cual puede representar un costo inicial importante en algunos casos donde no se pretenda procesar grandes cantidades de informaci√≥n. En particular, este problema se ha venido reduciendo en las versiones m√°s nuevas de Julia haciendo uso una estrateg√≠a de precompilaci√≥n para datos t√≠picos.\nEntre los tipos de datos es capaz de manera enteros y n√∫meros de punto flotante de diferentes precisiones, caracteres, cadenas de caracteres, y simbolos. Los arreglos son realmente importantes en Julia, y soportan de manera nativa vectores, matrices y tensores, estaremos tocando apenas esta parte del lenguaje. El resto de esta unidad esta dedicada a precisar la sintaxis del lenguaje y anotaciones de importancia sobre su funcionamiento, y en particular, en el manejo que nos permitir√° generar c√≥digo eficiente que limite el alojamiento de memoria.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#el-lenguaje-de-programaci√≥n-julia",
    "href": "cap1-julia.html#el-lenguaje-de-programaci√≥n-julia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "",
    "text": "1.1.1 Funciones\nLas funciones son centrales en Julia, y son definidas mediante la sintaxis\n```{julia}\n1function fun(arg1, arg2...)\n    # ... expresiones ...\nend\n\n2function fun(arg1, arg2...; kwarg1=valor1, kwargs2...)\n    # ... expresiones ...\nend\n\n3fun(arg1, arg2...; kwarg1=valor1, kwargs2...) = expresion\n\n4(arg1, arg2...; kwarg1=valor1, kwargs2...) -&gt; expresion\n\n5fun() do x\n    x^2 # ... expresiones ...\nend\n```\n\n1\n\nDefinici√≥n de una funci√≥n simple, los tipos de los argumentos se utilizan para generar m√∫ltiples versiones de una funci√≥n.\n\n2\n\nTambi√©n se soportan argumentos nombrados, los cuales van despu√©s de ;, se debe tener en cuenta que los tipos de los argumentos nombrados no son utilizados para determinar si una funci√≥n debe compilarse. Los argumentos nombrados pueden o no tener valores por omisi√≥n.\n\n3\n\nSi la funci√≥n tiene una estructura simple, de una expresi√≥n, es posible ignorar function y end, usando ‚Äò=‚Äô para definirla.\n\n4\n\nMuchas veces es √∫til definir funciones an√≥nimas, que suelen pasarse a otras funciones de orden superior.\n\n5\n\nUn embellecedor √∫til para generar una funci√≥n an√≥nima (definida entre do...end) que se pasa como primer argumento a fun, e.g., es equivalente a fun(x-&gt;x^2).\n\n\nEl √°mbito o scope de las variables en Julia es sint√°ctico, que significa que se hereda del c√≥digo donde las funciones fueron definidas, y no din√°mico (que se hereda desde d√≥nde se ejecuta la funci√≥n). Aunque es el comportamiento de la mayor√≠a de los lenguajes modernos, es importante conocerlo sobre todo para la creaci√≥n de cerraduras sint√°cticas en funciones.\nUna funci√≥n se ejecuta con la sintaxis nombre(arg1...). Conviene profundizar en las expresiones y dem√°s componentes del lenguaje antes del ir a m√°s ejemplos sobre funciones.\n\n\n1.1.2 Hola mundo\nUno de los programas m√°s comunes es el siguiente\n\nprintln(\"¬°Hola üåé!\")\n\n¬°Hola üåé!\n\n\n\n\n1.1.3 Expresiones y operadores\nLas expresiones son la forma m√°s gen√©rica de expresar el c√≥digo en Julia, comprenden operaciones aritm√©ticas, asignaci√≥n y declaraci√≥n de variables, definiciones de bloques de c√≥digo, llamadas de funciones, entre otras.\nCada linea suele ser una expresi√≥n, a menos que se extienda por m√∫ltiples lineas por medio de un agrupador de c√≥digo o datos, estos pueden ser begin...end, let...end, (...), [...], [...], for...end, while...end, if...end, function...end, try...end, entre las m√°s utilizadas.\nLas definiciones de variables tienen la sintaxis variable = valor; las variables comunmente comienzan con una letra o _, las letras pueden ser caracteres unicode, no deben contener espacios ni puntuaciones como parte del nombre; valor es el resultado de evaluar o ejecutar una expresi√≥n.\nLos operadores m√°s comunes son los aritm√©ticos +, -, *, /, √∑, %, \\, ^, con precedencia y significado t√≠pico. Existen maneras compuestas de modificar una variable anteponiendo el operador aritm√©tico al simbolo de asignaci√≥n, e.g., variable += valor, que se expande a variable = variable + valor. Esto implica que variable debe estar previamente definida previo a la ejecuci√≥n.\nLos operadores l√≥gicos tambi√©n tienen el significado esperado.\n\n\n\noperaci√≥n\ndescripci√≥n\n\n\n\n\na && b\nAND l√≥gico\n\n\na || b\nOR l√≥gico\n\n\na ‚äª b\nXOR l√≥gico\n\n\n!a\nnegaci√≥n l√≥gica\n\n\na &lt; b\ncomparaci√≥n a es menor que b\n\n\na &gt; b\ncomparaci√≥n a es mayor que b\n\n\na &lt;= b\ncomparaci√≥n a es menor o igual que b\n\n\na &gt;= b\ncomparaci√≥n a es mayor o igual que b\n\n\na == b\ncomparaci√≥n de igualdad\n\n\na === b\ncomparaci√≥n de igualdad (a nivel de tipo)\n\n\na != b\ncomparaci√≥n de desigualdad\n\n\na !== b\ncomparaci√≥n de desigualdad (a nivel de tipo)\n\n\n\nEn particular && y || implementan corto circuito de c√≥digo, por lo que pueden usarse para el control de que operaciones se ejecutan. Cuando se compara a nivel de tipo 0 (entero) ser√° diferente de 0.0 (real).\nTambi√©n hay operadores l√≥gicos a nivel de bit, los argumentos son enteros.\n\n\n\noperaci√≥n\ndescripci√≥n\n\n\n\n\na & b\nAND a nivel de bits\n\n\na | b\nOR a nivel de bits\n\n\na ‚äª b\nXOR a nivel del bits\n\n\n~a\nnegaci√≥n l√≥gica a nivel de bits\n\n\n\n\n\n1.1.4 Literales\nDado que existen m√∫ltiples tipos de datos existen diferentes formas de definirlas; una de ellas, probablemente la que m√°s estaremos usando son los literales, es decir, escribir los datos directamente en el c√≥digo.\nLos n√∫meros enteros se definen sin punto decimal, es posible usar _ como separador y dar m√°s claridad al c√≥digo. Los enteros pueden tener 8, 16, 32, o 64 bits; por omisi√≥n, se empaquetan en variables del tipo Int (Int64). Los valores hexadecimales se interpretan como enteros sin signo, y adem√°s se empaquetan al n√∫mero de bits necesario minimo para contener. El comportamiento para valores en base 10 es el de hexadecimal es congruente con un lenguaje para programaci√≥n de sistemas.\n\na = 100\nprintln((a, sizeof(a)))\nb = Int8(100)\nprintln((b, sizeof(b)))\nc = 30_000_000\nprintln((c, sizeof(c)))\nd = 0xffff\nprintln((d, sizeof(d)))\n\n(100, 8)\n(100, 1)\n(30000000, 8)\n(0xffff, 2)\n\n\n\n\nExisten n√∫meros enteros de precisi√≥n 128 pero las operaciones al d√≠a de hoy no son implementadas de manera nativa por los procesadores; as√≠ mismo se reconocen n√∫meros de punto flotante de precisi√≥n media Float16 pero la mayor√≠a de los procesadores no tienen soporte nativo para realizar operaciones con ellos, aunque los procesadores de √∫ltima generaci√≥n si lo tienen.\nSi la precisi√≥n esta en duda o el contexto lo am√©rita, deber√° especificarlo usando el constructor del tipo e.g., Int8(100), UInt8(100), Int16(100), UInt16(100), Int32(100), UInt32(100), Int64(100), UInt64(100).\nLos n√∫meros de punto flotante tienen diferentes formas de definirse, teniendo diferentes efectos. Para n√∫meros de precision simple, 32 bits, se definen con el sufijo f0 como 3f0. El sufijo e0 tambi√©n se puede usar para definir precisi√≥n doble (64 bit). El cero del sufijo en realidad tiene el objetivo de colocar el punto decimal, en notaci√≥n de ingenier√≠a, e.g., \\(0.003\\) se define como \\(3f-3\\) o \\(3e-3\\), dependiendo del tipo de dato que se necesite. Si se omite sufijo y se pone solo punto decimal entonces se interpretar√° como precision doble. Los tipos son Float32 y Float64.\nLos datos booleanos se indican mediante true y false para verdadero y falso, respectivamente.\nLos caracteres son s√≠mbolos para √≠ndicar cadenas, se suelen representar como enteros peque√±os en memoria. Se especifican con comillas simples 'a', 'z', '!' y soporta simbolos unicode 'ü§†'.\nLas cadenas de caracteres son la manera de representar textos como datos, se guardan en zonas contiguas de memoria. Se especifican con comillas dobles y tambi√©n soportan s√≠mbolos unicode, e.g., \"hola mundo\", \"pato es un üê∑\".\n\n\nJulia guarda los simbolos de manera especial y pueden ser utilizados para realizar identificaci√≥n de datos eficiente, sin embargo, no es buena idea saturar el sistema de manejo de s√≠mbolos por ejemplo para crear un vocabulario ya que no liberar√° la memoria despu√©s de definirlos ya que es un mec√°nismo dise√±ado para la representaci√≥n de los programas, pero lo suficientemente robusto y bien definido para usarse en el dise√±o e implementaci√≥n de programas de los usuarios.\nEn Julia existe la noci√≥n de s√≠mbolo, que es una cadena que adem√°s solo existe en una posici√≥n en memoria se usa el prefijo : para denotarlos.\n\nprintln(:hola === :hola)\nprintln(typeof(:hola))\nprintln(Symbol(\"hola mundo\"))\n\ntrue\nSymbol\nhola mundo\n\n\n\n\n1.1.5 Control de flujo\nEl control de flujo nos permite escoger que partes del c√≥digo se ejecutaran como consecuencia de la evaluaci√≥n de una expresi√≥n, esto incluye repeticiones.\nLas condicionales son el control de flujo m√°s simple.\n\na = 10\n1if a % 2 == 0\n2    \"par\"\nelse\n3    \"impar\"\nend\n\n\n1\n\nExpresi√≥n condicional.\n\n2\n\nExpresi√≥n a ejecutarse si (1) es verdadero.\n\n3\n\nExpresi√≥n a evaluarse si (1) es falso.\n\n\n\n\n\"par\"\n\n\nSe puede ignorar la clausula else dando solo la opci√≥n de evaluar (2) si (1) es verdadero. Finalmente, note que la condicional es una expresi√≥n y devuelve un valor.\n\na = 10\nif log10(a) == 1\n    \"es 10\"\nend\n\n\"es 10\"\n\n\nTambi√©n pueden concatenarse m√∫ltiples expresiones condicionales con elseif como se muestra a continuaci√≥n.\n\na = 9\nif a % 2 == 0\n    println(\"divisible entre 2\")\nelseif a % 3 == 0\n    println(\"divisible entre 3\")\nelse\n    println(\"no divisible entre 2 y 3\")\nend\n\ndivisible entre 3\n\n\nEs com√∫n utilizar la sintaxis en Julia (short circuit) para control de flujo:\n\na = 9\n\n1println(a % 2 == 0 && \"es divisible entre dos\")\n2println(a % 3 == 0 && \"es divisible entre tres\")\n\n\n1\n\nEl resultado de la condici√≥n es falso, por lo que no se ejecutar√° la siguiente expresi√≥n.\n\n2\n\nEl resultado es verdadero, por lo que se ejecutar√° la segunda expresi√≥n.\n\n\n\n\nfalse\nes divisible entre tres\n\n\nFnalmente, existe una condicional de tres vias expresion ? expr-verdadero : expr-falso\n\na = 9\n\nprintln(a % 2 == 0 ? \"es divisible entre dos\" : \"no es divisible entre dos\")\nprintln(a % 3 == 0 ? \"es divisible entre tres\" : \"no es divisible entre tres\")\n\nno es divisible entre dos\nes divisible entre tres\n\n\n\n1.1.5.1 Ciclos\nLos ciclos son expresiones de control de flujo que nos permiten iterar sobre una colecci√≥n o repetir un c√≥digo hasta que se cumpla alguna condici√≥n. En Julia existen dos expresiones de ciclos:\n\nfor x in colecci√≥n ...expresiones... end y\nwhile condici√≥n ...expresioens... end\n\nEn el caso de for, la idea es iterar sobre una colecci√≥n, esta colecci√≥n puede ser un rango, i.e., inicio:fin, inicio:paso:fin, o una colecci√≥n como las tuplas, los arreglos, o cualquiera que cumpla con la interfaz de colecci√≥n iterable del lenguaje.\n\nfor i in 1:5\n    println(\"1er ciclo: \", i =&gt; i^2)\nend\n\nfor i in [10, 20, 30, 40, 50]\n    println(\"2do ciclo: \", i =&gt; i/10)\nend\n\n1er ciclo: 1 =&gt; 1\n1er ciclo: 2 =&gt; 4\n1er ciclo: 3 =&gt; 9\n1er ciclo: 4 =&gt; 16\n1er ciclo: 5 =&gt; 25\n2do ciclo: 10 =&gt; 1.0\n2do ciclo: 20 =&gt; 2.0\n2do ciclo: 30 =&gt; 3.0\n2do ciclo: 40 =&gt; 4.0\n2do ciclo: 50 =&gt; 5.0\n\n\nAl igual que en otros lenguajes modernos, se define la variante completa o comprehensive for que se utiliza para transformar la colecci√≥n de entrada en otra colecci√≥n cuya sintaxis se ejemplifica a continuaci√≥n:\n\na = [i =&gt; i^2 for i in 1:5]\nprintln(a)\n\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nTambi√©n es posible definir un generador, esto es, un c√≥digo que puede generar los datos, pero que no los generar√° hasta que se les solicite.\n\na = (i =&gt; i^2 for i in 1:5)\nprintln(a)\nprintln(collect(a))\n\nBase.Generator{UnitRange{Int64}, var\"#3#4\"}(var\"#3#4\"(), 1:5)\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nOtra forma de hacer ciclos de intrucciones es repetir mientras se cumpla una condici√≥n:\n\ni = 0\nwhile i &lt; 5\n    i += 1\n    println(i)\nend\n\ni\n\n1\n2\n3\n4\n5\n\n\n5\n\n\n\n\n\n1.1.6 Tuplas y arreglos en Julia\nUna tupla es un conjunto ordenado de datos que no se puede modificar y que se desea esten contiguos en memoria, la sintaxis en memoria es como sigue:\n\n1a = (2, 3, 5, 7)\nb = (10, 20.0, 30f0)\nc = 100 =&gt; 200\n2println(typeof(a))\nprintln(typeof(b))\nprintln(typeof(c))\n3a[1], a[end], b[3], c.first, c.second\n\n\n1\n\nDefine las tuplas.\n\n2\n\nImprime los tipos de las tuplas.\n\n3\n\nMuestra como se accede a los elementos de las tuplas. Julia indexa comenzando desde 1, y el t√©rmino end tambi√©n se utiliza para indicar el √∫ltimo elemento en una colecci√≥n ordenada.\n\n\n\n\nNTuple{4, Int64}\nTuple{Int64, Float64, Float32}\nPair{Int64, Int64}\n\n\n(2, 7, 30.0f0, 100, 200)\n\n\nLa misma sintaxis puede generar diferentes tipos de tuplas. En el caso NTuple{4, Int4} nos indica que el tipo maneja cuatro elementos de enteros de 64 bits, los argumentos entre {} son parametros que especifican los tipos en cuesti√≥n. En el caso de Tuple se pueden tener diferentes tipos de elementos. La tupla Pair es especial ya que solo puede contener dos elementos y es b√°sicamente para embellecer o simplificar las expresiones; incluso se crea con la sintaxis key =&gt; value y sus elementos pueden accederse mediante dos campos nombrados.\nLos arreglos son datos del mismo tipo contiguos en memoria, a diferencia de las tuplas, los elementos se pueden modificar, incluso pueden crecer o reducirse. Esto puede implicar que se alojan en zonas de memoria diferente (las tuplas se colocan en el stack y los arreglos en el heap, ver la siguiente unidad para m√°s informaci√≥n). Desde un alto nivel, los arreglos en Julia suelen estar asociados con vectores, matrices y tensores, y un arsenal de funciones relacionadas se encuentran definidas en el paquete LinearAlgebra, lo cual esta m√°s all√° del alcance de este curso.\n\n1a = [2, 3, 5, 7]\nb = [10, 20.0, 30f0]\n2println(typeof(a))\nprintln(typeof(b))\n3a[1], a[end], b[3], b[2:3]\n\n\n1\n\nDefine los arreglos a y b.\n\n2\n\nMuestra los tipos de los arreglos, note como los tipos se promueven al tipo m√°s g√©nerico que contiene la definici√≥n de los datos.\n\n3\n\nEl acceso es muy similar a las tuplas para arreglos unidimensionales, note que es posible acceder rangos de elementos con la sintaxis ini:fin.\n\n\n\n\nVector{Int64}\nVector{Float64}\n\n\n(2, 7, 30.0, [20.0, 30.0])\n\n\n\na = [2 3;\n1     5 7]\n2display(a)\n3display(a[:, 1])\n4display(a[1, :])\n\n\n1\n\nDefinici√≥n de un arreglo bidimensional, note como se ignora la coma , en favor de la escritura por filas separadas por ;.\n\n2\n\nLa variable a es una matriz de 2x2.\n\n3\n\nEs posible acceder una columna completa usando el s√≠mbolo : para indicar todos los elementos.\n\n4\n\nDe igual forma, es posible acceder una fila completa.\n\n\n\n\n2√ó2 Matrix{Int64}:\n 2  3\n 5  7\n\n\n2-element Vector{Int64}:\n 2\n 5\n\n\n2-element Vector{Int64}:\n 2\n 3\n\n\n\n\n1.1.7 Diccionarios y conjuntos en Julia\nUn diccionario es un arreglo asociativo, i.e., guarda pares llave-valor. Permite acceder de manera eficiciente al valor por medio de la llave, as√≠ como tambi√©n verificar si hay una entrada dentro del diccionario con una llave dada. La sintaxis es como sigue:\n\n1a = Dict(:a =&gt; 1, :b =&gt; 2, :c =&gt; 3)\n2a[:b] = 20\nprintln(a)\n3a[:d] = 4\nprintln(a)\n4delete!(a, :a)\na\n\n\n1\n\nDefinici√≥n del diccionario a que mapea simbolos a enteros.\n\n2\n\nCambia el valor de :b por 20.\n\n3\n\nA√±ade :d =&gt; 4 al diccionario a.\n\n4\n\nBorra el par con llave :a.\n\n\n\n\nDict(:a =&gt; 1, :b =&gt; 20, :c =&gt; 3)\nDict(:a =&gt; 1, :b =&gt; 20, :d =&gt; 4, :c =&gt; 3)\n\n\nDict{Symbol, Int64} with 3 entries:\n  :b =&gt; 20\n  :d =&gt; 4\n  :c =&gt; 3\n\n\nEs posible utilizar diferentes tipos siempre y cuando el tipo en cuesti√≥n defina de manera correcta la funci√≥n hash sobre la llave y la verificaci√≥n de igualdad ==.\nUn conjunto se representa con el tipo Set, se implementa de manera muy similar al diccionario pero solo necesita el elemento (e.g., la llave). Como conjunto implementa las operaciones clasificaci√≥n de operaciones de conjuntos\n\n1a = Set([10, 20, 30, 40])\n2println(20 in a)\n3push!(a, 50)\nprintln(a)\n4delete!(a, 10)\nprintln(a)\n5println(intersect(a, [20, 35]))\n6union!(a, [100, 200])\nprintln(a)\n\n\n1\n\nDefinici√≥n del conjunto de n√∫meros enteros.\n\n2\n\nVerificaci√≥n de membresia al conjunto a.\n\n3\n\nA√±ade 50 al conjunto.\n\n4\n\nSe borra el elemento 10 del conjunto.\n\n5\n\nIntersecci√≥n de a con una colecci√≥n, no se modifica el conjunto a.\n\n6\n\nUni√≥n con otra colecci√≥n, se modifica a.\n\n\n\n\ntrue\nSet([50, 20, 10, 30, 40])\nSet([50, 20, 30, 40])\nSet([20])\nSet([50, 200, 20, 30, 40, 100])",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#el-flujo-de-compilaci√≥n-de-julia",
    "href": "cap1-julia.html#el-flujo-de-compilaci√≥n-de-julia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.2 El flujo de compilaci√≥n de Julia",
    "text": "1.2 El flujo de compilaci√≥n de Julia\nBasta con escribir una linea de c√≥digo en el REPL de Julia y esta se compilar√° y ejecutar√° en el contexto actual, usando el √°mbito de variables. Esto es conveniente para comenzar a trabajar, sin embargo, es importante conocer el flujo de compilaci√≥n para tenerlo en cuenta mientras se c√≥difica, y as√≠ generar c√≥digo eficiente. En particular, la creaci√≥n de funciones y evitar la inestabilidad de los tipos de las variables es un paso hacia la generaci√≥n de c√≥digo eficiente. Tambi√©n es importante evitar el alojamiento de memoria din√°mica siempre que sea posible. A continuaci√≥n se mostrar√° el an√°lisis de un c√≥digo simple a diferentes niveles, mostrando que el lenguaje nos permite observar la generaci√≥n de c√≥digo, que √∫ltimadamente nos da cierto control y nos permite verificar que lo que se esta implementando es lo que se espec√≠fica en el c√≥digo. Esto no es posible en lenguajes como Python.\n\nlet\n    e = 1.1\n    println(e*e)\n    @code_typed e*e\nend\n\n1.2100000000000002\n\n\nCodeInfo(\n1 ‚îÄ %1 = Base.mul_float(x, y)::Float64\n‚îî‚îÄ‚îÄ      return %1\n) =&gt; Float64\n\n\nEn este c√≥digo, se utiliza la estructa de agrupaci√≥n de expresiones let...end. Cada expresi√≥n puede estar compuesta de otras expresiones, y casi todo es una expresi√≥n en Julia. La mayoria de las expresiones ser√°n finalizadas por un salto de linea, pero las compuestas como let, begin, function, if, while, for, do, module estar√°n finalizadas con end. La indentaci√≥n no importa la indentaci√≥n como en Python, pero es aconsejable para mantener la legibilidad del c√≥digo. La linea 2 define e inicializa la variable e; la linea 3 llama a la funci√≥n println, que imprimir√° el resultado de e*e en la consola. La funci√≥n println esta dentro de la biblioteca est√°ndar de Julia y siempre esta visible. La linea 4 es un tanto diferente, es una macro que toma la expresi√≥n e*e y realiza algo sobre la expresi√≥n misma, en particular @code_type muestra como se reescribe la expresi√≥n para ser ejecutada. Note como se har√° una llamada a la funci√≥n Base.mul_float que recibe dos argumentos y que regresar√° un valor Float64. Esta informaci√≥n es necesaria para que Julia pueda generar un c√≥digo veloz, el flujo de compilaci√≥n llevar√≠a esta informaci√≥n a generar un c√≥digo intermedio de Low Level Virtual Machine (LLVM), que es el compilador empotrado en Julia, el cual estar√≠a generando el siguiente c√≥digo LLVM (usando la macro @code_llvm):\n\n\n;  @ float.jl:411 within `*`\ndefine double @\"julia_*_1779\"(double %0, double %1) #0 {\ntop:\n  %2 = fmul double %0, %1\n  ret double %2\n}\n\n\nEste c√≥digo ya no es espec√≠fico para Julia, sino para la maquinar√≠a LLVM. Observe la especificidad de los tipos y lo corto del c√≥digo. El flujo de compilaci√≥n requerir√≠a generar el c√≥digo nativo, que puede ser observado a continuaci√≥n mediante la macro @code_native:\n\n\n    .text\n    .file   \"*\"\n    .globl  \"julia_*_1818\"                  # -- Begin function julia_*_1818\n    .p2align    4, 0x90\n    .type   \"julia_*_1818\",@function\n\"julia_*_1818\":                         # @\"julia_*_1818\"\n; ‚îå @ float.jl:411 within `*`\n# %bb.0:                                # %top\n    push    rbp\n    mov rbp, rsp\n    vmulsd  xmm0, xmm0, xmm1\n    pop rbp\n    ret\n.Lfunc_end0:\n    .size   \"julia_*_1818\", .Lfunc_end0-\"julia_*_1818\"\n; ‚îî\n                                        # -- End function\n    .section    \".note.GNU-stack\",\"\",@progbits\n\n\nEn este caso podemos observar c√≥digo espec√≠fico para la computadora que esta generando este documento, es posible ver el manejo de registros y el uso de instrucciones del CPU en cuesti√≥n.\nEste c√≥digo puede ser eficiente dado que los tipos y las operaciones son conocidos, en el caso que esto no puede ser, la eficiencia esta perdida. Datos no nativos o la imposibilidad de determinar un tipo causar√≠an que se generar√° m√°s c√≥digo nativo que terminar√≠a necesitanto m√°s recursos del procesador. Una situaci√≥n similar ocurre cuando se aloja memoria de manera din√°mica. Siempre estaremos buscando que nuestro c√≥digo pueda determinar el tipo de datos para que el c√≥digo generado sea simple, si es posible usar datos nativos, adem√°s de no manejar o reducir el uso de memor√≠a din√°mica.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#ejemplos-de-funciones",
    "href": "cap1-julia.html#ejemplos-de-funciones",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.3 Ejemplos de funciones",
    "text": "1.3 Ejemplos de funciones\nLas funciones ser√°n una parte central de nuestros ejemplos, por lo que vale la pena retomarlas y dar ejemplos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#recursos-para-aprender-python-y-julia",
    "href": "cap1-julia.html#recursos-para-aprender-python-y-julia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.4 Recursos para aprender Python y Julia",
    "text": "1.4 Recursos para aprender Python y Julia\n\n1.4.1 Python\n\nPython, se recomieda utilizar la distribuci√≥n de https://www.anaconda.com/download/\nDocumentaci√≥n oficial, comenzar por el tutorial https://docs.python.org/3/\nDocumentaci√≥n oficial https://docs.julialang.org/en/stable/\n\n\n\n1.4.2 Julia\n\nInformaci√≥n sobre como instalar Julia y flujos de trabajo simples (e.g., REPL, editores, etc.) para trabajar con este lenguaje de programaci√≥n: Modern Julia Workflows https://modernjuliaworkflows.github.io/.\nLibro sobre julia Think Julia: How to Think Like a Computer Scientist https://benlauwens.github.io/ThinkJulia.jl/latest/book.html.\nCurso Introduction to computational thinking https://computationalthinking.mit.edu/Fall20/",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#licencia",
    "href": "cap1-julia.html#licencia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.5 Licencia",
    "text": "1.5 Licencia\n\nEsta obra est√° bajo una Licencia Creative Commons Atribuci√≥n-CompartirIgual 4.0 Internacional",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#footnotes",
    "href": "cap1-julia.html#footnotes",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "",
    "text": "Se recomienda utilizar la versi√≥n 1.10 o superior, y puede obtenerse en https://julialang.org/.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html",
    "href": "cap2-analisis.html",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "",
    "text": "2.1 Concepto de algoritmo y estructura de datos\nEste cap√≠tulo introduce los fundamentos de an√°lisis de algoritmos. Se introduce el concepto de modelo de c√≥mputo, se itroduce y se motiva la notaci√≥n asint√≥tica, ya que es el lenguaje com√∫n en el an√°lisis de algoritmos. Tambi√©n se mostrar√°n algunos de los ordenes de crecimiento m√°s representativos, que nos permitir√°n comparar algoritmos que resuelvan una tarea dada, as√≠ como permitirnos catalogarlos con respecto a los recursos de computo necesarios para ejecutarlos.\nLos algoritmos son especificaciones formales de los pasos u operaciones que deben aplicarse a un conjunto de entradas para resolver un problema, obteniendo una soluci√≥n correcta a dicho problema. Establecen los fundamentos de la programaci√≥n y de la manera en como se dise√±an los programas de computadoras. Dependiendo del problema, pueden existir m√∫ltiples algoritmos que lo resuelvan, cada uno de ellos con sus diferentes particularidades. As√≠ mismo, un problema suele estar conformado por una cantidad enorme de instancias de dicho problema, por ejemplo, para una lista de \\(n\\) n√∫meros, existen \\(n!\\) formas de acomodarlos, de tal forma que puedan ser la entrada a un algoritmo cuya entrada sea una lista de n√∫meros donde el orden es importante. En ocasiones, los problemas pueden tener infinitas de instancias. En este curso nos enfocaremos en problemas que pueden ser simplificados a una cantidad finita instancias.\nCada paso u operaci√≥n en un algoritmo esta bien definido y puede ser aplicado o ejecutado para producir un resultado. A su vez, cada operaci√≥n suele tener un costo, dependiente del m√≥delo de computaci√≥n. Conocer el n√∫mero de operaciones necesarias para transformar la entrada en la salida esperada, i.e., resolver el problema, es de vital importancia para seleccionar el mejor algoritmo para dicho problema, o aun m√°s, para instancias de dicho problema que cumplen con ciertas caracter√≠sticas.\nUna estructura de datos es una abstracci√≥n en memoria de entidades matem√°ticas y l√≥gicas que nos permite organizar, almacenar y procesar datos en una computadora. El objetivo es que la informaci√≥n representada puede ser manipulada de manera eficiente en un contexto espec√≠fico, adem√°s de simplificar la aplicaci√≥n de operaciones para la aplicaci√≥n de algoritmos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#modelos-de-c√≥mputo",
    "href": "cap2-analisis.html#modelos-de-c√≥mputo",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.2 Modelos de c√≥mputo",
    "text": "2.2 Modelos de c√≥mputo\nUn modelo de c√≥mputo es una abstracci√≥n matem√°tica de una computadora o marco de trabajo algor√≠tmico que nos permite estudiar y medir los costos de los algoritmos funcionando en este modelo de tal forma que sea m√°s simple que una computadora f√≠sica real. Ejemplos de estos modelos son las m√°quinas de Turing, las funciones recursivas, el c√°lculo lambda, o la m√°quina de acceso aleatorio. Todas estos modelos son equivalentes en sus capacidades, pero sus diferentes planteamientos permiten enfocarse en diferentes aspectos de los problemas.\n\nLa m√°quina de Turing. Es un m√≥delo creado por Alan Turing a principios del siglo XX; la idea es un dispositivo que podr√≠a ser implementada de manera mec√°nica si se tuvieran recursos infinitos; esta m√°quina puede leer y escribir en una cinta infinita una cantidad de s√≠mbolos predeterminada para cada problema siguiendo una serie de reglas simples sobre lo que lee y escribe, dichas reglas y la cienta, forman una m√°quina de estados y memoria, que pueden realizar cualquier c√°lculo si el tiempo no fuera un problema.\nFunciones recursivas. Se basa en funciones que trabajan sobre los n√∫meros naturales y que definen en conjunto el espacio de funciones computables. Son una herramienta abstracta que permite a los te√≥ricos de la l√≥gica y computaci√≥n establecer los l√≠mites de lo computable.\nC√°lculo lambda. Es un m√≥delo creado por Alonzo Church y Stephen Kleene a principios del siglo XX, al igual que las funciones recursivas, se fundamenta en el uso de funciones y es una herramienta abstracta con pr√≥positos similares, sin embargo el c√°lculo lambda no se limita a recursiones, y se enfoca en diferentes reglas de reducci√≥n y composici√≥n de funciones, y es natural la inclusi√≥n de operadores de alto nivel, aunque estos mismos sean definidos mediante un esquema funcional.\nM√°quina de acceso aleatorio (RAM). Es un m√≥delo que describe una computadora con registros. Adiferencia de una computadora f√≠sica, no tienen limitaci√≥n en su capacidad, ni en la cantidad de registros ni en la precisi√≥n de los mismos. Cada registro puede ser identicado de manera √∫nica y su contenido le√≠do y escrito mediante reglas o instrucciones formando un programa. En particular reconoce las diferencias entre registros de los programas y registros de datos, i.e., arquitectura harvard. Existe un n√∫mero m√≠nimo de instrucciones necesarias (i.e., incremento, decremento, poner a cero, copiar, salto condicional, parar) pero es com√∫n construir esquemas m√°s complejos basados en estas primitivas. Se necesita un registro especial que indica el registro de programa siendo ejecutado. Los accesos a los registros tienen un tiempo constante a diferencia de otros esquemas; es el modelo m√°s cercano a una implementaci√≥n moderna de computadora.\n\n\nUna computadora moderna difiere de muchas formas de una m√°quina RAM. De entrada, las limitaciones f√≠sicas requieren memorias finitas y registros con valores m√≠nimos y m√°ximos. Tambi√©n se debe trabajar con una jerarqu√≠a de memoria con diferentes niveles, donde los niveles m√°s r√°pidos tambi√©n son los m√°s escasos; por tanto, es importante sacar provecho de esta jerarqu√≠a siempre que sea posible. Las operaciones tambi√©n tienen costos diferentes, dependiendo de su implementaci√≥n a nivel de circuiter√≠a, as√≠ como tambi√©n existe cierto nivel de paralelizaci√≥n que no esta presente en una m√°quina RAM, tanto a nivel de procesamiento de datos como lectura de datos y el programa, esto sin tener en cuenta la arquitecturas multitarea que ya es com√∫n en el equipo actual.\n\nEn este curso nos enfocaremos en especificaciones de alto nivel, donde los algoritmos pueden ser implementados en una computadora f√≠sica, y estaremos contando operaciones de inter√©s pensando en costos constantes en el acceso a memoria y en una selecci√≥n de operaciones, al estilo de una m√°quina RAM.\nLa selecci√≥n de operaciones de inter√©s tiene el esp√≠ritu de simplificar el an√°lisis, focalizando nuestros esfuerzos en operaciones que acumulan mayor costo y que capturan la din√°mica del resto. Adicionalmente al conteo de operaciones nos interesa el desempe√±o de los algoritmos en tiempo real y en la cantidad de memoria consumida, por lo que se aboradar√° el costo realizando mediciones experimentales, contrastando con el an√°lisis basado en conteo de operaciones siempre que sea posible.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#tipos-de-an√°lisis",
    "href": "cap2-analisis.html#tipos-de-an√°lisis",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.3 Tipos de an√°lisis",
    "text": "2.3 Tipos de an√°lisis\nLa pregunta inicial ser√≠a ¬øqu√© nos interesa saber de un algoritmo que resuelve un problema? probablemente, lo primero ser√≠a saber si produce resultados correctos. Despu√©s, entre el conjunto de las alternativas que producen resultados correctos, es determinante obtener su desempe√±o para conocer cu√°l es m√°s conveniente para resolver un problema.\nEn ese punto, es necesario reconocer que para un problema, existen diferentes instancias posibles, esto es el espacio de instancias del problema, y que cada una de ellas exigir√≠an soluciones con diferentes costos para cada algoritmo. Por tanto existen diferentes tipos de an√°lisis y algoritmos.\n\nAn√°lisis de mejor caso. Obtener el m√≠nimo de resolver cualquier instancia posible, puede parecer poco √∫til desde el punto de vista de decisi√≥n para la selecci√≥n de un algoritmo, pero puede ser muy √∫til para conocer un problema o un algoritmo.\nAn√°lisis de peor caso. Obtener el costo m√°ximo necesario para resolver cualquier instancia posible del problema con un algoritmo, este es un costo que si nos puede apoyar en la decisi√≥n de selecci√≥n de un algoritmo; sin embargo, en muchas ocasiones, puede ser poco informativo o innecesario ya que tal vez hay pocas instancias que realmente lo am√©riten.\nAn√°lisis promedio. Se enfoca en obtener un an√°lisis promedio basado en la poblaci√≥n de instancias del problema para un algoritmo dado.\nAn√°lisis amortizado. Se enfoca en an√°lisis promedio pero para una secuencia de instancias.\nAn√°lisis adaptativo. Para un subconjunto bien caracterizado del espacio de instancias de un problema busca an√°lizar los costos del algoritmo en cuesti√≥n. La caracterizaci√≥n suele estar en t√©rminos de una medida de complejidad para el problema; y la idea general es medir si un algoritmo es capaz de sacar provecho de instancias f√°ciles.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#notaci√≥n-asint√≥tica",
    "href": "cap2-analisis.html#notaci√≥n-asint√≥tica",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.4 Notaci√≥n asint√≥tica",
    "text": "2.4 Notaci√≥n asint√≥tica\nRealizar un conteo de operaciones y mediciones es un asunto complejo que requiere focalizar los esfuerzos. Para este fin, es posible contabilizar solo algunas operaciones de importancia, que se supondr√≠an ser√≠an las m√°s costosas o que de alguna manera capturan de manera m√°s fiel la din√°mica de costos.\nEl comportamiento asint√≥tico es otra forma de simplificar y enfocarnos en los puntos de importancia, en este caso, cuando el tama√±o de la entrada es realmente grande. Es importante mencionar, que no se esperan entradas de tama√±o descomunal, ni tampoco se espera cualquier tipo de entrada.\n\n2.4.1 Notaci√≥n \\(\\Theta\\)\nPara una funci√≥n dada \\(g(n)\\) denotamos por \\(\\Theta(g(n))\\) el siguiente conjunto de funciones:\n\\[\\begin{align}\n\\Theta(g(n)) &=  \\left\\{ f(n) \\mid \\text{ existen las constantes positivas }c_1, c_2 \\text{ y } n_0 \\text{ tal que } \\right.\\\\\n    ~ & \\left. 0 \\leq c_1 g(n) \\leq f(n) \\leq c_2 g(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nesto es, una funci√≥n \\(f(n)\\) pertenece al conjunto \\(g(n)\\) si \\(c_1 g(n)\\) y \\(c_2 g(n)\\) pueden cubrirla por abajo y por arriba, para esto deben existen las constantes positivas \\(c_1\\) y \\(c_2\\) y una \\(n\\) lo suficientemente larga, e.g., para eso la constante \\(n_0\\). La notaci√≥n propiamente de conjuntos puede usarse \\(f(n) \\in \\Theta(g(n))\\) pero es com√∫n en el √°rea usar \\(f(n) = \\Theta(g(n))\\) para expresar la pertenencia; este abuso de la notaci√≥n tiene ventaja a la hora de plantear los problemas de an√°lisis.\n\n\n2.4.2 Notaci√≥n \\(O\\)\nSe utiliza para indicar una cota asint√≥tica superior. Una funci√≥n \\(f(n)\\) se dice que esta en \\(O(g(n))\\) si esta en el siguiente conjunto:\n\\[\\begin{align}\nO(g(n)) &=  \\left\\{ f(n)  \\mid \\text{ existen las constantes positivas }c \\text{ y } n_0 \\text{ tal que } \\right.\\\\\n    ~& \\left. 0 \\leq f(n) \\leq c g(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nLa notaci√≥n \\(O\\) se usa para dar una cota superior, dentro de un factor constante. Al escribir \\(f(n) = O(g(n))\\) se indica que \\(f(n)\\) es miembro del conjunto \\(O(g(n))\\); hay que notar que \\(f(n) = \\Theta(g(n))\\) implica que \\(f(n) = O(g(n))\\), i.e., \\(\\Theta(g(n)) \\subseteq O(g(n))\\).\n\n\n2.4.3 Notaci√≥n \\(\\Omega\\)\nAl contrario de \\(O\\), la notaci√≥n \\(\\Omega\\) da una cota asint√≥tica inferior. Una funci√≥n \\(f(n)\\) se dice que esta en \\(\\Omega(g(n))\\) si esta en el siguiente conjunto:\n\\[\\begin{align}\n\\Omega(g(n)) = & \\left\\{ f(n)  \\mid \\text{ existen las constantes positivas }c \\text{ y } n_0 \\text{ tal que } \\right. \\\\\n    & \\left. 0 \\leq c g(n) \\leq f(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nDado que la \\(\\Omega\\) define una cota superior, basicamente si \\(f(n) = \\Omega(g(n))\\), entonces \\(f(n)\\) debe estar por encima de \\(g(n)\\) con las constantes \\(c\\) y \\(n_0\\) adecuadas. Al igual que la notaci√≥n \\(O\\), la notaci√≥n \\(\\Omega\\) es menos estricta que \\(\\Theta\\), esto es \\(f(n) = \\Theta(g(n))\\) implica que \\(f(n) = \\Omega(g(n))\\), por lo que \\(\\Theta(g(n)) \\subseteq \\Omega(g(n))\\).\nPor tanto, si \\(f(n) = O(g(n))\\) y \\(f(n) = \\Omega(g(n))\\) entonces \\(f(n) \\in \\Theta(g(n))\\).\n\nEs importante conocer los ordenes de crecimiento m√°s comunes de tal forma que podamos realizar comparaciones r√°pidas de costos, y dimensionar las diferencias de recursos entre diferentes tipos de costos. La notaci√≥n asint√≥tica hace uso extensivo de la diferencia entre diferentes ordenes de crecimiento para ignorar detalles y simplificar el an√°lisis de algoritmos.\n\n\n\n2.4.4 Apoyo audio-visual\nEn los siguientes videos se profundiza sobre los modelos de c√≥mputo y los diferentes tipos de an√°lisis sobre algoritmos.\n\nParte 1: \nParte 2: \nParte 3: \n\n\n\n2.4.5 Ordenes de crecimiento\n\n\nDado que la idea es realizar un an√°lisis asint√≥tico, las constantes suelen ignorarse, ya que cuando el tama√±o de la entrada es suficientemente grande, los t√©rminos con mayor orden de magnitud o crecimiento dominar√°n el costo. Esto es, es una simplificaci√≥n necesar√≠a.\nLos ordenes de crecimiento son maneras de categorizar la velocidad de crecimiento de una funci√≥n, y para nuestro caso, de una funci√≥n de costo. Junto con la notaci√≥n asimpt√≥tica nos permite concentrarnos en razgos gruesos que se mantienen para entradas grandes, m√°s que en los detalles, y no perder el punto de inter√©s. A continuaci√≥n veremos algunas funciones con crecimientos paradigm√°ticos; las observaremos de poco en poco para luego verlos en conjunto.\n\n2.4.5.1 Costo constante, logaritmo y lineal\nLa siguiente figura muestra un crecimiento nulo (constante), logaritmico y lineal. Note como la funci√≥n logar√≠tmica crece lentamente.\n\nusing Plots, LaTeXStrings\nn = 300 # 300 puntos\n\nplot(1:n, [10 for x in 1:n], label=L\"c\")\nplot!(1:n, [log2(x) for x in 1:n], label=L\"\\log{n}\")\nplot!(1:n, [x for x in 1:n], label=L\"n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.2 Costo \\(n \\log n\\) y polinomial\nA continuaci√≥n veremos tres funciones, una funci√≥n con \\(n\\log n\\) y una funci√≥n cuadr√°tica y una c√∫bica. Note como para valores peque√±os de \\(n\\) las diferencias no son tan apreciables para como cuando comienza a crecer \\(n\\); as√≠ mismo, observe los valores de \\(n\\) de las figuras previas y de la siguiente, este ajuste de rangos se hizo para que las diferencias sean apreciables.\n\nn = 7 # note que se usan menos puntos porque 300 ser√≠an demasiados para el rango\n\nplot(1:n, [x * log2(x) for x in 1:n], label=L\"n\\log_2{n}\")\nplot!(1:n, [x^2 for x in 1:n], label=L\"n^2\")\nplot!(1:n, [x^3 for x in 1:n], label=L\"n^3\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.3 Exponencial\nA continuaci√≥n se compara el crecimiento de una funci√≥n exponencial con una funci√≥n polinomial. Note que la funci√≥n polinomial es de grado 4 y que la funci√≥n exponencial tiene como base 2; a√∫n cuando para n√∫meros menores de aproximadamente 16 la funci√≥n polinomial es mayor, a partir de ese valor la funci√≥n \\(2^n\\) supera rapidamente a la polinomial.\n\nn = 20\n\nplot(1:n, [x^4 for x in 1:n], label=L\"n^4\")\nplot!(1:n, [2^x for x in 1:n], label=L\"2^n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.4 Crecimiento factorial\nVease como la funci√≥n factorial crece mucho m√°s r√°pido que la funci√≥n exponencial para una \\(n\\) relativamente peque√±a. Vea las magnitudes que se alcanzan en el eje \\(y\\), y comparelas con aquellas con los anteriores crecimientos.\n\nn = 20\n\nplot(1:n, [2^x for x in 1:n], label=L\"2^n\")\nplot!(1:n, [factorial(x) for x in 1:n], label=L\"n!\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.5 Un poco m√°s sobre funciones de muy alto costo\n\nn = 10\n\nplot(1:n, [factorial(x) for x in 1:n], label=L\"n!\")\nplot!(1:n, [x^x for x in Int128(1):Int128(n)], label=L\"n^n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVea la figura anterior, donde se compara \\(n!\\) con \\(n^n\\), observe como es que cualquier constante se vuelve irrelevante rapidamente; aun para \\(n^n\\) piense en \\(n^{n^n}\\).\nNote que hay problemas que son realmente costosos de resolver y que es necesario conocer si se comporta as√≠ siempre, si es bajo determinado tipo de entradas. Hay problemas en las diferentes √°reas de la ciencia de datos, donde veremos este tipo de costos, y habr√° que saber cuando es posible solucionarlos, o cuando se deben obtener aproximaciones que nos acerquen a las respuestas correctas con un costo manejable, es decir, mediar entre exactitud y costo. En este curso se abordaran problemas con un costo menor, pero que por la cantidad de datos, i.e., \\(n\\), se vuelven muy costosos y veremos como aprovechar supuestos como las distribuciones naturales de los datos para mejorar los costos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#el-enfoque-experimental",
    "href": "cap2-analisis.html#el-enfoque-experimental",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.5 El enfoque experimental",
    "text": "2.5 El enfoque experimental\nLa notaci√≥n asint√≥tica nos permite alcanzar un lenguaje com√∫n y preciso sobre los costos de problemas y algoritmos; es de especial importancia para la evaluaci√≥n de las alternativas en la literatura especializada, y elegir algoritmos a√∫n sin la necesidad de implementaci√≥n. El an√°lisis asint√≥tico da la posibilidad de conocer el desempe√±o desde diferentes perspectivas como peor caso o caso promedio, utilizando un m√≥delo de computaci√≥n, y siempre pensando en entradas lo suficientemente grandes.\nEn la pr√°ctica, existe una m√∫ltitud de razones por los cuales los problemas que se resuelven podrian no ser tan grandes como para que un algoritmo domine a otros de manera asint√≥tica, las instancias podr√≠an no ser tan generales como para preocuparse en el peor caso, o el caso promedio general. En muchas situaciones, es importante sacar provecho de los casos f√°ciles, sobre todo cuando el problema a resolver podr√≠a asegurar que dichos casos simples sean abundantes. Dada la complejidad detr√°s de definir sub-conjuntos de instancias y llevar a cabo un an√°lisis formal, se vuelve imperativo realizar pruebas experimentales.\nPor otra parte, dada la complejidad de una computadora moderna, es necesario realizar evaluaciones experimentales de los algoritmos que tengan una complejidad similar. Las computadoras reales tienen una jerarquia de memoria con tama√±os y velocidades de acceso divergentes entre s√≠, con optimizaciones integradas sobre la predicci√≥n de acceso y cierto nivel de paralelismo. Incluso, cada cierto tiempo se obtienen optimizaciones en los dispositivos que podr√≠an mejorar los rendimientos, por lo que es posible que con una generaci√≥n a otra, lo que sabemos de los algoritmos y su desempe√±o en computadoras y cargas de trabajo reales cambie.\n\n2.5.1 Metodolog√≠a experimental\nAlgunos de los algoritmos que se ver√°n en este libro son sumamente rapidos en la pr√°ctica para resolver una instancia pr√°ctica por lo que medir el desempe√±o de instancias solas podr√≠a no tener sentido. La acumulaci√≥n de operaciones es fundamental, as√≠ como la diversidad de las instancias tambi√©n lo es. Caracterizar las entradas es de vital importancia ya que la adaptabilidad a las instancias es parte de los objetivos.\nEntonces, estaremos probando conjuntos de instancias, caracterizadas y estaremos utilizando tiempos promedios. Tambi√©n estaremos usando conteo de operaciones, por lo que los algoritmos en cuesti√≥n muchas veces ser√°n adaptados para poder realizar este conteo.\nEn Julia etaremos utilizando las siguientes instrucciones:\n\n@time expr macro que mide el tiempo en segundo utilizado por expr, tambi√©n reporta el n√∫mero de alojaciones de memoria. Note que reducir la cantidad de memoria alojada puede significar reducir el tiempo de una implementaci√≥n, ya que el manejo de memoria din√°mica es costoso.\n@benchmark expr params macro del paquete BenchmarkTools que automatiza la repetici√≥n de expr para obtener diferentes mediciones y hacer un reporte, params permite manipular la forma en que se reliza la evaluaci√≥n.\n@btime expr params macro del paquete BenchmarkTools que mimetiza la salida de @time.\n\n\na = rand(Float32, 3, 3)\n1@time a * a\n2@time a * a\n\n\n1\n\nTodas las fuciones se deben compilar, la primera llamada uncluye los costos de compilaci√≥n.\n\n2\n\nEl costo sin compilaci√≥n, hay una alojaci√≥n que es la matriz donde se guarda el resultado.\n\n\n\n\n  1.149417 seconds (2.00 M allocations: 135.521 MiB, 4.97% gc time, 99.97% compilation time)\n  0.000013 seconds (1 allocation: 96 bytes)\n\n\n3√ó3 Matrix{Float32}:\n 0.192604  0.768473  0.844105\n 0.388769  0.845516  1.38606\n 0.613623  0.4825    0.975766\n\n\nTanto @benchmark como @btime aceptan interpolaci√≥n de variables con el prefijo $ para controlar la evaluaci√≥n de una expresi√≥n se debe contar como parte de lo que se quiere medir o no. Se puede combinar con el parametro setup para controlar de manera precisa las entradas para evaluar cada una de las repeticiones de expr.\n\nusing BenchmarkTools\n\n@benchmark a * a setup=(a=rand(Float32, 3, 3))\n\nBenchmarkTools.Trial: 10000 samples with 984 evaluations.\n Range (min ‚Ä¶ max):  50.088 ns ‚Ä¶  4.631 Œºs  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 96.38%\n Time  (median):     61.026 ns              ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   70.964 ns ¬± 82.403 ns  ‚îä GC (mean ¬± œÉ):  4.22% ¬±  4.11%\n\n    ‚ñÖ‚ñà‚ñÑ                                                        \n  ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ ‚ñÇ\n  50.1 ns         Histogram: frequency by time         167 ns &lt;\n\n Memory estimate: 96 bytes, allocs estimate: 1.\n\n\n\n\na = rand(Float32, 3, 3)\n@btime a * a setup=(a=$a)\n\n  52.337 ns (1 allocation: 96 bytes)\n\n\n3√ó3 Matrix{Float32}:\n 1.06282  0.208756  0.60189\n 2.21355  1.4028    2.01148\n 1.44996  1.06617   1.53792\n\n\nEl parametro sample controla el n√∫mero m√°ximo de muestras que se tomar√°n para el an√°lisis, y seconds limita el tiempo sobre el cual se tomar√°n muestras; se asegura que al menos se tomar√° una muestra, se debe tener en cuenta que puede costar m√°s que seconds.1\n\na = rand(Float32, 3, 3)\nb = rand(Float32, 3, 3)\n@benchmark a * b setup=(a=$a, b=$b) samples=1000 seconds=0.33\n\nBenchmarkTools.Trial: 1000 samples with 977 evaluations.\n Range (min ‚Ä¶ max):  65.705 ns ‚Ä¶  1.344 Œºs  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 91.31%\n Time  (median):     79.439 ns              ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   86.416 ns ¬± 57.817 ns  ‚îä GC (mean ¬± œÉ):  2.75% ¬±  4.06%\n\n   ‚ñá‚ñÜ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ                                                \n  ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ ‚ñÑ\n  65.7 ns         Histogram: frequency by time         164 ns &lt;\n\n Memory estimate: 96 bytes, allocs estimate: 1.\n\n\n\n\n2.5.2 Ejemplo del c√°lculo de m√°ximo de un arreglo y diferentes tipos de costo.\n‚Äì\n\n\n1function maximo(col)\n    maxpos = 1\n    actualizaciones = 1\n    i = 2\n\n    while i &lt; length(col)\n        if col[maxpos] &lt; col[i]\n            maxpos = i\n            actualizaciones += 1\n        end\n        i += 1\n    end\n\n    maxpos, actualizaciones\nend\n\n\n1\n\nFunci√≥n que encuentra el m√°ximo en una secuencia y devuelve su posici√≥n, y adem√°s devuelve el n√∫mero de veces que se actualiz√≥ el m√°ximo en el recorrido.\n\n\n\n\nmaximo (generic function with 1 method)\n\n\n\na = rand(UInt32, 128)\n1@benchmark maximo($a) samples=100 seconds=3\n\n\n1\n\nUn an√°lisis de desempe√±o usando @benchmark; probando con m√°ximo 100 samples en 3 segundos.\n\n\n\n\nBenchmarkTools.Trial: 100 samples with 815 evaluations.\n Range (min ‚Ä¶ max):  174.276 ns ‚Ä¶ 247.742 ns  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 0.00%\n Time  (median):     186.936 ns               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   188.047 ns ¬±  12.573 ns  ‚îä GC (mean ¬± œÉ):  0.00% ¬± 0.00%\n\n  ‚ñÜ    ‚ñá‚ñÑ   ‚ñà‚ñÑ    ‚ñÑ                                              \n  ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñá‚ñÅ‚ñÖ‚ñà‚ñà‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñà‚ñá‚ñà‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ ‚ñÖ\n  174 ns        Histogram: log(frequency) by time        247 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n\n\nNote que aunque se tiene un an√°lisis muy detallado del desempe√±o, otras medidas de costo caen fuera del dise√±o del paquete, por lo que es necesario hacerlas por otros medios. Por ejemplo, suponga que el n√∫mero de actualizaciones es nuesta medida de desempe√±o, un c√≥digo donde se capturen las actualizaciones\n\n1using StatsBase\n2a = [maximo(rand(UInt32, 128))[2] for i in 1:100]\n3quantile(a, [0.0, 0.25, 0.5, 0.75, 1.0])\n\n\n1\n\nInclusi√≥n de un paquete para c√°lculo de estad√≠sticas b√°sicas.\n\n2\n\nDefinici√≥n de 100 experimentos que calculan maximo sobre arreglos aleatorios.\n\n3\n\nC√°lculo del m√≠nimo, cuantiles 0.25, 0.5, 0.75, y el m√°ximo, para determinar el desempe√±o.\n\n\n\n\n5-element Vector{Float64}:\n  1.0\n  4.0\n  5.0\n  6.0\n 10.0",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#actividades",
    "href": "cap2-analisis.html#actividades",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.6 Actividades",
    "text": "2.6 Actividades\nComparar mediante simulaci√≥n en un notebook de Jupyter o Quarto los siguientes √≥rdenes de crecimiento:\n\n\\(O(1)\\) vs \\(O(\\log n)\\)\n\\(O(n)\\) vs \\(O(n \\log n)\\)\n\\(O(n^2)\\) vs \\(O(n^3)\\)\n\\(O(a^n)\\) vs \\(O(n!)\\)\n\\(O(n!)\\) vs \\(O(n^n)\\)\nEscoja los rangos adecuados para cada comparaci√≥n, ya que como ser√° evidente despu√©s, no es pr√°ctico fijar los rangos.\nCree una figura por comparaci√≥n, i.e., cinco figuras. Discuta lo observado por figura.\nCree una tabla donde muestre tiempos de ejecuci√≥n simulados para algoritmos ficticios que tengan los √≥rdenes de crecimiento anteriores, suponiendo que cada operaci√≥n tiene un costo de 1 nanosegundo.\n\nUse diferentes tama√±os de entrada \\(n=100\\), \\(n=1000\\), \\(n=10000\\) y \\(n=100000\\).\nNote que para algunas f√≥rmulas, los n√∫meros pueden ser muy grandes, tome decisiones en estos casos y defiendalas en el reporte.\n\nDiscuta las implicaciones de costos de c√≥mputo necesarios para manipular grandes vol√∫menes de informaci√≥n, en el mismo notebook.\n\n\n2.6.1 Entregable\nSu trabajo se entregar√° en PDF y con el notebook fuente; deber√° estar plenamente documentado, con una estructura que permita a un lector interesado entender el problema, sus experimentos y metodolog√≠a, as√≠ como sus conclusiones. Tenga en cuenta que los notebooks pueden alternar celdas de texto y c√≥digo.\nNo olvide estructurar su reporte, en particular el reporte debe cubrir los siguientes puntos:\n\nT√≠tulo del reporte, su nombre.\nIntroducci√≥n.\nC√≥digo cercano a la presentaci√≥n de resultados.\nFiguras y comparaci√≥n de los √≥rdenes de crecimiento.\nAn√°lisis y simulaci√≥n de costo en formato de tabla.\nConclusi√≥n. Debe abordar las comparaciones hechas y la simulaci√≥n; tambi√©n toque el tema de casos extremos y una \\(n\\) variable y asint√≥ticamente muy grande.\nLista de referencias. Nota, una lista de referencias que no fueron utilizadas en el cuerpo del texto ser√° interpretada como una lista vac√≠a.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#bibliograf√≠a",
    "href": "cap2-analisis.html#bibliograf√≠a",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.7 Bibliograf√≠a",
    "text": "2.7 Bibliograf√≠a\nCormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2022). Introduction to Algorithms (2nd ed.). MIT Press.\n\nParte I: Cap. 1, 2, 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#footnotes",
    "href": "cap2-analisis.html#footnotes",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "",
    "text": "Se recomienda visitar el sitio https://juliaci.github.io/BenchmarkTools.jl/stable/ para m√°s informaci√≥n sobre el paquete BenchmarkTools, y en particular para sus parametros, como guardar informaci√≥n de corridas.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html",
    "href": "cap3-estructuras.html",
    "title": "3¬† Estructuras de datos elementales",
    "section": "",
    "text": "Objetivo\nImplementar, aplicar y caracterizar el desempe√±o de algoritmos en peor caso y adaptativos para b√∫squeda en arreglos ordenados. Se discutir√°n estructuras de datos b√°sicas que ser√°n de gran utilidad al momento de construir programas y de resolver problemas m√°s complejos; nos enfocaremos en las estructuras de datos .",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#introducci√≥n",
    "href": "cap3-estructuras.html#introducci√≥n",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.1 Introducci√≥n",
    "text": "3.1 Introducci√≥n\nEn esta unidad se discutir√°n las propiedades y operaciones b√°sicas de estructuras como conjuntos, listas, pilas, colas, arreglos, vectores, matrices y matrices dispersas. La intenci√≥n es utilizar c√≥digo en el lenguaje de programaci√≥n Julia, que pueda ser traducido f√°cilmente en otros lenguajes de programaci√≥n; as√≠ como explicar las particularidades de las estructuras.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#conjuntos",
    "href": "cap3-estructuras.html#conjuntos",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.2 Conjuntos",
    "text": "3.2 Conjuntos\nLos conjuntos son estructuras abstractas que representan una colecci√≥n de elementos, en particular, dado las posibles aplicaciones un conjunto puede tener contenido inmutable o mutable, esto es que puede aceptar modificaciones a dicha colecci√≥n. Un conjunto puede estar vacio (\\(\\emptyset\\)) o contener elementos, e.g., \\(\\{a, b, c\\}\\). Un conjunto puede unirse con otro conjunto, e.g., \\(\\{a, b\\} \\cup \\{c\\} = \\{a, b, c\\}\\), as√≠ como puede intersectarse con otros conjuntos, e.g.¬†\\(\\{a, b, c\\} \\cap \\{b, d\\} = \\{b\\}\\). El tama√±o de una colecci√≥n lo representamos con barras, e.g., \\(|\\{a, b\\}| = 2\\). Tambi√©n es √∫til consultar por membresia \\(a \\in \\{a, b, c\\}\\) o por la negaci√≥n de membrsia, i.e., \\(a \\not\\in \\{a, b, c\\}\\). En contraste con la definici√≥n matem√°tica de conjunto, es com√∫n necesitar conjuntos mutables en diferentes algoritmos, esto es, que permitan inserciones y borrados sobre la misma estructura. Esto es sumamente √∫til ya que nos permite hacer una representaci√≥n en memoria que no requiera realizar copias y gestionar m√°s memoria. Suponga el conjunto \\(S = \\{a, b, c\\}\\), la funci√≥n \\(pop!(S, b)\\) resultar√≠a en \\(\\{a, c\\}\\), y la funci√≥n \\(push!(S, d)\\) resultar√≠a en \\(\\{a, c, d\\}\\) al encadenar estas operaciones. Note que el s√≠mbolo \\(!\\) solo se esta usando en cooncordancia con el lenguaje de programaci√≥n Julia para indicar que la funci√≥n cambiar√≠a el argumento de entrada, y es solo una convenci√≥n, no un operador en s√≠ mismo. As√≠ mismo, note que estamos usando una sintaxis muy sencilla \\(fun(arg1, arg2, ...)\\) para indicar la aplicaci√≥n de una funci√≥n u operaci√≥n a una serie de argumentos.\nEs importante hacer notar, que aunque es uno de los conceptos fundamentales, no existe una √∫nica manera de representar conjuntos, ya que los requerimientos de los algoritmos son diversos y tener la representaci√≥n correcta puede ser la diferencia. Las implementaciones y algoritmos alrededor pueden llegar a ser muy sofisticados, dependiendo de las caracter√≠sticas que se desean, algunas de las cuales ser√°n el centro de estudio de este curso.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#tuplas-y-estructuras",
    "href": "cap3-estructuras.html#tuplas-y-estructuras",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.3 Tuplas y estructuras",
    "text": "3.3 Tuplas y estructuras\nLas tuplas son colecciones abstractas ordenadas, donde incluso puede haber repetici√≥n, pueden verse como una secuencia de elementos, e.g., \\(S = (a, b, c)\\); podemos referirnos a la \\(i\\)√©sima posici√≥n de la forma \\(S_i\\), o incluso \\(S[i]\\), si el contexto lo am√©rita, e.g., pseudo-c√≥digo que pueda ser transferido a un lenguaje de programaci√≥n m√°s f√°cilmente. Es com√∫n que cada parte de la tupla pueda contener cierto tipo de dato, e.g., enteros, n√∫meros de punto flotante, s√≠mbolos, cadenas de car√°cteres, etc. Una tupla es muy amena para ser representada de manera contigua en memoria. En el lenguaje de programaci√≥n Julia, las tuplas se representan entre par√©ntesis, e.g., \\((1, 2, 3)\\).\n\nt = (10, 20, 30)\n\nt[1] * t[3] - t[2]\n\n280\nDefinici√≥n y acceso a los campos de una tupla en Julia\n\n\n\n\nDado que es amena para representarse de manera contigua en memoria, en los lenguajes de programaci√≥n que aprovechen este hecho, una tupla puede enviarse como valor (copiar) cuando se utiliza en una funci√≥n; por lo mismo, puede guardarse en el stack, que es la memoria inmediata que se tiene en el contexto de ejecuci√≥n de una funci√≥n. En esos casos, se puede optimizar el manejo de memoria (alojar y liberar), lo cu√°l puede ser muy beneficioso para un algoritmo en la pr√°ctico. El otro esquema posible es el heap, que es una zona de memoria que debe gestionarse (memoria din√°mica); es m√°s flexible y duradera entre diferentes llamadas de funciones en un programa. Los patrones esperados son dispersos y puede generar fragmentaci√≥n\nUna estructura es una tupla con campos nombrados; es muy √∫tilizada en lenguajes de programaci√≥n, por ejemplo, en Julia la siguiente estructura puede representar un punto en un plano:\n\nstruct Point\n  x::Float32\n  y::Float32\nend\n\nNote la especificaci√≥n de los tipos de datos que en conjunto describir√°n como dicha estructura se maneja por una computadora, y que en t√©rminos pr√°cticos, es determinante para el desempe√±o. Es com√∫n asignar valores satelitales en programas o algoritmos, de tal forma que un elemento simple sea manipulado o utilizado de manera explicita en los algoritmos y tener asociados elementos secundarios que se vean afectados por las operaciones. Los conjuntos, tuplas y las estructuras son excelentes formas de representar datos complejos de una manera sencilla.\nEn Julia, es posible definir funciones o m√©todos al rededor del tipo de tuplas y estructuras.\n\n\nEs importante saber que si algunos de los campos o datos de una tupla o estructura estan en el heap entonces solo una parte estar√° en el stack; i.e., en el caso extremo solo ser√°n referencias a datos en el heap. Esto puede llegar a complicar el manejo de memoria, pero tambi√©n puede ser un comportamiento sobre el que se puede razonar y construir.\n\n\"\"\"\n  Calcula la norma de un vector representado\n  como un tupla\n\"\"\"\nfunction norm(u::Tuple)\n  s = 0f0\n  for i in eachindex(u)\n    s = u[i]^2\n  end\n  sqrt(s)\nend\n\n\"\"\"\n  Calcula la norma de un vector de 2 dimensiones\n  representado como una estructura\n\"\"\"\nfunction norm(u::Point)\n  sqrt(u.x^2 + u.y^2)\nend\n\n(norm((1, 1, 1, 1)), norm(Point(1, 1)))\n\n(1.0, 1.4142135f0)\nFunciones sobre diferentes tipos de datos\n\n\nNote que la funci√≥n es diferente para cada tipo de entrada; a este comportamiento se le llamada despacho m√∫ltiple y ser√° un concepto com√∫n este curso. En otros lenguajes de programaci√≥n se implementa mediante orientaci√≥n a objetos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#arreglos",
    "href": "cap3-estructuras.html#arreglos",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.4 Arreglos",
    "text": "3.4 Arreglos\nLos arreglos son estructuras de datos que mantienen informaci√≥n de un solo tipo, tienen un costo constante \\(O(1)\\) para acceder a cualquier elemento (tambi√©n llamado acceso aleatorio) y tipicamente se implementan como memoria contigua en una computadora. Al igual que las tuplas, son colecciones ordenadas, las estaremos accediendo a sus elementos con la misma notaci√≥n. En este curso usaremos arreglos como colecciones representadas en segmentos contiguos de memoria con dimensiones l√≥gicas fijas. A diferencia de las tuplas, es posible reemplazar valores, entonces \\(S_{ij} \\leftarrow a\\), reemplazar√° el contenido de \\(S\\) en la celda especificada por \\(a\\).\n\n\nJulia tiene un soporte para arreglos excepcional, el cual apenas trataremos ya que se enfoca en diferentes √°reas del c√≥mputo num√©rico, y nuestro curso esta orientado a algoritmos. En Python, estructuras similares se encuentra en el paquete Numeric Python o numpy; tenga en cuenta que las afirmaciones sobre el manejo de memoria y representaci√≥n que estaremos usando se apegan a estos modelos, y no a las listas nativas de Python.\nA diferencia de las tuplas, pueden tener m√°s que una dimensi√≥n. La notaci√≥n para acceder a los elementos se extiende, e.g.¬†para una matriz \\(S\\) (arreglo bidimensional) \\(S_{ij}\\) se refiere a la celda en la fija \\(i\\) columna \\(j\\), lo mismo que \\(S[i, j]\\). Si pensamos en datos num√©ricos, un arreglo unidimensional es √∫til para modelar un vector de m√∫ltiples dimensiones, un arreglo bidimensional para representar una m√°triz de tama√±o \\(m \\times n\\), y arreglos de dimensi√≥n mayor pueden usarse para tensores. Se representan en memoria en segmentos contiguos, y los arreglos de m√∫ltiples dimensiones ser√°n representados cuyas partes pueden ser delimitadas mediante aritm√©tica simple, e.g., una matriz de tama√±o \\(m \\times n\\) necesitar√° una zona de memoria de \\(m \\times n\\) elementos, y se puede acceder a la primera columna mediante en la zona \\(1,\\dots,m\\), la segunda columna en \\(m+1,\\dots,2m\\), y la \\(i\\)√©sima en \\((i-1)m+1,\\dots,im\\); esto es, se implementa como el acceso en lotes de tama√±o fijo en un gran arreglo unidimensional que es la memoria.\n\n\nEsta es la manera que en general se manejan los datos en una computadora, y conocerlo de manera expl√≠cita nos permite tomar decisiones de dise√±o e implementaci√≥n.\n\n\n\n\n\n\n\n\nlista\n\n\n\nRAM\n\nmemoria RAM\n\notros\ndatos\n\ncolumna 1 - x[:, 1]\n\nx[1,1]\n\nx[2,1]\n\nx[3,1]\n\nx[4,1]\n\ncolumna 2 - x[:, 2]\n\nx[1,2]\n\nx[2,2]\n\nx[3,2]\n\nx[4,2]\n\ncolumna 3 - x[:, 3]\n\nx[1,3]\n\nx[2,3]\n\nx[3,3]\n\nx[4,3]\n\ncolumna 4 - x[:, 4]\n\nx[1,4]\n\nx[2,4]\n\nx[3,4]\n\nx[4,4]\n\notros\ndatos\n\n\n\n\n\n\nFigura¬†3.1: Esquema de una matriz en memoria.\n\n\n\n\n\nLa representaci√≥n precisa en memoria es significativa en el desempe√±o de operaciones matriciales como pueden ser el producto entre matrices o la inversi√≥n de las mismas. La manera como se acceden los datos es crucial en el dise√±o de los algoritmos.\nEl siguiente ejemplo define un vector \\(u\\) de \\(m\\) elementos y una matriz \\(X\\) de tama√±o \\(m \\times n\\), ambos en un cubo unitario de 4 dimensiones, y define una funci√≥n que selecciona el producto punto m√°ximo del vector \\(u\\) a los vectores columna de \\(X\\):\n\n\nfunction mydot(u, x)\n  s = 0f0\n  for i in eachindex(u, x)\n    s += u[i] * x[i]\n  end\n  s\nend\n\nfunction getmaxdot(u::Vector, X::Matrix)\n  maxpos = 1\n  # en la siguiente linea, @view nos permite controlar que\n  # no se copien los arreglos, y en su lugar, se usen referencias\n  maxdot = mydot(u, @view X[:, 1])\n  # obtiene el n√∫mero de columnas e itera apartir del 2do indice \n  mfilas, ncols = size(X)\n  for i in 2:ncols\n    d = mydot(u, @view X[:, i]) \n    if d &gt; maxdot\n      maxpos = i\n      maxdot = d\n    end\n  end\n\n  (maxpos, maxdot)\nend\n\ngetmaxdot(rand(Float32, 4), rand(Float32, 4, 1000))\n\n(740, 2.5505784f0)\n\n\nEn este c√≥digo puede verse como se separa el c√°lculo del producto punto en una funci√≥n, esto es porque en s√≠ mismo es una operaci√≥n importante; tambi√©n podemos aislar de esta forma la manera que se accede (el orden) a los vectores. La idea fue acceder columna a columna, lo cu√°l asegura el uso apropiado de los accesos a memoria. En la funci√≥n \\(getmaxdot\\) se resuelve el problema de encontrar el m√°ximo de un arreglo, y se puede observar que sin conocimiento adicional, este requiere \\(O(n)\\) comparaciones, para una m√°triz de \\(n\\) columnas. Esto implica que cada producto punto se cuenta como \\(O(1)\\), lo cual simplifica el razonamiento. Por la funci√≥n \\(mydot\\) podemos observar que el producto punto tiene un costo de \\(O(m)\\), por lo que la \\(getmaxdot\\) tiene un costo de \\(O(mn)\\) operaciones l√≥gicas y aritm√©ticas.\nEl producto entre matrices es un caso paradigm√°tico por su uso en la resoluci√≥n de problemas pr√°cticos, donde hay una gran cantidad de trabajo al rededor de los costos necesarios para llevarlo a cabo. En particular, el algoritmo na√Øve, es un algoritmo con costo c√∫bico, como se puede ver a continuaci√≥n:\n\nfunction myprod(A::Matrix, B::Matrix)\n  mA, nA = size(A)\n  mB, nB = size(B)\n  @assert nA == mB\n  C = Matrix{Float32}(undef, mA, nB)\n\n  for i in 1:mA\n    for j in 1:mB\n      rowA = @view A[i, :]\n      colB = @view B[:, i]\n      C[i, j] = mydot(rowA, colB)\n    end\n  end\n\n  C\nend\n\nA = rand(Float32, 5, 3)\nB = rand(Float32, 3, 5)\nC = myprod(A, B)\ndisplay(C)\n\n5√ó5 Matrix{Float32}:\n 1.15099   1.15099   1.15099   0.0         8.11f-43\n 0.159122  0.159122  0.159122  7.34f-43    4.3639f-41\n 1.16537   1.16537   1.16537   4.3639f-41  3.36f-43\n 1.487     1.487     1.487     3.36f-43    0.0\n 1.32428   1.32428   1.32428   0.0         8.13f-43\nFunciones sobre diferentes tipos de datos\n\n\nSe pueden ver dos ciclos iterando a lo largo de filas y columnas, adicionalmente un producto punto, el cual tiene un costo lineal en la dimensi√≥n del vector, por lo que el costo es c√∫bico. Esta implementaci√≥n es directa con la definici√≥n misma del producto matricial. Dado su implacto, existen diferentes algoritmos para hacer esta operaci√≥n m√°s eficiente, incluso hay √°reas completas dedicadas a mejorar los costos para diferentes casos o caracter√≠sticas de las matrices.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#listas",
    "href": "cap3-estructuras.html#listas",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.5 Listas",
    "text": "3.5 Listas\nLas listas son estructuras de datos ordenadas lineales, esto es, no se asume que los elementos se guardan de manera contigua y los accesos al \\(i\\)-√©simo elemento cuestan \\(O(i)\\). Se soportan inserciones y borrados. Por ejemplo, sea \\(L = [a, b, c, d]\\) una lista con cuatro elementos, \\(L_2 = b\\), \\(insert!(L, 2, z)\\) convertir√° \\(L = [a, z, b, c, d]\\) (note que \\(b\\) se desplaz√≥ y no se reemplaz√≥ como se esperar√≠a en un arreglo). La operaci√≥n \\(deleteat!(L, 2)\\) regresar√° la lista a su valor previo a la inserci√≥n. Estas operaciones que modifican la lista tambi√©n tienen diferentes costos dependiendo de la posici√≥n, e.g., donde el inicio y final de la secuencia (tambi√©n llamados cabeza y cola) suelen ser m√°s eficientes que accesos aleatorios, ya que se tienen referencias a estas posiciones en memoria. Es de especial importancia la navegaci√≥n por la lista mediante operaciones de sucesor \\(succ\\) y predecedor \\(pred\\), que pueden encadenarse para obtener acceso a los elementos. A diferencia de un arreglo, las listas no requieren una notaci√≥n simple para acceso a los elementos y sus reemplazos, ya que su aplicaci√≥n es diferente.\n\n\n\n\n\n\n\n\nlista\n\n\n\nlist\n\nhead\n\ntail\n\n\n\na\n\na\n\n \n\n\n\nlist:n-&gt;a:n\n\n\n\n\n\nc\n\nc\n\n \n\n\n\nlist:s-&gt;c:s\n\n\n\n\n\nb\n\nb\n\n \n\n\n\na:c-&gt;b:w\n\n\n\n\n\nb:c-&gt;c:w\n\n\n\n\n\nnothing\n\nnothing\n\n\n\nc:c-&gt;nothing\n\n\n\n\n\n\n\n\nFigura¬†3.2: Una lista ligada simple\n\n\n\n\n\nLa Figura¬†3.2 muestra una lista ligada, que es una implementaci√≥n de lista que puede crecer f√°cilmente, funciona en el heap de memoria por lo que cada bloque requiere memoria din√°mica. Cada bloque es una estructura; se pueden distinguir dos tipos, la lista que contiene referencias al primer nodo y al √∫ltimo nodo. Los nodos de de datos contienen los elementos de la colecci√≥n y referencias al siguiente nodo, tambi√©n llamado sucesor. El nodo nothing es especial y significa que no hay m√°s elementos.\nEl siguiente c√≥digo muestra como la definici√≥n de lista ligada.\n\n\n\n\nListado¬†3.1: C√≥digo para una lista ligada simple\n\n\nstruct Nodo\n  data::Int\n  next::Union{Nodo,Nothing}\nend\n\nnodo = Nodo(10, Nodo(20, Nodo(30, nothing)))\n\nprintln(nodo)\n(nodo.data, nodo.next.data, nodo.next.next.data)\n\n\n\n\nNodo(10, Nodo(20, Nodo(30, nothing)))\n\n\n(10, 20, 30)\n\n\nEn el Listado¬†3.1 se ignora la referencia a tail (head se guarda en nodo), por lo que las operaciones sobre tail requieren recorrer la lista completa, costando \\(O(n)\\) en el peor caso para una lista de \\(n\\) elementos.\nPor su manera en la cual son accedidos los datos, se tienen dos tipos de listas muy √∫tiles: las colas y las pilas. Las colas son listas que se acceden solo por sus extremos, y emulan la pol√≠tica de el primero en entrar es el primero en salir (first in - first out, FIFO), y es por eso que se les llama colas haciendo referencia a una cola para realizar un tr√°mite o recibir un servicio. Las pilas o stack son listas con la pol√≠tica el √∫ltimo en entrar es el primero en salir (last in - first out, LIFO). Mientras que cualquier lista puede ser √∫til para implementarlas, algunas maneras ser√°n mejores que otras dependiendo de los requerimientos de los problemas siendo resueltos; sin embargo, es importante recordar sus pol√≠ticas de acceso para comprender los algoritmos que las utilicen.\nEn este curso, se tienen en cuenta las siguientes operaciones, nombrando diferente cada operaci√≥n:\n\npush!(L, a): insertar \\(a\\) al final de la lista \\(L\\).\npop!(L): remueve el √∫ltimo elemento en \\(L\\).\ndeleteat!(L, pos): remueve el elemento en la posici√≥n \\(pos\\), se desplazan los elementos.\ninsert!(L, pos, valor): inserta \\(valor\\) en la posici√≥n \\(pos\\) desplazando los elementos anteriores.\n\n\n3.5.0.1 Ejercicios\n\nImplemente insert! y deleteat!\n¬øCu√°l ser√≠a la implementaci√≥n de succ y pred en una lista ligada?\n¬øCuales ser√≠an sus costos?\nA√±adiendo m√°s memoria, como podemos mejorar pred?\n\n\n\n3.5.1 Grafos\nOtras estructuras de datos elementales son los grafos. Un grafo \\(G = (V, E)\\) es una tupla compuesta por un conjunto de vertices \\(V\\) y el conjunto de aristas \\(E\\). Por ejemplo, el grafo con \\(A = (\\{a, b, c, d\\}, \\{(a, b), (b, c), (c, d), (d, a)\\})\\)\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na-&gt;b\n\n\n\n\n\nc\n\nc\n\n\n\nb-&gt;c\n\n\n\n\n\nd\n\nd\n\n\n\nc-&gt;d\n\n\n\n\n\nd-&gt;a\n\n\n\n\n\n\n\n\nFigura¬†3.3: Un grafo dirigido simple\n\n\n\n\n\nLos grafos son herramientas poderosas para representar de manera abstracta problemas que implican relaciones entre elementos. En algunos casos es √∫til asociar funciones a los v√©rtices y las aristas. Tenga en cuenta los siguientes ejemplos:\n\n\\(peso: V \\rightarrow \\mathbb{R}\\), la cual podr√≠a usarse como \\(peso(a) = 1.5\\).\n\\(costo: V \\times V \\rightarrow \\mathbb{R}\\), la cual podr√≠a usarse como \\(costo(a, b) = 2.0\\).\n\nLa estructura del grafo puede accederse mediante las funciones:\n\n\\(in(G, v) = \\{ u \\mid (u, v) \\in E\\}\\)\n\\(out(G, u) = \\{ v \\mid (u, v) \\in E\\}\\)\n\nas√≠ como el n√∫mero de vertices que entran y salen como:\n\n\\(indegree(G, v) = |in(G, v)|\\).\n\\(outdegree(G, u) = |out(G, u)|\\).\n\nUn grafo puede tener aristas no dirigidas, el grafo con \\(B=(\\{a, b, c, d\\}, \\{\\{a, b\\}, \\{b, c\\}, \\{c, d\\}, \\{d, a\\}\\})\\), no reconocer√° orden en las aristas.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\nd\n\nd\n\n\n\nc--d\n\n\n\n\nd--a\n\n\n\n\n\n\n\nFigura¬†3.4: Un grafo cuyas aristas no estan dirigidas\n\n\n\n\n\nPor lo tanto, podremos decir que \\((a, b) \\in E_A\\) pero \\((b, a) \\not\\in E_A\\). Por otro lado tenemos que \\(\\{a, b\\} \\in E_B\\), y forzando un poco la notaci√≥n, \\((a, b) \\in E_B\\), \\((b, a) \\in E_B\\); para los conjuntos de aristas de \\(A\\) y \\(B\\). La estructura puede ser accedida mediante \\(neighbors(G, u) = \\{ v \\mid \\{u, v\\} \\in E \\}\\).\nUn grafo puede estar representado de diferentes maneras, por ejemplo, un arreglo bidimensional (matriz), donde \\(S_{ij} = 1\\) si hay una arista entre los v√©rtices \\(i\\) y \\(j\\); y \\(S_{ij} = 0\\) si no existe una arista. A esta representaci√≥n se le llama matriz de adjacencia. Si el grafo tiene pocos \\(1\\)‚Äôs vale la pena tener una representaci√≥n diferente; este es el caso de las listas de adjacencia, donde se representa cada fila o cada columna de la matriz de adjacencia como una lista de los elementos diferentes de cero.\nExisten otras representaciones como la lista de coordenadas, coordinate lists (COO), o las representaciones dispersas compimidas, sparse row (CSR) y compressed sparse column (CSC) (Scott y T≈Øma 2023). Todas estas representaciones tratan de disminuir el uso de memoria y aprovechar la gran dispersi√≥n para realizar operaciones solo cuando sea estrictamente necesario.\nUn √°rbol es un grafo en el cual no existen ciclos, esto es, no existe forma que en una caminata sobre los v√©rtices, a traves de las aristas y prohibiendo revisitar aristas, es imposible regresar a un v√©rtice antes visto.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\nd\n\nd\n\n\n\na--d\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\ne\n\ne\n\n\n\nd--e\n\n\n\n\nf\n\nf\n\n\n\nd--f\n\n\n\n\n\n\n\nFigura¬†3.5: √Årbol con aristas no dirigidas\n\n\n\n\n\nEn algunos casos, es conveniente identificar v√©rtices especiales en un √°rbol \\(T=(V, E)\\). Un v√©rtice es la ra√≠z del √°rbol, \\(root(T)\\), es especial ya que seguramente se utilizar√° como acceso al √°rbol y por tanto contiene un camino a cada uno v√©rtices en \\(V\\). Cada v√©rtice puede tener o no hijos, \\(children(T, u) = \\{ v \\mid (u, v) \\in E \\}\\). Se dice que \\(u\\) es un hoja (leaf) si \\(children(T, u) = \\emptyset\\), e interno (inner) si no es ni ra√≠z ni hoja.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na-&gt;b\n\n\n\n\n\nd\n\nd\n\n\n\na-&gt;d\n\n\n\n\n\nc\n\nc\n\n\n\nb-&gt;c\n\n\n\n\n\ne\n\ne\n\n\n\nd-&gt;e\n\n\n\n\n\nf\n\nf\n\n\n\nd-&gt;f\n\n\n\n\n\n\n\n\nFigura¬†3.6: √Årbol con aristas dirigidas, note que es f√°cil saber si hay un v√©rtice o nodo que se distinga como ra√≠z, o nodos que sean hojas.\n\n\n\n\n\nAl igual que en los grafos m√°s generales, en los √°rboles es √∫til definir funciones sobre v√©rtices y aristas, as√≠ como marcar tipos de v√©rtices, e.g., posici√≥n u color, que simplifiquen el razonamiento para con los algoritmos asociados.\nLos nodos y las aristas de un grafo pueden recorrerse de diferentes maneras, donde se aprovechan las relaciones representadas. En un grafo general podr√≠a ser importante solo visitar una vez cada v√©rtice, o guiarse en el recorrido por alguna heur√≠stica o funci√≥n asociada a v√©rtices o aristas.\nEl recorrido primero a lo profundo, Depth First Search (DFS), comienza en un nodo dado y de manera voraz avanzar√° recordando orden de visita y avanzando al ver un nuevo nodo repitiendo el procedimiento hasta que todos los v√©rtices alcanzables sean visitados. El siguiente pseudo-c√≥digo lo implementa:\n#| lst-label: lst-dfs\n#| lst-cap: Psudo-c√≥digo DFS\n\nfunction operaci√≥n!(v√©rtice)\n  #... operaciones sobre el v√©rtice siendo visitado ...\nend\n\nfunction DFS(grafo, v√©rtice, visitados)\n  operaci√≥n!(v√©rtice)\n  push!(visitados, v√©rtice)\n  for v in neighbors(grafo, v√©rtice)\n    if v ‚àâ visitados\n      operaci√≥n!(v)\n      push!(visitados, v)\n      DFS(grafo, v, visitados)\n    end\n  end\nend\n\n# ... c√≥digo de preparaci√≥n del grafo\nvisitados = Set()\nDFS((v√©rtices, aristas), v√©rticeinicial, visitados)\n# ... c√≥digo posterior a la visita DFS\nLas llamadas recursivas a DFS tienen el efecto de memorizar el orden de visita anterior y regresarlo cuando se sale de este, por lo que hay una memoria implicita utilizada, implementanda por el stack de llamadas. La funci√≥n operaci√≥n! es una abstracci√≥n de cualquier cosa que deba hacerse sobre los nodos siendo visitados.\nEl recorrido a lo ancho, Breadth First Search (BSF), visita los v√©rtices locales primero que los alejados contrar√≠o al avance voraz utilizado por DFS.\n#| lst-label: lst-bfs\n#| lst-cap: Psudo-c√≥digo BFS\n\nfunction BFS(grafo, v√©rtice, visitados, cola)\n  operaci√≥n!(v√©rtice)\n  push!(visitados, v√©rtice)\n  push!(cola, v√©rtice)\n\n  while length(cola) &gt; 0\n    u = popfirst!(cola)\n    for v in neighbors(grafo, u)\n      if v ‚àâ visitados\n        operaci√≥n!(v)\n        push!(visitados, v)\n        push!(cola, v)\n      end\n    end\n  end\nend\n\n# ... c√≥digo de preparaci√≥n del grafo\nvisitados = Set()\nBFS((v√©rtices, aristas), v√©rticeinicial, visitados)\n# ... c√≥digo posterior a la visita BFS\nEl BFS hace uso expl√≠cito de la memoria para guardar el orden en que se visitar√°n los v√©rtices (cola); se utiliza un conjunto para marcar v√©rtices ya visitados (visitados) con la finalidad de evitar un recorrido infinito.\n\n3.5.1.1 Ejercicios\n\nImplemente un grafo dirigido mediante listas de adyacencia.\nImplemente un grafo no dirigido mediante lista de adyacencia.\nImplemente el algoritmo de recorrido DFS y BFS con implementaciones de grafos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#actividades",
    "href": "cap3-estructuras.html#actividades",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.6 Actividades",
    "text": "3.6 Actividades\nImplementar los siguientes algoritmos sobre matrices. - Multiplicaci√≥n de matrices - Eliminaci√≥n gaussiana / Gauss-Jordan Compare los desempe√±os de ambos algoritmos contando el n√∫mero de operaciones y el tiempo real para matrices aleatorias de tama√±o ( n n ) para ( n= 100, 300, 1000). Maneje de manera separada los datos de conteo de operaciones (multiplicaciones y sumas escalares) y las de tiempo real. Discuta sus resultados experimentales; ¬øqu√© puede concluir? ¬øCu√°l es el impacto de acceder los elementos contiguos en memoria de una matriz? ¬øQu√© cambiar√≠a si utiliza matrices dispersas? ¬øCu√°les ser√≠an los costos?\nEntregable\nSu trabajo se entregar√° en PDF y con el notebook fuente; deber√° estar plenamente documentado, con una estructura que permita a un lector interesado entender el problema, sus experimentos y metodolog√≠a, as√≠ como sus conclusiones. Tenga en cuenta que los notebooks pueden alternar celdas de texto y c√≥digo.\nNo olvide estructurar su reporte, en particular el reporte debe cubrir los siguientes puntos:\n\nT√≠tulo del reporte, su nombre.\nIntroducci√≥n.\nC√≥digo cercano a la presentaci√≥n de resultados.\nFiguras y tablas\nAn√°lisis de los resultados\nConclusi√≥n, discusiones de las preguntas\nLista de referencias. Nota, una lista de referencias que no fueron utilizadas en el cuerpo del texto ser√° interpretada como una lista vac√≠a.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#bibliograf√≠a",
    "href": "cap3-estructuras.html#bibliograf√≠a",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.7 Bibliograf√≠a",
    "text": "3.7 Bibliograf√≠a\nCormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2022). Introduction to Algorithms (2nd ed.). MIT Press.\n\nParte III: Cap 10 Elementary Data Structures.\nParte VI: Cap 22 Elementary Graph Algorithms.\nParte VII: Cap 28 Matrix Operations.\n\n\n\n\n\n\n\nScott, Jennifer, y Miroslav T≈Øma. 2023. ‚ÄúAn Introduction to Sparse Matrices‚Äù. En Algorithms for Sparse Linear Systems, 1‚Äì18. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-25820-6_1.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html",
    "href": "cap4-ordenamiento.html",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "",
    "text": "Objetivo\nImplementar y analizar algoritmos de ordenamiento de arreglos con costo √≥ptimo en el peor caso, as√≠ como algoritmos adaptativos a la entrada para caracterizar su desempe√±o bajo un enfoque experimental para la soluci√≥n efectiva de problemas inform√°ticos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#introducci√≥n",
    "href": "cap4-ordenamiento.html#introducci√≥n",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.1 Introducci√≥n",
    "text": "4.1 Introducci√≥n\nEn este tema se aborda el ordenamiento basado en comparaci√≥n, esto es, existe un operador \\(&lt;\\) que es capaz de distinguir si un elemento \\(a\\) es menor que un elemento \\(b\\).\nEl operador cumple con las siguientes propiedades:\n\nsi \\(a &lt; b\\) y \\(b &lt; c\\) entonces \\(a &lt; c\\) (transitividad); e.g., \\(1 &lt; 10\\) y \\(10 &lt; 100\\) entonces \\(1 &lt; 100\\).\ntricotom√≠a:\n\nsi \\(a &lt; b\\) es falso y \\(b &lt; a\\) es falso, entonces \\(a = b\\) (antis√≠metria); dicho de otras formas:\n\nsi \\(a\\) no es menor que \\(b\\) ni \\(b\\) menor que \\(a\\) entonces \\(a\\) es igual a \\(b\\),\ndesvelando variables, \\(1 &lt; 1\\) es falso, el intercambio es obvio, entonces \\(1=1\\).\n\nen otro caso, \\(a &lt; b\\) o \\(a &lt; b\\).\n\n\n\n\nUsar un operador como \\(&lt;\\) es suficiente para crear algoritmos correctos y eficientes, sin embargo, en la pr√°ctica y en una computadora real, tambi√©n es v√°lido utilizar operadores como \\(=\\) o \\(\\leq\\), o intercambiar por \\(&gt;\\) y \\(\\geq\\) seg√∫n convenga. No hay impacto en la eficiencia.\nSin perdida de generalidad, podemos planter el problema de ordenamiento sin permitir repeticiones como sigue: dado un arreglo \\(A[1, n] = a_1, a_2, \\cdots, a_n\\); un algoritmo de ordenamiento obtiene la permutaci√≥n \\(\\pi\\) tal que \\(a_{\\pi(1)} &lt; a_{\\pi(2)} &lt; \\cdots &lt; a_{\\pi(n)}\\).\n\n\nCuando se permiten elementos repetidos, se le llama ordenamiento estable i se asegura que en el arreglo ordenado se preserven el orden original posicional cuando \\(a = b\\). Esta propiedad es importante cuando hay datos sat√©litales asociados a la llave de comparaci√≥n.\nEn t√©rminos pr√°cticos, la idea es reorganizar \\(A\\), mediante el c√°lculo implicito de la permutaci√≥n \\(\\pi\\), de tal forma que despu√©s de terminar el proceso de ordenamiento se obtenga que \\(A\\) esta ordenado, i.e., \\(a_i \\leq a_{i+1}\\). En sistemas reales, el alojar memoria para realizar el ordenamiento implica costos adicionales, y es por esto muchas veces se busca modificar directamente \\(A\\).\n\n\nUtilizar \\(\\pi\\) solo es necesario cuando no es posible modificar \\(A\\). Tambi√©n es muy com√∫n utilizar datos sat√©lite asociados con los valores a comparar, de esta manera es posible ordenar diversos tipos de datos. Un ejemplo de esto es ordenar un dataframe, pero tambi√©n estructuras de datos donde existe un campo especial y el resto de los datos asociados es de importancia para una aplicaci√≥n.\n\n4.1.1 Costo del problema\nPara una entrada de tama√±o \\(n\\) existen \\(n!\\) permutaciones posibles; cada una de estas permutaciones es una instancia del problema de ordenamiento de tama√±o \\(n\\).\nExiste una permutaci√≥n objetivo \\(\\pi^*\\), i.e., que cumple con la definici√≥n de que esta ordenada; ahora pensemos en un grafo donde cada \\(\\pi_i\\) esta conectada con todas las permutaciones en las que se puede transformar haciendo una √∫nica operaci√≥n, e.g., intercambiando un elemento. El algoritmo forma ese grafo con sus posibles decisiones, por lo que el camino m√°s largo i.e., ruta sin ciclos, entre cualquier \\(\\pi_i\\) y la permutaci√≥n \\(\\pi^*\\) es el costo de peor caso del algoritmo.\nAhora, cada operaci√≥n que realicemos en un algoritmo nos acercar√° m√°s a \\(\\pi^*\\), descartando una cierta cantidad de instancias posibles pero no viables; si nuestra funci√≥n de transici√≥n en el grafo viene dada con respecto a colocar cada par de elementos en su orden relativo, entonces, la mitad de las permutaciones se han descartado, ya que ese par no puede estar en el orden contrario. Por tanto, el costo de cualquier algoritmo que realice comparaciones y descarte la mitad del espacio de b√∫squeda, es \\(\\log_2(n!)\\), que usando la aproximaci√≥n de Stirling,1 lo podemos reescribir como sigue:\n\\[\\log_2(n!) = n \\log_2 n - n \\log_2 e + O(\\log_2 n)\\]\nEsto se puede simplemente escribir como \\(O(n \\log n)\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#algoritmos-de-ordenamiento",
    "href": "cap4-ordenamiento.html#algoritmos-de-ordenamiento",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.2 Algoritmos de ordenamiento",
    "text": "4.2 Algoritmos de ordenamiento\nExisten muchos algoritmos que pueden resolver el problema de ordenamiento, es com√∫n contar el n√∫mero de comparaciones ya que produce la informaci√≥n necesaria para la navegaci√≥n en el grafo de instancias; tambi√©n es com√∫n contar las operaci√≥n de intercambiar elementos. Las pruebas y la navegaci√≥n en el grafo determina el costo del algoritmo. Es necesario mencionar que mover datos entre diferentes zonas de memoria puede llegar a ser m√°s costoso que solo acceder a esas zonas por lo que hay una asimetr√≠a en el costo de estas dos operaciones.\nNote que algunos de los algoritmos m√°s simples pueden tener un comportamiento oportunistas y que son capaces de obtener ventaja en instancias sencillas, por lo que no deber√≠a saltarse esas secciones si solo conoce su comportamiento en peor caso.\n\n4.2.1 Bubble sort\nEl algoritmo de ordenamiento de burbuja o bubble sort realiza una gran cantidad de comparaciones, como puede verse en Listado¬†4.1, el algoritmo usa dos ciclos anidados para realizar una comparaci√≥n y una posible transposici√≥n, formando un tri√°ngulo, i.e., \\[ \\sum_{i=1}^{n-1} \\sum_{j=1}^{n-i} O(1);\\] por lo tanto su costo esta dominado por el triangulo formado, i.e., \\(\\sim n^2/2\\) lo que puede escribirse simplemente como \\(O(n^2)\\).\n\n\n\n\nListado¬†4.1: Bubble sort de peor caso\n\n\nfunction bubble_sort!(A)\n  n = length(A)\n  for i in 1:n-1\n    for j in 1:n-i\n      if A[j] &gt; A[j+1]\n        A[j], A[j+1] = A[j+1], A[j]\n      end\n    end\n  end\n  \n  A\nend\n\nbubble_sort!([8, 4, 3, 1, 6, 5, 2, 7])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nCiclo que recorre \\(n-1\\) veces todo el arreglo; y pone el elemento m√°ximo en su posici√≥n final.\nCiclo que recorre \\(n-i\\) veces el arreglo; ya que en cada corrida se pone el m√°ximo en su posici√≥n.\nIntercambio cuando hay pares en desorden.\n\nEl algoritmo mostrado en Listado¬†4.1 es un algoritmo de peor caso, ya que sin importar la complejidad de la instancia (i.e., que tal alejada esta \\(\\pi_i\\) de \\(\\pi^*\\)), se comporta igual.\nEs relativamente f√°cil hacer un bubble sort que tenga en cuenta la complejidad de la instancia, medida como el n√∫mero de intercambios necesarios.\n\n\n\n\nListado¬†4.2: Bubble sort adaptable\n\n\nfunction adaptive_bubble_sort!(A)\n  n = length(A)\n\n  for i in 1:n-1     \n    s = 0            \n    for j in 1:n-i\n      if A[j] &gt; A[j+1]\n        s += 1\n        A[j], A[j+1] = A[j+1], A[j] \n      end\n    end\n    s == 0 && break\n  end\n  \n  A\nend\n\nadaptive_bubble_sort!([7, 8, 4, 3, 1, 6, 5, 2])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nLa idea es que si no hay intercambios en una iteraci√≥n, entonces el arreglo ya esta ordenado.\nContador de intercambios.\nCondici√≥n de paro, i.e., no hubo intercambios.\n\nEn la forma Listado¬†4.2, bubble sort es capaz de t√©rminar en \\(n-1\\) comparaciones si el arreglo esta ordenado; sacando provecho de casos simples en t√©rminos de instancias casi ordenadas.\n\n\n4.2.2 Insertion sort\nEl algoritmo de ordenamiento por inserci√≥n o insertion sort es un algoritmo simple que al igual que bubble sort tiene un mal peor caso y puede aprovechar casos simples\n\n\n\n\nListado¬†4.3: Algoritmo insertion sort\n\n\nfunction insertion_sort!(A)\n  n = length(A)\n  for i in 2:n\n    key = A[i]\n    j = i - 1   \n    while j &gt;= 1 && A[j] &gt; key\n      A[j + 1] = A[j]\n      j -= 1\n    end\n\n    A[j + 1] = key\n  end\n  \n  A\nend\n\ninsertion_sort!([5, 1, 4, 8, 2, 6, 3, 7])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nEl algoritmo comienza en la segunda posici√≥n del arreglo y revisar√° todos los elementos.\nEs importante hacer una copia de key para simplificar la implementaci√≥n.\nLa idea general es ordenar las posiciones de \\(1..i\\), para esto se debe recorrer hacia atr√°s el arreglo completo, para determinar la posici√≥n de inserci√≥n de key.\nIntercambio de elementos para colocar key en su lugar ordenado.\nkey se pone en su lugar final.\n\nPara analizar Listado¬†4.3, es importante notar que el ciclo m√°s externo termina con el subarreglo \\(A[1..i]\\) ordenado; por lo que cuando se comienza el ciclo, si key se prueba estar en su posici√≥n correcta, entonces ya no es necesario revisar el resto del subarreglo, esto determina que un arreglo ordenado tendr√° un costo de \\(O(n)\\) comparaciones; si esta casi ordenado en t√©rminos del n√∫mero de intercambios necesarios, entonces, el algoritmo se adaptar√° sacando provecho de la instancia.\nEn el peor caso de insertion sort, el algoritmo no puede parar de manera prematura, e.g., un arreglo en orden reverso, el ciclo for se ejecutara \\(n-1\\) veces, mientras que el ciclo while deber√° revisar el subarreglo completo en cada iteraci√≥n, sumando un costo de \\(i\\) operaciones en cada iteraci√≥n, i.e., \\(\\sum_{i=1}^n i\\), esta forma produce un tri√°ngulo, resultando en un costo \\(O(n^2)\\).\n\n\n4.2.3 Quick sort\nQuick sort (ver Cormen et¬†al. 2022, cap. 7) es un algoritmo tipo dividir para vencer; esto es, un algoritmo que divide un problema grande en instancias peque√±as m√°s sencillas. Es uno de los algoritmos m√°s veloces en la pr√°ctica por su buen manejo de memoria, aun cuando tiene un peor caso cuadr√°tico, en promedio el costo es \\(O(n \\log n)\\).\n\n\n\n\nListado¬†4.4: Algoritmo quick sort.\n\n\nusing Random\n\nfunction qsort!(A, low=1, high=length(A))\n  if low &lt; high\n      piv = part!(A, low, high)\n      qsort!(A, low, piv - 1)\n      qsort!(A, piv + 1, high)\n  end\n  \n  A\nend\n\nfunction part!(A, low, high)\n  ipiv = rand(low:high)\n  A[ipiv], A[high] = A[high], A[ipiv]\n  piv = A[high]\n\n  i = low - 1  # uno antes porque se accede despu√©s de un i+1\n  for j in low:high - 1\n      if A[j] &lt; piv\n          i += 1\n          A[i], A[j] = A[j], A[i]\n      end\n  end\n  \n  ipiv = i + 1\n  A[ipiv], A[high] = A[high], A[ipiv]\n  ipiv\nend\n\nqsort!([6, 8, 3, 7, 4, 1, 2, 5])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nEl arreglo se divide en 3 partes, ordenadas entre s√≠, un subarreglo izquierdo, un pivote, y un subarreglo derecho; los subarreglos no estan ordenados localmente, pero el pivote esta en su posici√≥n final.\nSe resuelve el problema izquierdo y el problema derecho por separado.\nLa funci√≥n part! particiona el arreglo \\(A[low:end]\\) en 3 partes como se espec√≠fico en el punto 1; para eso selecciona de manera aleatoria un pivote. Lo ponemos al final del arreglo para simplificar el c√≥digo siguiente.\nEste ciclo itera por todo el subarreglo, su objetivo es asegurar que \\(A[i] &lt; piv\\) para todo \\(i \\in low:piv-1\\) y \\(piv &lt; A[i]\\) para todo \\(i \\in piv+1:high\\).\nIntercambia elementos si \\(A[j] &lt; piv\\), hacemos seguimiento de \\(i\\) ya que esta posici√≥n determinar√° al pivote.\nComo piv se encontraba en high, entonces hay que intercambiarlos para que qsort! sepa como manejarlos; recordando que los subarreglos no estan ordenados dentro de s√≠.\n\nEl c√≥digo Listado¬†4.4 es relativamente simple, usa recurrencias sobre qsort! sobre dos partes extremas divididas por un pivote; estos tres elementos son encontrados en part!. La funci√≥n part! es muy eficiente en t√©rminos de memoria, lo que puede hacer la diferencia en la pr√°ctica. La correcta selecci√≥n del pivote es muy importante para evitar casos malos, i.e., costo cuadr√°tico; en esta implementaci√≥n se realiza una selecci√≥n aleator√≠a de pivote que funcionar√° en la mayor√≠a de los casos.\nEl peor de los casos en qsort! es debido a una mala selecci√≥n del pivote, de tal forma que \\[|A[low:piv-1]| \\ll |A[piv+1:high]|,\\] o lo contrario en toda selecci√≥n, en el extremo una de los subarreglos puede verse como de tama√±o constante o cero, i.e., selecci√≥n de pivote como el minimo o el m√°ximo. Esta estrateg√≠a reduce a qsort! a un costo \\(O(n^2)\\).\nSi se realiza un particionado donde \\[|A[low:piv-1]| \\approx |A[piv+1:high]|,\\] entonces tenemos un algoritmo \\(O(n \\log n)\\); ya que hace una divisi√≥n en dos partes casi iguales en cada recurrencia a qsort!, y esto solo puede profundizar a \\(\\log n\\) veces, y en cada nivel part! tiene un costo lineal.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#skip-list",
    "href": "cap4-ordenamiento.html#skip-list",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.3 Skip list",
    "text": "4.3 Skip list\nUna skip list (Pugh 1990) es una lista ligada con capacidades de b√∫squeda eficiente con garant√≠as probabil√≠sticas, esto es que se cumplen con alta probabilidad. Para esto, la idea es que cada dato tiene asociado un arreglo de punteros o referencias hacia nodos sucesores, i.e., los nodos a nivel \\(i\\) se conectan con el siguiente nodo a nivel \\(i\\). En el nivel m√°s bajo, la skip list es una simple lista ligada, mientras que sube, se vuelve m√°s dispersa dando saltos m√°s largos.\n\n\n\n\n\n\n\n\nlista\n\n\n\nhead\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\n(head)\n\n\n\na\n\n(2)\n\n(1)\n\na\n\n\n\nhead:1-&gt;a:1\n\n\n\n\n\nhead:2-&gt;a:2\n\n\n\n\n\n\ne\n\n(3)\n\n(2)\n\n(1)\n\ne\n\n\n\nhead:3-&gt;e:3\n\n\n\n\n\nh\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\nh\n\n\n\nhead:e-&gt;h:w\n\n\n\n\n\nb\n\n(1)\n\nb\n\n\n\na:1-&gt;b:1\n\n\n\n\n\n\nc\n\n(2)\n\n(1)\n\nc\n\n\n\na:2-&gt;c:2\n\n\n\n\n\nb:1-&gt;c:1\n\n\n\n\n\n\nd\n\n(1)\n\nd\n\n\n\nc:1-&gt;d:1\n\n\n\n\n\n\nc:2-&gt;e:2\n\n\n\n\n\nd:1-&gt;e:1\n\n\n\n\n\n\nf\n\n(1)\n\nf\n\n\n\ne:1-&gt;f:1\n\n\n\n\n\n\ng\n\n(2)\n\n(1)\n\ng\n\n\n\ne:2-&gt;g:2\n\n\n\n\n\ne:3-&gt;h:3\n\n\n\n\n\nf:1-&gt;g:1\n\n\n\n\n\n\ng:1-&gt;h:1\n\n\n\n\n\ng:2-&gt;h:2\n\n\n\n\n\n\ni\n\n(1)\n\ni\n\n\n\nh:1-&gt;i:1\n\n\n\n\n\n\nj\n\n(3)\n\n(2)\n\n(1)\n\nj\n\n\n\nh:2-&gt;j:2\n\n\n\n\n\nh:3-&gt;j:3\n\n\n\n\n\ntail\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\n(tail)\n\n\n\nh:e-&gt;tail:w\n\n\n\n\n\ni:1-&gt;j:1\n\n\n\n\n\n\nj:1-&gt;tail:1\n\n\n\n\n\nj:2-&gt;tail:2\n\n\n\n\n\nj:3-&gt;tail:3\n\n\n\n\n\n\n\n\n\nFigura¬†4.1: Ejemplo de una skip list\n\n\n\n\n\nA diferencia de los algoritmos vistos anteriormente, en este caso, ya se tiene una estructura de datos, que conlleva un costo en memor√≠a expl√≠cito por nodo. Figura¬†4.1 ilustra la estructura.\nLa altura de cada nodo es calculada de manera probabil√≠stica, dada la probababilidad \\(p\\). Un valor com√∫n de \\(p=0.5\\). La altura de cada nodo se calcula como sigue:\n\nfunction levels(p)\n  i = 1\n  while rand() &lt; p\n    i += 1\n  end\n\n  i\nend\n\nlevels (generic function with 1 method)\n\n\nSi tenemos \\(n\\) evaluaciones de levels, Los niveles peque√±os son relativamente probables, mientras que niveles grandes son relativamente poco probables. De hecho, los niveles \\(\\log_{1/p} n\\) son cercanos a una constante, \\(\\log_{1/p}{n} - 1\\) son \\(1/p\\) veces la constante, \\(\\log_{1/p}{n} - 2\\) son \\(1/p^2\\) veces la constante, etc.\nA diferencia de los algoritmos anteriores, una skip list comienza vacia, y se va poblando insertando elementos a la lista. Se va colocando en la posici√≥n que no viola el orden; generando el nodo correspondiente con nivel calculado. Los nodos especiales head y tail siempre tienen el nivel m√°ximo posible. La inserci√≥n de un valor encapsulado en el nodo \\(u\\) comienza por visitar el m√°ximo nivel en head e ir bajando hasta determinar \\(u.dato &gt; head[level].dato\\); en ese momento se debe avanzar al nodo apuntado por \\(head[level]\\) y repetir el algoritmo hasta que \\(level=1\\), en cuyo caso encontramos el lugar de inserci√≥n del nuevo dato. Se procede a reasignar los punteros de los sucesores y ajustar los punteros hacia los nodos sucesores a los niveles que tiene \\(u\\).\nCada inserci√≥n tiene un costo \\(O(\\log_{1/p} n)\\), garant√≠a probabil√≠stica; por lo que insertar \\(n\\) elementos tiene un costo: \\[ \\sum_{i=1}^n O(\\log_{1/p} i) = O(\\log_{1/p} \\prod_{i=1}^n i) = O(\\log_{1/p} {n!}) = O(n \\log n); \\] usando la aproximaci√≥n de Stirling.\nA diferencia de la versi√≥n basada en arreglos, una skip list es capaz de aceptar nuevos elementos y mantener el orden de manera eficiente.\n\n4.3.1 Ejercicios:\n\nInvestigue, implemente y pruebe merge sort. 1.1 ¬øCuales son las ventajas y desventajas de merge sort? 1.2 ¬øPor qu√© merge sort se puede utilizar en algoritmos paralelos y otros pueden tener muchas dificultades? 1.3 ¬øC√≥mo se puede reducir la memoria extra necesaria de merge sort?\nInvestigue, implemente y pruebe heap sort. 2.1 ¬øCuales son las ventajas y desventajas de heap sort?\n¬øCu√°l es el costo en memoria de una skip list?. 3.1 Investigue, implemente y pruebe un skip list.\nInvestigue, implemente y pruebe un √°rbol binario de b√∫squeda.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#lecturas",
    "href": "cap4-ordenamiento.html#lecturas",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.4 Lecturas",
    "text": "4.4 Lecturas\nLas lecturas de este tema corresponden al cap√≠tulo 5 de (Knuth 1998), en espec√≠fico 5.2 Internal sorting. Tambi√©n se recomienda leer y comprender la parte II de (Cormen et¬†al. 2022), que corresponde a Sorting and order statistics, en part√≠cular Cap. 6 y 7, as√≠ como el Cap. 8.1. El art√≠culo de wikipedia https://en.wikipedia.org/wiki/Sorting_algorithm tambi√©n puede ser consultado con la idea de encontrar una explicaci√≥n r√°pida de los algoritmos.\nEn la pr√°ctica, pocos algoritmos son mejores que quicksort. En (Loeser 1974) se detalla una serie de experimentos donde se compara quicksort contra otros algoritmos relacionados; por lo que es una lectura recomendable.\nLa parte adaptable, esto es para algoritmos oportunistas que toman ventaja de instancias simples, esta cubierta por el art√≠culo (Estivill-Castro y Wood 1992). En especial, es muy necesario comprender las secciones 1.1 y 1.2, el resto del art√≠culo debe ser le√≠do aunque no invierta mucho tiempo en comprender las pruebas expuestas si no le son claras. En especial, en las secciones indicadas se establecen las medidas de desorden contra las cuales se mide la complejidad. En (Cook y Kim 1980) realiza una comparaci√≥n del desempe√±o de varios algoritmos para ordenamiento de listas casi ordenadas, esto es, en cierto sentido donde los algoritmos adaptables tienen sentido. Este art√≠culo es anterior a (Estivill-Castro y Wood 1992) pero tiene experimentos que simplifican el entendimiento de los temas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#material-audio-visual-sobre-algoritmos-de-ordenamiento",
    "href": "cap4-ordenamiento.html#material-audio-visual-sobre-algoritmos-de-ordenamiento",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.5 Material audio-visual sobre algoritmos de ordenamiento",
    "text": "4.5 Material audio-visual sobre algoritmos de ordenamiento\n\n\n\n\n\n\n\n\nCook, Curtis R, y Do Jin Kim. 1980. ‚ÄúBest sorting algorithm for nearly sorted lists‚Äù. Communications of the ACM 23 (11): 620‚Äì24.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, y Clifford Stein. 2022. Introduction to algorithms. MIT press.\n\n\nEstivill-Castro, Vladmir, y Derick Wood. 1992. ‚ÄúA survey of adaptive sorting algorithms‚Äù. ACM Computing Surveys (CSUR) 24 (4): 441‚Äì76.\n\n\nKnuth, Donald. 1998. The Art Of Computer Programming, vol. 3 (2nd ed): Sorting And Searching. Vol. 3. Redwood City, CA, USA.: Addison Wesley Longman Publishing Co. Inc.\n\n\nLoeser, Rudolf. 1974. ‚ÄúSome performance tests of ‚Äòquicksort‚Äô and descendants‚Äù. Communications of the ACM 17 (3): 143‚Äì52.\n\n\nPugh, William. 1990. ‚ÄúSkip lists: a probabilistic alternative to balanced trees‚Äù. Commun. ACM 33 (6): 668‚Äì76. https://doi.org/10.1145/78973.78977.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#footnotes",
    "href": "cap4-ordenamiento.html#footnotes",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "",
    "text": "Aproximaci√≥n de Stirling https://en.wikipedia.org/wiki/Stirling%27s_approximation.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html",
    "href": "cap5-busqueda.html",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "",
    "text": "5.0.1 Listas ordenadas\nEsta unidad esta dedicada a la implementaci√≥n y an√°lisis de algoritmos de b√∫squeda sobre arreglos ordenados, esto es que presentan un orden total. Un arreglo es una estructura lineal de elementos contiguos en memor√≠a donde la posici√≥n es importante. En esta unidad se estudian algoritmos que para localizar elementos que cumplan con predicados simples de orden. Como restricci√≥n adicional, se limita la duplicidad de elementos en los arreglos, esto sin reducir la generalidad de los algoritmos estudiados. Para cualquier tripleta de elementos \\(a, b, c\\) en el a arreglo se cumple lo siguiente:\nNote que dada la condici√≥n de arreglo consecutivo en memoria, para dos elementos \\(u_i\\) y \\(u_j\\), donde \\(i\\) y \\(j\\) son posiciones:\nLos algoritmos tomar√°n ventaja de este hecho para localizar de manera precisa y eficiente elementos deseados, descritos mediante los mismos operadores.\nEn esta unidad se aborda la b√∫squeda en arreglos ordenados, y abusando del t√©rmino, muchas veces les llamaremos listas ordenadas. Recuerde que a lo largo de este curso, esta ser√° nuestra representaci√≥n para conjuntos.\nEn la literatura es com√∫n que se aborde el tema con un modelo de costo basado en comparaciones, esto es, cada comparaci√≥n \\(\\le\\) provoca costo constante \\(O(1)\\). Este curso no es la excepci√≥n. La comparaci√≥n como unidad de costo es un excelente factorizador de las operaciones satelitales en los algoritmos de b√∫squeda; esto deber√≠a quedar claro una vez que se comprendan los algoritmos.\nUtilizaremos como base el art√≠culo (Jon Louis Bentley y Yao 1976), que es de lectura forzosa. Nos apoyaremos en una serie de lecturas adicionales para comprender y madurar el concepto.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#material-audio-visual",
    "href": "cap5-busqueda.html#material-audio-visual",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "5.1 Material audio-visual",
    "text": "5.1 Material audio-visual\nEn el siguiente video se adentraran en diferentes estrateg√≠as de b√∫squeda, notoriamente aquellas que llamaremos oportunistas o adaptables (adaptative). Estas t√©cnicas nos permitir√°n tomar provecho de instancias sencillas de problemas e incrementar el desempe√±o en ese tipo de instancias.\nTenga en cuenta que, honrando la literatura, usaremos de forma indiscriminada listas ordenadas como sin√≥nimo de arreglos ordenados.\n\n5.1.1 B√∫squeda",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#actividades",
    "href": "cap5-busqueda.html#actividades",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "5.2 Actividades",
    "text": "5.2 Actividades\n\n5.2.1 Actividad 0 [sin entrega]\nRealizar las actividades de lectura y comprensi√≥n, apoyos√© en el video de esta unidad. De preferencia realice los ejercicios de las secciones relacionadas.\n\nEl art√≠culo sobre b√∫squeda no acotada, como representativo sobre b√∫squeda adaptativa (Jon Louis Bentley y Yao 1976).\nCap. 12 de (Sedgewick 1998), en part√≠cular Sec. 12.3 y 12.4.\nCap. 6 de (Knuth 1998), en part√≠cular Sec. 6.1 y 6.2.\nEl art√≠culo sobre b√∫squeda adaptativa secuencial (Jon L. Bentley y McGeoch 1985).\nRecuerde la referencia b√°sica para la notaci√≥n y conceptos es (Cormen et¬†al. 2022).\n\n\n\n5.2.2 Actividad 1 [con reporte]\nRealice y reporte el siguiente experimento:\n\nUse el archivo listas-posteo-100.json, contiene las 100 listas de posteo m√°s frecuentes, se encuentran en formato JSON.\nUtilice las listas (sin el t√©rmino asociado).\nLos usuarios de Julia deber√°n asegurar que los tipos de los arreglos es Int y no Any para asegurar la velocidad adecuada\nSeleccione 1000 identificadores de documentos al azar, entre \\(1\\) y \\(n\\), recuerde que \\(n=50,000\\).\nGrafique el tiempo promedio de buscar los 1000 identificadores en todas las listas (un solo n√∫mero que represente las \\(100\\times 1000\\) b√∫squedas). Nota: lo que determinar√° al buscar es la posici√≥n de inserci√≥n que se define como el lugar donde deber√≠a estar el identificador si se encontrara en la lista.\nLos algoritmos que caracterizar√° son los siguientes (nombres con referencia a (Jon Louis Bentley y Yao 1976)):\n\nB√∫squeda binaria acotada\nB√∫squeda secuencial \\(B_0\\)\nB√∫squeda no acotada \\(B_1\\)\nB√∫squeda no acotada \\(B_2\\)\nImportante: Tal vez deba repetir varias veces cada b√∫squeda si los tiempos son muy peque√±os.\n\nBosqueje en pseudo-c√≥digo la implementaci√≥n de la b√∫squeda cas√≠ optima \\(B_k\\)\n\n\n\n5.2.3 Entregable\nEl reporte deber√° ser en formato notebook y el PDF del mismo notebook. El notebook debe contener las implementaciones de los algoritmos solicitados. Recuerde que el reporte debe llevar claramente su nombre, debe incluir una introducci√≥n, la explicaci√≥n de los experimentos realizados, las observaciones, conclusiones y bibliograf√≠a.\nNota: En las implementaciones podr√° usar comparaci√≥n \\(&lt;, \\leq\\), o incluso \\(cmp \\rightarrow \\{-1, 0, 1\\}\\), teniendo en cuenta que \\(cmp\\) es com√∫n en lenguajes modernos, solo debe indicarlo.\n\n\n5.2.4 Actividad 2 [sin entrega]\nRevisar el notebook crear-indice-invertido.ipynb para los detalles de como se gener√≥ la lista de posteo. Usted puede crear nuevas listas de posteo si lo desea usando los conjuntos de datos disponibles (listados en dicho notebook), y a su vez utilizarlas en las actividades de este Unidad. Solo deber√° indicarlo; recuerde que los n√∫meros de documentos y tama√±o de vocabulario cambiar√°n.\n\n\n5.2.5 Leyendo las listas de posteo\nUsted no necesita generar las listas de posteo, solo leer las que se le han proporcionado en el archivo listas-posteo-100.json que corresponden a las 100 listas de posteo m√°s pobladas (100 terminos m√°s usados en el conjunto de datos). En el archivo listas-posteo-100.json , cada linea un JSON valido, donde se tiene el t√©rmino y la lista de posteo.\n\nEn el notebook lectura-listas-de-posteo.ipynb se muestra como se leen las listas de posteo desde Julia\n\n\n\n\n\n\n\nBentley, Jon L., y Catherine C. McGeoch. 1985. ‚ÄúAmortized analyses of self-organizing sequential search heuristics‚Äù. Commun. ACM 28 (4): 404‚Äì11. https://doi.org/10.1145/3341.3349.\n\n\nBentley, Jon Louis, y Andrew Chi-Chih Yao. 1976. ‚ÄúAn almost optimal algorithm for unbounded searching‚Äù. Information Processing Letters 5 (3): 82‚Äì87. https://doi.org/https://doi.org/10.1016/0020-0190(76)90071-5.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, y Clifford Stein. 2022. Introduction to algorithms. MIT press.\n\n\nKnuth, Donald. 1998. The Art Of Computer Programming, vol. 3 (2nd ed): Sorting And Searching. Vol. 3. Redwood City, CA, USA.: Addison Wesley Longman Publishing Co. Inc.\n\n\nSedgewick, Robert. 1998. Algorithms in c++, parts 1-4: fundamentals, data structure, sorting, searching. Addison-Wesley-Longman, 1998.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html",
    "href": "cap6-intersecciones.html",
    "title": "6¬† Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas",
    "section": "",
    "text": "Objetivo\nImplementar y comparar algoritmos de intersecci√≥n de conjuntos representados como listas ordenadas, utilizando una variedad de algoritmos de b√∫squeda que dan diferentes propiedades a los algoritmos de intersecci√≥n.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#introducci√≥n",
    "href": "cap6-intersecciones.html#introducci√≥n",
    "title": "6¬† Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas",
    "section": "6.1 Introducci√≥n",
    "text": "6.1 Introducci√≥n\nEn este tema se conocer√°n, implementar√°n y comparar√°n algoritmos de intersecci√≥n de listas ordenadas. El c√°lculo de la intersecci√≥n es un proceso costoso en una m√°quina de b√∫squeda, sin embargo, es un procedimiento esencial cuando se trabaja con grandes colecciones de datos.\nEl √≠ndice invertido tal y como lo hemos creado, es capaz de manejar una cantidad razonablemente grande de documentos. Para asegurarnos del escalamiento con la cantidad de documentos, es necesario utilizar algoritmos de intersecci√≥n que sean eficientes. Entonces, dadas las listas ordenadas \\(L_1, \\cdots, L_k\\) (e.g, correspondientes a las listas de posteo en un √≠ndice invertido), tomar√° dichas listas y producir√° \\(L^* = \\bigcap_i L_i\\), esto es, si \\(u\\in L^*\\) entonces \\(u \\in L_i\\) para \\(1 \\leq i \\leq k\\).\nExisten varios algoritmos prominentes para llevar a cabo esta operaci√≥n. Uno de los trabajos seminales viene de Hwang & Lin, en su algoritmo de merge entre dos conjuntos (Hwang y Lin 1971). En este trabajo se replantea el costo como encontrar los puntos de uni√≥n entre ambos conjuntos, esto se traslada de manera inmediata al problema de intersecci√≥n. El problema correspondiente para intersectar dos conjuntos cualesquiera representados como conjuntos ordenados es entonces \\(\\log{{n+m} \\choose m}\\), que usando la aproximaci√≥n de Stirling se puede reescribir como \\[n \\log \\frac{n}{m} + (n-m)\\log \\frac{n}{n-m},\\] donde \\(n\\) y \\(m\\) corresponden a al n√∫mero de elementos en cada conjunto.\nUn algoritmo na√Øve para realizar la intersecci√≥n, puede ser buscar todos los elementos del conjunto m√°s peque√±o en el m√°s grande. Si para la b√∫squeda se utiliza b√∫squeda binaria, tenemos un costo de \\(m \\log n\\).\nEsta simple idea puede ser explotada y mejorada para obtener costos m√°s bajos, por ejemplo, si en lugar de buscar sobre la lista m√°s grande directamente, esta se divide en bloques de tama√±o \\(m\\) para encontrar el bloque que contiene cada elemento (recuerde que el arreglo esta ordenado), para despu√©s buscar dentro del bloque. Haciendo esto, el costo se convierte en \\[ m \\log \\frac{n}{m} + m \\log m\\] cuyo costo se ajusta mejor al costo del problema. Este es el algoritmo propuesto, a groso modo, en (Hwang y Lin 1971).\nCuando \\(k&gt;2\\), la intersecci√≥n se puede realizar usando las \\(k\\) listas a la vez, o se puede hace por pares. Se puede observar que la intersecci√≥n de dos conjuntos da como resultado un conjunto igual o m√°s peque√±o que el m√°s peque√±o de los conjuntos intersectados. Adicionalmente, los conjuntos peque√±os son ‚Äúm√°s faciles‚Äù de intersectar con un algoritmo na\"ive. Por tanto, una estrateg√≠a que funciona bien en el peor caso es intersectar los 2 arreglos m√°s peque√±os cada vez. Esta una idea muy popular llamada Small vs Small (SvS).\nExiste otra familia de algoritmos, basados en b√∫squedas adaptativas que pueden llegar a mejorar el desempe√±o bajo cierto tipo de entradas. En (Demaine, L√≥pez-Ortiz, y Ian Munro 2001), (Barbay, L√≥pez-Ortiz, y Lu 2006), (Barbay et¬†al. 2010), y (Baeza-Yates y Salinger 2005) se muestran comparaciones experimentales de diversos algoritmos de intersecci√≥n, entre ellos adaptables, que utilizan de manera creativa algoritmos de b√∫squeda adaptables para aprovechar instancias simples. Estos estudios se basan en contribuciones teoricas de los mismos autores (Demaine, L√≥pez-Ortiz, y Munro 2000), (Demaine, L√≥pez-Ortiz, y Ian Munro 2001), (Barbay y Kenyon 2002), (Baeza-Yates 2004).",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#recursos-audio-visuales-de-la-unidad",
    "href": "cap6-intersecciones.html#recursos-audio-visuales-de-la-unidad",
    "title": "6¬† Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas",
    "section": "6.2 Recursos audio-visuales de la unidad",
    "text": "6.2 Recursos audio-visuales de la unidad\nParte 1: Algoritmos de intersecci√≥n (y uni√≥n) de listas ordenadas \nParte 2: Algoritmos de intersecci√≥n y algunas aplicaciones",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#actividades",
    "href": "cap6-intersecciones.html#actividades",
    "title": "6¬† Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas",
    "section": "6.3 Actividades",
    "text": "6.3 Actividades\nImplementaci√≥n y comparaci√≥n de diferentes algoritmos de intersecci√≥n de conjuntos.\nLea cuidadosamente las instrucciones y desarrolle las actividades. Entregue el reporte correspondiente en tiempo.\n\n6.3.1 Actividad 0 [Sin entrega]\n\nLea y comprenda los art√≠culos relacionados (listados en la introducci√≥n).\n\n\n\n6.3.2 Actividad 1 [Con reporte]\n\nCargue el archivo listas-posteo-100.json del tema 3. Si lo desea, puede usar listas de posteo generadas con otros conjuntos de datos, usando los scripts de las unidades pasadas. Si es necesario, repase los temas anteriores para recordar la naturaleza y propiedades de las listas.\n\n\nSea \\(P^{(2)}\\) el conjunto de todos los posibles pares de listas entre las 100 listas de posteo. Seleccione de manera aleatoria \\(A \\subset P^{(2)}\\), \\(|A| = 1000\\).\nSea \\(P^{(3)}\\) el conjunto de todas las posibles combinaciones de tres listas de posteo entre las 100 listas disponibles, Seleccione de manera aleatoria \\(B \\subset P^{(3)}\\), \\(|B| = 1000\\).\nSea \\(P^{(4)}\\) el conjunto de todas las posibles combinaciones de cuatro listas de posteo entre las 100 listas disponibles. Seleccione de manera aleatoria \\(C \\subset P^{(4)}\\), \\(|C| = 1000\\).\n\n\nImplemente los algoritmos de las secciones 3.1 Melding Algorithms y 3.2 Search algorithms (en especial 3.2.1 y 3.2.2) de (Barbay et¬†al. 2010).\nRealice y reporte los siguientes experimentos:\n\n\nIntersecte cada par de listas \\(a, b \\in A\\), y reporte de manera acumulada el tiempo en segundos y el n√∫mero de comparaciones.\nIntersecte cada tripleta de listas \\(a, b, c \\in B\\), y reporte de manera acumulada el tiempo en segundos y el n√∫mero de comparaciones.\nIntersecte cada tetrapleta de listas \\(a, b, c, d \\in C\\), y reporte de manera acumulada el tiempo en segundos y el n√∫mero de comparaciones.\nCree una figura boxplot que describa el tiempo en segundos para los tres experimentos.\nCree una figura boxplot que describa el n√∫mero de comparaciones para los tres experimentos.\nCree una figura boxplot que describa las longitudes de las intersecciones resultantes para \\(A\\), \\(B\\), \\(C\\).\n\n\n\n6.3.3 Entregable\nEl reporte deber√° ser en formato notebook y el PDF del mismo notebook. El notebook debe contener las implementaciones. Recuerde que el reporte debe llevar claramente su nombre, debe incluir una introducci√≥n, la explicaci√≥n de los m√©todos usados, la explicaci√≥n de los experimentos realizados, la discusi√≥n de los resultados, y finalizar con sus observaciones y conclusiones.\nNota sobre la generaci√≥n del PDF: Jupyter no genera el PDF directamente, a menos que se tengan instalados una gran cantidad de paquetes, entre ellos una instalaci√≥n completa de LaTeX. En su lugar, para generar el PDF en Jupyter primero guarde el notebook como HTML y luego genere el PDF renderizando e imprimiendo el HTML con su navegador. En lugar de imprimir, seleccione guardar como PDF.\n\n\n\n\n\n\nBaeza-Yates, Ricardo. 2004. ‚ÄúA fast set intersection algorithm for sorted sequences‚Äù. En Combinatorial Pattern Matching: 15th Annual Symposium, CPM 2004, Istanbul, Turkey, July 5-7, 2004. Proceedings 15, 400‚Äì408. Springer.\n\n\nBaeza-Yates, Ricardo, y Alejandro Salinger. 2005. ‚ÄúExperimental analysis of a fast intersection algorithm for sorted sequences‚Äù. En International Symposium on String Processing and Information Retrieval, 13‚Äì24. Springer.\n\n\nBarbay, J√©r√©my, y Claire Kenyon. 2002. ‚ÄúAdaptive intersection and t-threshold problems‚Äù. En Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms, 390‚Äì99. SODA ‚Äô02. USA: Society for Industrial; Applied Mathematics.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, y Tyler Lu. 2006. ‚ÄúFaster adaptive set intersections for text searching‚Äù. En Experimental Algorithms: 5th International Workshop, WEA 2006, Cala Galdana, Menorca, Spain, May 24-27, 2006. Proceedings 5, 146‚Äì57. Springer.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, Tyler Lu, y Alejandro Salinger. 2010. ‚ÄúAn experimental investigation of set intersection algorithms for text searching‚Äù. Journal of Experimental Algorithmics (JEA) 14: 3‚Äì7.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, y J Ian Munro. 2001. ‚ÄúExperiments on adaptive set intersections for text retrieval systems‚Äù. En Algorithm Engineering and Experimentation: Third International Workshop, ALENEX 2001 Washington, DC, USA, January 5‚Äì6, 2001 Revised Papers 3, 91‚Äì104. Springer.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, y J Ian Munro. 2000. ‚ÄúAdaptive set intersections, unions, and differences‚Äù. En Proceedings of the eleventh annual ACM-SIAM symposium on Discrete algorithms, 743‚Äì52.\n\n\nHwang, Frank K., y Shen Lin. 1971. ‚ÄúOptimal merging of 2 elements with n elements‚Äù. Acta Informatica 1 (2): 145‚Äì58.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n de conjuntos con representaci√≥n de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "refs.html",
    "href": "refs.html",
    "title": "References",
    "section": "",
    "text": "Baeza-Yates, Ricardo. 2004. ‚ÄúA Fast Set Intersection Algorithm for\nSorted Sequences.‚Äù In Combinatorial Pattern Matching: 15th\nAnnual Symposium, CPM 2004, Istanbul, Turkey, July 5-7, 2004.\nProceedings 15, 400‚Äì408. Springer.\n\n\nBaeza-Yates, Ricardo, and Alejandro Salinger. 2005. ‚ÄúExperimental\nAnalysis of a Fast Intersection Algorithm for Sorted Sequences.‚Äù\nIn International Symposium on String Processing and Information\nRetrieval, 13‚Äì24. Springer.\n\n\nBarbay, J√©r√©my, and Claire Kenyon. 2002. ‚ÄúAdaptive Intersection\nand t-Threshold Problems.‚Äù In Proceedings of the Thirteenth\nAnnual ACM-SIAM Symposium on Discrete Algorithms, 390‚Äì99. SODA ‚Äô02.\nUSA: Society for Industrial; Applied Mathematics.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, and Tyler Lu. 2006. ‚ÄúFaster\nAdaptive Set Intersections for Text Searching.‚Äù In\nExperimental Algorithms: 5th International Workshop, WEA 2006, Cala\nGaldana, Menorca, Spain, May 24-27, 2006. Proceedings 5, 146‚Äì57.\nSpringer.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, Tyler Lu, and Alejandro Salinger.\n2010. ‚ÄúAn Experimental Investigation of Set Intersection\nAlgorithms for Text Searching.‚Äù Journal of Experimental\nAlgorithmics (JEA) 14: 3‚Äì7.\n\n\nBentley, Jon L., and Catherine C. McGeoch. 1985. ‚ÄúAmortized\nAnalyses of Self-Organizing Sequential Search Heuristics.‚Äù\nCommun. ACM 28 (4): 404‚Äì11. https://doi.org/10.1145/3341.3349.\n\n\nBentley, Jon Louis, and Andrew Chi-Chih Yao. 1976. ‚ÄúAn Almost\nOptimal Algorithm for Unbounded Searching.‚Äù Information\nProcessing Letters 5 (3): 82‚Äì87. https://doi.org/https://doi.org/10.1016/0020-0190(76)90071-5.\n\n\nCook, Curtis R, and Do Jin Kim. 1980. ‚ÄúBest Sorting Algorithm for\nNearly Sorted Lists.‚Äù Communications of the ACM 23 (11):\n620‚Äì24.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, and Clifford\nStein. 2022. Introduction to Algorithms. MIT press.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, and J Ian Munro. 2001.\n‚ÄúExperiments on Adaptive Set Intersections for Text Retrieval\nSystems.‚Äù In Algorithm Engineering and Experimentation: Third\nInternational Workshop, ALENEX 2001 Washington, DC, USA, January 5‚Äì6,\n2001 Revised Papers 3, 91‚Äì104. Springer.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, and J Ian Munro. 2000.\n‚ÄúAdaptive Set Intersections, Unions, and Differences.‚Äù In\nProceedings of the Eleventh Annual ACM-SIAM Symposium on Discrete\nAlgorithms, 743‚Äì52.\n\n\nEstivill-Castro, Vladmir, and Derick Wood. 1992. ‚ÄúA Survey of\nAdaptive Sorting Algorithms.‚Äù ACM Computing Surveys\n(CSUR) 24 (4): 441‚Äì76.\n\n\nHwang, Frank K., and Shen Lin. 1971. ‚ÄúOptimal Merging of 2\nElements with n Elements.‚Äù Acta Informatica 1 (2):\n145‚Äì58.\n\n\nKnuth, Donald. 1998. The Art of Computer Programming, Vol. 3 (2nd\nEd): Sorting and Searching. Vol. 3. Redwood City, CA, USA.: Addison\nWesley Longman Publishing Co. Inc.\n\n\nLoeser, Rudolf. 1974. ‚ÄúSome Performance Tests of\n‚ÄòQuicksort‚Äô and Descendants.‚Äù Communications of\nthe ACM 17 (3): 143‚Äì52.\n\n\nPugh, William. 1990. ‚ÄúSkip Lists: A Probabilistic Alternative to\nBalanced Trees.‚Äù Commun. ACM 33 (6): 668‚Äì76. https://doi.org/10.1145/78973.78977.\n\n\nScott, Jennifer, and Miroslav T≈Øma. 2023. ‚ÄúAn Introduction to\nSparse Matrices.‚Äù In Algorithms for Sparse Linear\nSystems, 1‚Äì18. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-25820-6_1.\n\n\nSedgewick, Robert. 1998. Algorithms in c++, Parts 1-4: Fundamentals,\nData Structure, Sorting, Searching. Addison-Wesley-Longman, 1998.",
    "crumbs": [
      "References"
    ]
  }
]