[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curso Introductorio al Análisis de Algoritmos con Julia",
    "section": "",
    "text": "Prefacio\nEl Análisis de algoritmos es una disciplina formativa enfocada en el desempeño de los algoritmos bajo una cierta entrada. Su estudio nos permite identificar el problema algorítmico subyacente dentro de problemas reales, y por tanto, ser capaces de seleccionar, adaptar o construir una solución eficiente y eficaz para dicho problema. Una solución adecuada sobre una ingenua nos permite mejorar de manera significativa los recursos computacionales, que pueden llevar a reducción de costos de operación en un sistema o la posibilidad de procesar grandes cantidades de información de manera más eficiente.\nEl diseño, implementación y análisis de algoritmos es fundamental para formar el criterio del científico de datos. Los conocimientos adquiridos servirán para obtener las herramientas y la intuición necesaria para plantear la solución a un problema basado en un modelo de cómputo y resolverlo de manera eficiente y escalable cuando sea posible.\nA lo largo de los temas se abordarán los algoritmos y estructuras de manera teórica y práctica, y se motivará al estudiante a realizar sus propias implementaciones. Al terminar este curso, se pretende que el alumno sea competente para seleccionar, diseñar, implementar y analizar algoritmos sobre secuencias, conjuntos y estructuras de datos para resolver problemas optimizando los recursos disponibles, en particular, memoria y tiempo de cómputo. Durante el curso se estudiaran problemas y algoritmos simples, que suelen formar parte de algoritmos más complejos, y por lo tanto, si somos capaces de seleccionar adecuadamente estos bloques más simples, afectaremos directamente el desempeño de los sistemas.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#contenido-del-libro",
    "href": "index.html#contenido-del-libro",
    "title": "Curso Introductorio al Análisis de Algoritmos con Julia",
    "section": "Contenido del libro",
    "text": "Contenido del libro\nEste libro esta diseñado para ser impartido en un semestre de licenciatura o maestría con un enfoque experimental, de Ingeniería en Computación o Ciencias de la Computación, así como Ciencia de Datos. Los algoritmos que se van develando desentrañan los algoritmos clásicos de Recuperación de Información, algoritmos detrás de grandes máquinas de búsqueda, sistemas de información basados en similitud, retrieval augmented generation (RAG), así como de los métodos detrás de la aceleración de otras técnicas de análisis de datos como agrupamiento y reducción de dimensión no-lineal.\n\nEl Cap. 1  Julia como lenguaje de programación para un curso de algoritmos se dedica a revisar el lenguaje de programación Julia, desde un punto de vista de alguien que podría no conocer el lenguaje, pero que definitivamente sabe programar y esta familiarizado con los conceptos generales de un lenguaje de programación moderno.\nEl Cap. 2  Introducción al análisis de algoritmos con Julia introduce los conceptos de análisis asintótico y compara ordenes de crecimiento con la idea de formar intuición.\nEn el Cap. 3  Estructuras de datos elementales nos encontramos con las estructuras de datos elementales como son las estructuras de datos lineales y de acceso aleatorio, y su organización en memoria.\nEl Cap. 4  Algoritmos de ordenamiento esta dedicado a algoritmos de ordenamiento en el modelo de comparación, estudia algoritmos tanto de peor caso como aquellos que toman ventaja de la distribución de entrada.\nEn el Cap. 5  Algoritmos de búsqueda en el modelo de comparación abordamos algoritmos de búsqueda en arreglos ordenados en el modelo de comparación. De nueva cuenta se abordan algoritmos de peor caso y algoritmos que pueden sacar ventaja de instancias fáciles.\nFinalmente, el Cap. 6  Algoritmos de intersección de conjuntos con representación de listas ordenadas estudia algoritmos de intersección de conjuntos, los cuales son la base de sistemas de información capaces de manipular cantidades enormes de datos.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#trabajo-en-progreso",
    "href": "index.html#trabajo-en-progreso",
    "title": "Curso Introductorio al Análisis de Algoritmos con Julia",
    "section": "Trabajo en progreso",
    "text": "Trabajo en progreso\nEste libro es un trabajo en progreso, que se pretende términar durante el primer semestre de 2025, mientras se imparte el curso Análisis de algoritmos en la Maestría en Ciencia de Datos e Información de INFOTEC, México. El perfil de ingreso de la maestría es multidisciplinario, y esto es parte esencial del diseño de este libro.\nEn particular, los capítulos 1, 2, y 3 tienen un avance significativo, aunque no estan terminados. El resto de los capítulos ese encuentran en un estado incipiente.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Curso Introductorio al Análisis de Algoritmos con Julia",
    "section": "Licencia",
    "text": "Licencia\n\nEsta obra está bajo una Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "cap1-julia.html",
    "href": "cap1-julia.html",
    "title": "1  Julia como lenguaje de programación para un curso de algoritmos",
    "section": "",
    "text": "1.1 El lenguaje de programación Julia\nNuestro objetivo trabajar sobre algoritmos, por lo que cualquier lenguaje que pueda expresar todo lo computable, puede ser adecuado. Pero dado que nuestro enfoque será experimental, y nuestra metodología incluye medir la factibilidad y desempeño de cada algoritmo en términos reales, entonces necesitamos un lenguaje donde las instrucciones, los acceso a memoria, y la manipulación de la misma sea controlable. En este caso, y mediando con la fácilidad de aprendizaje y la productividad, este curso utiliza el lenguaje de programación Julia.1 Pero no hay porque preocuparse por aprender un nuevo lenguaje, el curso utiliza ejemplos en Julia y utiliza una variante de su sintaxis como pseudo-código, pero las actividades se esperan tanto en Julia como en Python.\nAmbos lenguajes de programación son fáciles de aprender y altamente productivos. Python es un lenguaje excelente para realizar prototipos, o para cuando existen bibliotecas que resuelvan el problema que se este enfrentando. Por otro lado, cuando se necesita control sobre las operaciones que se estan ejecutando, o la memoria que se aloja, Python no es un lenguaje que nos permita trabajar en ese sentido. Julia esta diseñado para ser veloz y a la vez mantener el dinámismo que se espera de un lenguaje moderno, adicionalmente, es posible conocer los tipos de instrucciones que realmente se ejecutan, así como también es posible controlar la alojación de memoria, ya se mediante la utilización de patrones que así nos lo permitan, o mediante instrucciones que nos lo aseguren.\nEste curso esta escrito en Quarto, y se esperan reportes de de tareas y actividades tanto en Quarto https://quarto.org como en Jupyter https://jupyter.org/. La mayoría de los ejemplos estarán empotrados en el sitio, y en principio, deberían poder replicarse copiando, pegando, y ejecutando en una terminal de Julia.\nEs importante clarificar que este capítulo introducirá el lenguaje de programación Julia hasta el nivel que se requiere en este curso, ignorando una gran cantidad de capacidades que no son de interés para nuestro curso. Se recomienda al alumno interesado la revisión del manual y la documentación oficial para un estudio más profundo del lenguaje.\nJulia es un lenguaje singular, es un lenguaje dinámico y de alto nivel, tiene de tipado fuerte y compila a código máquina para cada una de las instrucciones que se dan. Su interfaz más común es un REPL o , esto es que puede ser utilizado de manera interactiva, además de la ejecución en scripts o notebooks como los que estaremos usando para reportar.\nEs homoicónico, que significa que la manera en que se representan sus programas coincide con las estructuras de datos básicas, lo cual permite crear programas validos mediante programas. De manera práctica, también le permite la reescritura de los programas utilizando otro programa utilizando macros, los cuales son funciones que modifican el código y empiezan con el simbolo @. Estaremos viendo una serie de macros con propósitos muy específicos, crear macros y la manipulación automática de código cae fuera de nuestro curso.\nEl lenguaje tiene estructuras de datos básicas como rangos, vistas, tuplas, arreglos, estructuras, diccionarios, conjuntos, cadenas de caracteres, así como expresiones de código como datos y controla la ejecución mediante condicionales, ciclos y funciones. Tiene un sistema de tipos de datos muy poderoso, que le permite entre otras cosas generar código específico para dichos tipos. El código se organiza en scripts, y a nivel lógico en módulos y paquetes. Una de sus características importantes el despacho múltiple en las funciones, esto es, que para cada conjunto de tipos de argumentos, compilará una función especializada. Este patrón puede ser muy poderoso para escribir código genérico que pueda ser muy eficiente, a costa de múltiples códigos de máquina para una función. Esta estrategía también viene con el problema que la primera vez que se ejecuta una función con un conjunto específico de tipos de argumentos, dicha función será especializada y compilada, lo cual puede representar un costo inicial importante en algunos casos donde no se pretenda procesar grandes cantidades de información. En particular, este problema se ha venido reduciendo en las versiones más nuevas de Julia haciendo uso una estrategía de precompilación para datos típicos.\nEntre los tipos de datos es capaz de manera enteros y números de punto flotante de diferentes precisiones, caracteres, cadenas de caracteres, y simbolos. Los arreglos son realmente importantes en Julia, y soportan de manera nativa vectores, matrices y tensores, estaremos tocando apenas esta parte del lenguaje. El resto de esta unidad esta dedicada a precisar la sintaxis del lenguaje y anotaciones de importancia sobre su funcionamiento, y en particular, en el manejo que nos permitirá generar código eficiente que limite el alojamiento de memoria.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Julia como lenguaje de programación para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#el-lenguaje-de-programación-julia",
    "href": "cap1-julia.html#el-lenguaje-de-programación-julia",
    "title": "1  Julia como lenguaje de programación para un curso de algoritmos",
    "section": "",
    "text": "1.1.1 Funciones\nLas funciones son centrales en Julia, y son definidas mediante la sintaxis\n```{julia}\n1function fun(arg1, arg2...)\n    # ... expresiones ...\nend\n\n2function fun(arg1, arg2...; kwarg1=valor1, kwargs2...)\n    # ... expresiones ...\nend\n\n3fun(arg1, arg2...; kwarg1=valor1, kwargs2...) = expresion\n\n4(arg1, arg2...; kwarg1=valor1, kwargs2...) -&gt; expresion\n\n5fun() do x\n    x^2 # ... expresiones ...\nend\n```\n\n1\n\nDefinición de una función simple, los tipos de los argumentos se utilizan para generar múltiples versiones de una función.\n\n2\n\nTambién se soportan argumentos nombrados, los cuales van después de ;, se debe tener en cuenta que los tipos de los argumentos nombrados no son utilizados para determinar si una función debe compilarse. Los argumentos nombrados pueden o no tener valores por omisión.\n\n3\n\nSi la función tiene una estructura simple, de una expresión, es posible ignorar function y end, usando ‘=’ para definirla.\n\n4\n\nMuchas veces es útil definir funciones anónimas, que suelen pasarse a otras funciones de orden superior.\n\n5\n\nUn embellecedor útil para generar una función anónima (definida entre do...end) que se pasa como primer argumento a fun, e.g., es equivalente a fun(x-&gt;x^2).\n\n\nEl ámbito o scope de las variables en Julia es sintáctico, que significa que se hereda del código donde las funciones fueron definidas, y no dinámico (que se hereda desde dónde se ejecuta la función). Aunque es el comportamiento de la mayoría de los lenguajes modernos, es importante conocerlo sobre todo para la creación de cerraduras sintácticas en funciones.\nUna función se ejecuta con la sintaxis nombre(arg1...). Conviene profundizar en las expresiones y demás componentes del lenguaje antes del ir a más ejemplos sobre funciones.\n\n\n1.1.2 Hola mundo\nUno de los programas más comunes es el siguiente\n\nprintln(\"¡Hola 🌎!\")\n\n¡Hola 🌎!\n\n\n\n\n1.1.3 Expresiones y operadores\nLas expresiones son la forma más genérica de expresar el código en Julia, comprenden operaciones aritméticas, asignación y declaración de variables, definiciones de bloques de código, llamadas de funciones, entre otras.\nCada linea suele ser una expresión, a menos que se extienda por múltiples lineas por medio de un agrupador de código o datos, estos pueden ser begin...end, let...end, (...), [...], [...], for...end, while...end, if...end, function...end, try...end, entre las más utilizadas.\nLas definiciones de variables tienen la sintaxis variable = valor; las variables comunmente comienzan con una letra o _, las letras pueden ser caracteres unicode, no deben contener espacios ni puntuaciones como parte del nombre; valor es el resultado de evaluar o ejecutar una expresión.\nLos operadores más comunes son los aritméticos +, -, *, /, ÷, %, \\, ^, con precedencia y significado típico. Existen maneras compuestas de modificar una variable anteponiendo el operador aritmético al simbolo de asignación, e.g., variable += valor, que se expande a variable = variable + valor. Esto implica que variable debe estar previamente definida previo a la ejecución.\nLos operadores lógicos también tienen el significado esperado.\n\n\n\noperación\ndescripción\n\n\n\n\na && b\nAND lógico\n\n\na || b\nOR lógico\n\n\na ⊻ b\nXOR lógico\n\n\n!a\nnegación lógica\n\n\na &lt; b\ncomparación a es menor que b\n\n\na &gt; b\ncomparación a es mayor que b\n\n\na &lt;= b\ncomparación a es menor o igual que b\n\n\na &gt;= b\ncomparación a es mayor o igual que b\n\n\na == b\ncomparación de igualdad\n\n\na === b\ncomparación de igualdad (a nivel de tipo)\n\n\na != b\ncomparación de desigualdad\n\n\na !== b\ncomparación de desigualdad (a nivel de tipo)\n\n\n\nEn particular && y || implementan corto circuito de código, por lo que pueden usarse para el control de que operaciones se ejecutan. Cuando se compara a nivel de tipo 0 (entero) será diferente de 0.0 (real).\nTambién hay operadores lógicos a nivel de bit, los argumentos son enteros.\n\n\n\noperación\ndescripción\n\n\n\n\na & b\nAND a nivel de bits\n\n\na | b\nOR a nivel de bits\n\n\na ⊻ b\nXOR a nivel del bits\n\n\n~a\nnegación lógica a nivel de bits\n\n\n\n\n\n1.1.4 Literales\nDado que existen múltiples tipos de datos existen diferentes formas de definirlas; una de ellas, probablemente la que más estaremos usando son los literales, es decir, escribir los datos directamente en el código.\nLos números enteros se definen sin punto decimal, es posible usar _ como separador y dar más claridad al código. Los enteros pueden tener 8, 16, 32, o 64 bits; por omisión, se empaquetan en variables del tipo Int (Int64). Los valores hexadecimales se interpretan como enteros sin signo, y además se empaquetan al número de bits necesario minimo para contener. El comportamiento para valores en base 10 es el de hexadecimal es congruente con un lenguaje para programación de sistemas.\n\na = 100\nprintln((a, sizeof(a)))\nb = Int8(100)\nprintln((b, sizeof(b)))\nc = 30_000_000\nprintln((c, sizeof(c)))\nd = 0xffff\nprintln((d, sizeof(d)))\n\n(100, 8)\n(100, 1)\n(30000000, 8)\n(0xffff, 2)\n\n\n\n\nExisten números enteros de precisión 128 pero las operaciones al día de hoy no son implementadas de manera nativa por los procesadores; así mismo se reconocen números de punto flotante de precisión media Float16 pero la mayoría de los procesadores no tienen soporte nativo para realizar operaciones con ellos, aunque los procesadores de última generación si lo tienen.\nSi la precisión esta en duda o el contexto lo amérita, deberá especificarlo usando el constructor del tipo e.g., Int8(100), UInt8(100), Int16(100), UInt16(100), Int32(100), UInt32(100), Int64(100), UInt64(100).\nLos números de punto flotante tienen diferentes formas de definirse, teniendo diferentes efectos. Para números de precision simple, 32 bits, se definen con el sufijo f0 como 3f0. El sufijo e0 también se puede usar para definir precisión doble (64 bit). El cero del sufijo en realidad tiene el objetivo de colocar el punto decimal, en notación de ingeniería, e.g., \\(0.003\\) se define como \\(3f-3\\) o \\(3e-3\\), dependiendo del tipo de dato que se necesite. Si se omite sufijo y se pone solo punto decimal entonces se interpretará como precision doble. Los tipos son Float32 y Float64.\nLos datos booleanos se indican mediante true y false para verdadero y falso, respectivamente.\nLos caracteres son símbolos para índicar cadenas, se suelen representar como enteros pequeños en memoria. Se especifican con comillas simples 'a', 'z', '!' y soporta simbolos unicode '🤠'.\nLas cadenas de caracteres son la manera de representar textos como datos, se guardan en zonas contiguas de memoria. Se especifican con comillas dobles y también soportan símbolos unicode, e.g., \"hola mundo\", \"pato es un 🐷\".\n\n\nJulia guarda los simbolos de manera especial y pueden ser utilizados para realizar identificación de datos eficiente, sin embargo, no es buena idea saturar el sistema de manejo de símbolos por ejemplo para crear un vocabulario ya que no liberará la memoria después de definirlos ya que es un mecánismo diseñado para la representación de los programas, pero lo suficientemente robusto y bien definido para usarse en el diseño e implementación de programas de los usuarios.\nEn Julia existe la noción de símbolo, que es una cadena que además solo existe en una posición en memoria se usa el prefijo : para denotarlos.\n\nprintln(:hola === :hola)\nprintln(typeof(:hola))\nprintln(Symbol(\"hola mundo\"))\n\ntrue\nSymbol\nhola mundo\n\n\n\n\n1.1.5 Control de flujo\nEl control de flujo nos permite escoger que partes del código se ejecutaran como consecuencia de la evaluación de una expresión, esto incluye repeticiones.\nLas condicionales son el control de flujo más simple.\n\na = 10\n1if a % 2 == 0\n2    \"par\"\nelse\n3    \"impar\"\nend\n\n\n1\n\nExpresión condicional.\n\n2\n\nExpresión a ejecutarse si (1) es verdadero.\n\n3\n\nExpresión a evaluarse si (1) es falso.\n\n\n\n\n\"par\"\n\n\nSe puede ignorar la clausula else dando solo la opción de evaluar (2) si (1) es verdadero. Finalmente, note que la condicional es una expresión y devuelve un valor.\n\na = 10\nif log10(a) == 1\n    \"es 10\"\nend\n\n\"es 10\"\n\n\nTambién pueden concatenarse múltiples expresiones condicionales con elseif como se muestra a continuación.\n\na = 9\nif a % 2 == 0\n    println(\"divisible entre 2\")\nelseif a % 3 == 0\n    println(\"divisible entre 3\")\nelse\n    println(\"no divisible entre 2 y 3\")\nend\n\ndivisible entre 3\n\n\nEs común utilizar la sintaxis en Julia (short circuit) para control de flujo:\n\na = 9\n\n1println(a % 2 == 0 && \"es divisible entre dos\")\n2println(a % 3 == 0 && \"es divisible entre tres\")\n\n\n1\n\nEl resultado de la condición es falso, por lo que no se ejecutará la siguiente expresión.\n\n2\n\nEl resultado es verdadero, por lo que se ejecutará la segunda expresión.\n\n\n\n\nfalse\nes divisible entre tres\n\n\nFnalmente, existe una condicional de tres vias expresion ? expr-verdadero : expr-falso\n\na = 9\n\nprintln(a % 2 == 0 ? \"es divisible entre dos\" : \"no es divisible entre dos\")\nprintln(a % 3 == 0 ? \"es divisible entre tres\" : \"no es divisible entre tres\")\n\nno es divisible entre dos\nes divisible entre tres\n\n\n\n1.1.5.1 Ciclos\nLos ciclos son expresiones de control de flujo que nos permiten iterar sobre una colección o repetir un código hasta que se cumpla alguna condición. En Julia existen dos expresiones de ciclos:\n\nfor x in colección ...expresiones... end y\nwhile condición ...expresioens... end\n\nEn el caso de for, la idea es iterar sobre una colección, esta colección puede ser un rango, i.e., inicio:fin, inicio:paso:fin, o una colección como las tuplas, los arreglos, o cualquiera que cumpla con la interfaz de colección iterable del lenguaje.\n\nfor i in 1:5\n    println(\"1er ciclo: \", i =&gt; i^2)\nend\n\nfor i in [10, 20, 30, 40, 50]\n    println(\"2do ciclo: \", i =&gt; i/10)\nend\n\n1er ciclo: 1 =&gt; 1\n1er ciclo: 2 =&gt; 4\n1er ciclo: 3 =&gt; 9\n1er ciclo: 4 =&gt; 16\n1er ciclo: 5 =&gt; 25\n2do ciclo: 10 =&gt; 1.0\n2do ciclo: 20 =&gt; 2.0\n2do ciclo: 30 =&gt; 3.0\n2do ciclo: 40 =&gt; 4.0\n2do ciclo: 50 =&gt; 5.0\n\n\nAl igual que en otros lenguajes modernos, se define la variante completa o comprehensive for que se utiliza para transformar la colección de entrada en otra colección cuya sintaxis se ejemplifica a continuación:\n\na = [i =&gt; i^2 for i in 1:5]\nprintln(a)\n\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nTambién es posible definir un generador, esto es, un código que puede generar los datos, pero que no los generará hasta que se les solicite.\n\na = (i =&gt; i^2 for i in 1:5)\nprintln(a)\nprintln(collect(a))\n\nBase.Generator{UnitRange{Int64}, var\"#3#4\"}(var\"#3#4\"(), 1:5)\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nOtra forma de hacer ciclos de intrucciones es repetir mientras se cumpla una condición:\n\ni = 0\nwhile i &lt; 5\n    i += 1\n    println(i)\nend\n\ni\n\n1\n2\n3\n4\n5\n\n\n5\n\n\n\n\n\n1.1.6 Tuplas y arreglos en Julia\nUna tupla es un conjunto ordenado de datos que no se puede modificar y que se desea esten contiguos en memoria, la sintaxis en memoria es como sigue:\n\n1a = (2, 3, 5, 7)\nb = (10, 20.0, 30f0)\nc = 100 =&gt; 200\n2println(typeof(a))\nprintln(typeof(b))\nprintln(typeof(c))\n3a[1], a[end], b[3], c.first, c.second\n\n\n1\n\nDefine las tuplas.\n\n2\n\nImprime los tipos de las tuplas.\n\n3\n\nMuestra como se accede a los elementos de las tuplas. Julia indexa comenzando desde 1, y el término end también se utiliza para indicar el último elemento en una colección ordenada.\n\n\n\n\nNTuple{4, Int64}\nTuple{Int64, Float64, Float32}\nPair{Int64, Int64}\n\n\n(2, 7, 30.0f0, 100, 200)\n\n\nLa misma sintaxis puede generar diferentes tipos de tuplas. En el caso NTuple{4, Int4} nos indica que el tipo maneja cuatro elementos de enteros de 64 bits, los argumentos entre {} son parametros que especifican los tipos en cuestión. En el caso de Tuple se pueden tener diferentes tipos de elementos. La tupla Pair es especial ya que solo puede contener dos elementos y es básicamente para embellecer o simplificar las expresiones; incluso se crea con la sintaxis key =&gt; value y sus elementos pueden accederse mediante dos campos nombrados.\nLos arreglos son datos del mismo tipo contiguos en memoria, a diferencia de las tuplas, los elementos se pueden modificar, incluso pueden crecer o reducirse. Esto puede implicar que se alojan en zonas de memoria diferente (las tuplas se colocan en el stack y los arreglos en el heap, ver la siguiente unidad para más información). Desde un alto nivel, los arreglos en Julia suelen estar asociados con vectores, matrices y tensores, y un arsenal de funciones relacionadas se encuentran definidas en el paquete LinearAlgebra, lo cual esta más allá del alcance de este curso.\n\n1a = [2, 3, 5, 7]\nb = [10, 20.0, 30f0]\n2println(typeof(a))\nprintln(typeof(b))\n3a[1], a[end], b[3], b[2:3]\n\n\n1\n\nDefine los arreglos a y b.\n\n2\n\nMuestra los tipos de los arreglos, note como los tipos se promueven al tipo más génerico que contiene la definición de los datos.\n\n3\n\nEl acceso es muy similar a las tuplas para arreglos unidimensionales, note que es posible acceder rangos de elementos con la sintaxis ini:fin.\n\n\n\n\nVector{Int64}\nVector{Float64}\n\n\n(2, 7, 30.0, [20.0, 30.0])\n\n\n\na = [2 3;\n1     5 7]\n2display(a)\n3display(a[:, 1])\n4display(a[1, :])\n\n\n1\n\nDefinición de un arreglo bidimensional, note como se ignora la coma , en favor de la escritura por filas separadas por ;.\n\n2\n\nLa variable a es una matriz de 2x2.\n\n3\n\nEs posible acceder una columna completa usando el símbolo : para indicar todos los elementos.\n\n4\n\nDe igual forma, es posible acceder una fila completa.\n\n\n\n\n2×2 Matrix{Int64}:\n 2  3\n 5  7\n\n\n2-element Vector{Int64}:\n 2\n 5\n\n\n2-element Vector{Int64}:\n 2\n 3\n\n\n\n\n1.1.7 Diccionarios y conjuntos en Julia\nUn diccionario es un arreglo asociativo, i.e., guarda pares llave-valor. Permite acceder de manera eficiciente al valor por medio de la llave, así como también verificar si hay una entrada dentro del diccionario con una llave dada. La sintaxis es como sigue:\n\n1a = Dict(:a =&gt; 1, :b =&gt; 2, :c =&gt; 3)\n2a[:b] = 20\nprintln(a)\n3a[:d] = 4\nprintln(a)\n4delete!(a, :a)\na\n\n\n1\n\nDefinición del diccionario a que mapea simbolos a enteros.\n\n2\n\nCambia el valor de :b por 20.\n\n3\n\nAñade :d =&gt; 4 al diccionario a.\n\n4\n\nBorra el par con llave :a.\n\n\n\n\nDict(:a =&gt; 1, :b =&gt; 20, :c =&gt; 3)\nDict(:a =&gt; 1, :b =&gt; 20, :d =&gt; 4, :c =&gt; 3)\n\n\nDict{Symbol, Int64} with 3 entries:\n  :b =&gt; 20\n  :d =&gt; 4\n  :c =&gt; 3\n\n\nEs posible utilizar diferentes tipos siempre y cuando el tipo en cuestión defina de manera correcta la función hash sobre la llave y la verificación de igualdad ==.\nUn conjunto se representa con el tipo Set, se implementa de manera muy similar al diccionario pero solo necesita el elemento (e.g., la llave). Como conjunto implementa las operaciones clasificación de operaciones de conjuntos\n\n1a = Set([10, 20, 30, 40])\n2println(20 in a)\n3push!(a, 50)\nprintln(a)\n4delete!(a, 10)\nprintln(a)\n5println(intersect(a, [20, 35]))\n6union!(a, [100, 200])\nprintln(a)\n\n\n1\n\nDefinición del conjunto de números enteros.\n\n2\n\nVerificación de membresia al conjunto a.\n\n3\n\nAñade 50 al conjunto.\n\n4\n\nSe borra el elemento 10 del conjunto.\n\n5\n\nIntersección de a con una colección, no se modifica el conjunto a.\n\n6\n\nUnión con otra colección, se modifica a.\n\n\n\n\ntrue\nSet([50, 20, 10, 30, 40])\nSet([50, 20, 30, 40])\nSet([20])\nSet([50, 200, 20, 30, 40, 100])",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Julia como lenguaje de programación para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#el-flujo-de-compilación-de-julia",
    "href": "cap1-julia.html#el-flujo-de-compilación-de-julia",
    "title": "1  Julia como lenguaje de programación para un curso de algoritmos",
    "section": "1.2 El flujo de compilación de Julia",
    "text": "1.2 El flujo de compilación de Julia\nBasta con escribir una linea de código en el REPL de Julia y esta se compilará y ejecutará en el contexto actual, usando el ámbito de variables. Esto es conveniente para comenzar a trabajar, sin embargo, es importante conocer el flujo de compilación para tenerlo en cuenta mientras se códifica, y así generar código eficiente. En particular, la creación de funciones y evitar la inestabilidad de los tipos de las variables es un paso hacia la generación de código eficiente. También es importante evitar el alojamiento de memoria dinámica siempre que sea posible. A continuación se mostrará el análisis de un código simple a diferentes niveles, mostrando que el lenguaje nos permite observar la generación de código, que últimadamente nos da cierto control y nos permite verificar que lo que se esta implementando es lo que se específica en el código. Esto no es posible en lenguajes como Python.\n\nlet\n    e = 1.1\n    println(e*e)\n    @code_typed e*e\nend\n\n1.2100000000000002\n\n\nCodeInfo(\n1 ─ %1 = Base.mul_float(x, y)::Float64\n└──      return %1\n) =&gt; Float64\n\n\nEn este código, se utiliza la estructa de agrupación de expresiones let...end. Cada expresión puede estar compuesta de otras expresiones, y casi todo es una expresión en Julia. La mayoria de las expresiones serán finalizadas por un salto de linea, pero las compuestas como let, begin, function, if, while, for, do, module estarán finalizadas con end. La indentación no importa la indentación como en Python, pero es aconsejable para mantener la legibilidad del código. La linea 2 define e inicializa la variable e; la linea 3 llama a la función println, que imprimirá el resultado de e*e en la consola. La función println esta dentro de la biblioteca estándar de Julia y siempre esta visible. La linea 4 es un tanto diferente, es una macro que toma la expresión e*e y realiza algo sobre la expresión misma, en particular @code_type muestra como se reescribe la expresión para ser ejecutada. Note como se hará una llamada a la función Base.mul_float que recibe dos argumentos y que regresará un valor Float64. Esta información es necesaria para que Julia pueda generar un código veloz, el flujo de compilación llevaría esta información a generar un código intermedio de Low Level Virtual Machine (LLVM), que es el compilador empotrado en Julia, el cual estaría generando el siguiente código LLVM (usando la macro @code_llvm):\n\n\n;  @ float.jl:411 within `*`\ndefine double @\"julia_*_1779\"(double %0, double %1) #0 {\ntop:\n  %2 = fmul double %0, %1\n  ret double %2\n}\n\n\nEste código ya no es específico para Julia, sino para la maquinaría LLVM. Observe la especificidad de los tipos y lo corto del código. El flujo de compilación requeriría generar el código nativo, que puede ser observado a continuación mediante la macro @code_native:\n\n\n    .text\n    .file   \"*\"\n    .globl  \"julia_*_1818\"                  # -- Begin function julia_*_1818\n    .p2align    4, 0x90\n    .type   \"julia_*_1818\",@function\n\"julia_*_1818\":                         # @\"julia_*_1818\"\n; ┌ @ float.jl:411 within `*`\n# %bb.0:                                # %top\n    push    rbp\n    mov rbp, rsp\n    vmulsd  xmm0, xmm0, xmm1\n    pop rbp\n    ret\n.Lfunc_end0:\n    .size   \"julia_*_1818\", .Lfunc_end0-\"julia_*_1818\"\n; └\n                                        # -- End function\n    .section    \".note.GNU-stack\",\"\",@progbits\n\n\nEn este caso podemos observar código específico para la computadora que esta generando este documento, es posible ver el manejo de registros y el uso de instrucciones del CPU en cuestión.\nEste código puede ser eficiente dado que los tipos y las operaciones son conocidos, en el caso que esto no puede ser, la eficiencia esta perdida. Datos no nativos o la imposibilidad de determinar un tipo causarían que se generará más código nativo que terminaría necesitanto más recursos del procesador. Una situación similar ocurre cuando se aloja memoria de manera dinámica. Siempre estaremos buscando que nuestro código pueda determinar el tipo de datos para que el código generado sea simple, si es posible usar datos nativos, además de no manejar o reducir el uso de memoría dinámica.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Julia como lenguaje de programación para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#ejemplos-de-funciones",
    "href": "cap1-julia.html#ejemplos-de-funciones",
    "title": "1  Julia como lenguaje de programación para un curso de algoritmos",
    "section": "1.3 Ejemplos de funciones",
    "text": "1.3 Ejemplos de funciones\nLas funciones serán una parte central de nuestros ejemplos, por lo que vale la pena retomarlas y dar ejemplos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Julia como lenguaje de programación para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#recursos-para-aprender-python-y-julia",
    "href": "cap1-julia.html#recursos-para-aprender-python-y-julia",
    "title": "1  Julia como lenguaje de programación para un curso de algoritmos",
    "section": "1.4 Recursos para aprender Python y Julia",
    "text": "1.4 Recursos para aprender Python y Julia\n\n1.4.1 Python\n\nPython, se recomieda utilizar la distribución de https://www.anaconda.com/download/\nDocumentación oficial, comenzar por el tutorial https://docs.python.org/3/\nDocumentación oficial https://docs.julialang.org/en/stable/\n\n\n\n1.4.2 Julia\n\nInformación sobre como instalar Julia y flujos de trabajo simples (e.g., REPL, editores, etc.) para trabajar con este lenguaje de programación: Modern Julia Workflows https://modernjuliaworkflows.github.io/.\nLibro sobre julia Think Julia: How to Think Like a Computer Scientist https://benlauwens.github.io/ThinkJulia.jl/latest/book.html.\nCurso Introduction to computational thinking https://computationalthinking.mit.edu/Fall20/",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Julia como lenguaje de programación para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#licencia",
    "href": "cap1-julia.html#licencia",
    "title": "1  Julia como lenguaje de programación para un curso de algoritmos",
    "section": "1.5 Licencia",
    "text": "1.5 Licencia\n\nEsta obra está bajo una Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Julia como lenguaje de programación para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#footnotes",
    "href": "cap1-julia.html#footnotes",
    "title": "1  Julia como lenguaje de programación para un curso de algoritmos",
    "section": "",
    "text": "Se recomienda utilizar la versión 1.10 o superior, y puede obtenerse en https://julialang.org/.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Julia como lenguaje de programación para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html",
    "href": "cap2-analisis.html",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "",
    "text": "2.1 Concepto de algoritmo y estructura de datos\nEste capítulo introduce los fundamentos de análisis de algoritmos. Se introduce el concepto de modelo de cómputo, se itroduce y se motiva la notación asintótica, ya que es el lenguaje común en el análisis de algoritmos. También se mostrarán algunos de los ordenes de crecimiento más representativos, que nos permitirán comparar algoritmos que resuelvan una tarea dada, así como permitirnos catalogarlos con respecto a los recursos de computo necesarios para ejecutarlos.\nLos algoritmos son especificaciones formales de los pasos u operaciones que deben aplicarse a un conjunto de entradas para resolver un problema, obteniendo una solución correcta a dicho problema. Establecen los fundamentos de la programación y de la manera en como se diseñan los programas de computadoras. Dependiendo del problema, pueden existir múltiples algoritmos que lo resuelvan, cada uno de ellos con sus diferentes particularidades. Así mismo, un problema suele estar conformado por una cantidad enorme de instancias de dicho problema, por ejemplo, para una lista de \\(n\\) números, existen \\(n!\\) formas de acomodarlos, de tal forma que puedan ser la entrada a un algoritmo cuya entrada sea una lista de números donde el orden es importante. En ocasiones, los problemas pueden tener infinitas de instancias. En este curso nos enfocaremos en problemas que pueden ser simplificados a una cantidad finita instancias.\nCada paso u operación en un algoritmo esta bien definido y puede ser aplicado o ejecutado para producir un resultado. A su vez, cada operación suele tener un costo, dependiente del módelo de computación. Conocer el número de operaciones necesarias para transformar la entrada en la salida esperada, i.e., resolver el problema, es de vital importancia para seleccionar el mejor algoritmo para dicho problema, o aun más, para instancias de dicho problema que cumplen con ciertas características.\nUna estructura de datos es una abstracción en memoria de entidades matemáticas y lógicas que nos permite organizar, almacenar y procesar datos en una computadora. El objetivo es que la información representada puede ser manipulada de manera eficiente en un contexto específico, además de simplificar la aplicación de operaciones para la aplicación de algoritmos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#modelos-de-cómputo",
    "href": "cap2-analisis.html#modelos-de-cómputo",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "2.2 Modelos de cómputo",
    "text": "2.2 Modelos de cómputo\nUn modelo de cómputo es una abstracción matemática de una computadora o marco de trabajo algorítmico que nos permite estudiar y medir los costos de los algoritmos funcionando en este modelo de tal forma que sea más simple que una computadora física real. Ejemplos de estos modelos son las máquinas de Turing, las funciones recursivas, el cálculo lambda, o la máquina de acceso aleatorio. Todas estos modelos son equivalentes en sus capacidades, pero sus diferentes planteamientos permiten enfocarse en diferentes aspectos de los problemas.\n\nLa máquina de Turing. Es un módelo creado por Alan Turing a principios del siglo XX; la idea es un dispositivo que podría ser implementada de manera mecánica si se tuvieran recursos infinitos; esta máquina puede leer y escribir en una cinta infinita una cantidad de símbolos predeterminada para cada problema siguiendo una serie de reglas simples sobre lo que lee y escribe, dichas reglas y la cienta, forman una máquina de estados y memoria, que pueden realizar cualquier cálculo si el tiempo no fuera un problema.\nFunciones recursivas. Se basa en funciones que trabajan sobre los números naturales y que definen en conjunto el espacio de funciones computables. Son una herramienta abstracta que permite a los teóricos de la lógica y computación establecer los límites de lo computable.\nCálculo lambda. Es un módelo creado por Alonzo Church y Stephen Kleene a principios del siglo XX, al igual que las funciones recursivas, se fundamenta en el uso de funciones y es una herramienta abstracta con própositos similares, sin embargo el cálculo lambda no se limita a recursiones, y se enfoca en diferentes reglas de reducción y composición de funciones, y es natural la inclusión de operadores de alto nivel, aunque estos mismos sean definidos mediante un esquema funcional.\nMáquina de acceso aleatorio (RAM). Es un módelo que describe una computadora con registros. Adiferencia de una computadora física, no tienen limitación en su capacidad, ni en la cantidad de registros ni en la precisión de los mismos. Cada registro puede ser identicado de manera única y su contenido leído y escrito mediante reglas o instrucciones formando un programa. En particular reconoce las diferencias entre registros de los programas y registros de datos, i.e., arquitectura harvard. Existe un número mínimo de instrucciones necesarias (i.e., incremento, decremento, poner a cero, copiar, salto condicional, parar) pero es común construir esquemas más complejos basados en estas primitivas. Se necesita un registro especial que indica el registro de programa siendo ejecutado. Los accesos a los registros tienen un tiempo constante a diferencia de otros esquemas; es el modelo más cercano a una implementación moderna de computadora.\n\n\nUna computadora moderna difiere de muchas formas de una máquina RAM. De entrada, las limitaciones físicas requieren memorias finitas y registros con valores mínimos y máximos. También se debe trabajar con una jerarquía de memoria con diferentes niveles, donde los niveles más rápidos también son los más escasos; por tanto, es importante sacar provecho de esta jerarquía siempre que sea posible. Las operaciones también tienen costos diferentes, dependiendo de su implementación a nivel de circuitería, así como también existe cierto nivel de paralelización que no esta presente en una máquina RAM, tanto a nivel de procesamiento de datos como lectura de datos y el programa, esto sin tener en cuenta la arquitecturas multitarea que ya es común en el equipo actual.\n\nEn este curso nos enfocaremos en especificaciones de alto nivel, donde los algoritmos pueden ser implementados en una computadora física, y estaremos contando operaciones de interés pensando en costos constantes en el acceso a memoria y en una selección de operaciones, al estilo de una máquina RAM.\nLa selección de operaciones de interés tiene el espíritu de simplificar el análisis, focalizando nuestros esfuerzos en operaciones que acumulan mayor costo y que capturan la dinámica del resto. Adicionalmente al conteo de operaciones nos interesa el desempeño de los algoritmos en tiempo real y en la cantidad de memoria consumida, por lo que se aboradará el costo realizando mediciones experimentales, contrastando con el análisis basado en conteo de operaciones siempre que sea posible.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#tipos-de-análisis",
    "href": "cap2-analisis.html#tipos-de-análisis",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "2.3 Tipos de análisis",
    "text": "2.3 Tipos de análisis\nLa pregunta inicial sería ¿qué nos interesa saber de un algoritmo que resuelve un problema? probablemente, lo primero sería saber si produce resultados correctos. Después, entre el conjunto de las alternativas que producen resultados correctos, es determinante obtener su desempeño para conocer cuál es más conveniente para resolver un problema.\nEn ese punto, es necesario reconocer que para un problema, existen diferentes instancias posibles, esto es el espacio de instancias del problema, y que cada una de ellas exigirían soluciones con diferentes costos para cada algoritmo. Por tanto existen diferentes tipos de análisis y algoritmos.\n\nAnálisis de mejor caso. Obtener el mínimo de resolver cualquier instancia posible, puede parecer poco útil desde el punto de vista de decisión para la selección de un algoritmo, pero puede ser muy útil para conocer un problema o un algoritmo.\nAnálisis de peor caso. Obtener el costo máximo necesario para resolver cualquier instancia posible del problema con un algoritmo, este es un costo que si nos puede apoyar en la decisión de selección de un algoritmo; sin embargo, en muchas ocasiones, puede ser poco informativo o innecesario ya que tal vez hay pocas instancias que realmente lo amériten.\nAnálisis promedio. Se enfoca en obtener un análisis promedio basado en la población de instancias del problema para un algoritmo dado.\nAnálisis amortizado. Se enfoca en análisis promedio pero para una secuencia de instancias.\nAnálisis adaptativo. Para un subconjunto bien caracterizado del espacio de instancias de un problema busca análizar los costos del algoritmo en cuestión. La caracterización suele estar en términos de una medida de complejidad para el problema; y la idea general es medir si un algoritmo es capaz de sacar provecho de instancias fáciles.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#notación-asintótica",
    "href": "cap2-analisis.html#notación-asintótica",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "2.4 Notación asintótica",
    "text": "2.4 Notación asintótica\nRealizar un conteo de operaciones y mediciones es un asunto complejo que requiere focalizar los esfuerzos. Para este fin, es posible contabilizar solo algunas operaciones de importancia, que se supondrían serían las más costosas o que de alguna manera capturan de manera más fiel la dinámica de costos.\nEl comportamiento asintótico es otra forma de simplificar y enfocarnos en los puntos de importancia, en este caso, cuando el tamaño de la entrada es realmente grande. Es importante mencionar, que no se esperan entradas de tamaño descomunal, ni tampoco se espera cualquier tipo de entrada.\n\n2.4.1 Notación \\(\\Theta\\)\nPara una función dada \\(g(n)\\) denotamos por \\(\\Theta(g(n))\\) el siguiente conjunto de funciones:\n\\[\\begin{align}\n\\Theta(g(n)) &=  \\left\\{ f(n) \\mid \\text{ existen las constantes positivas }c_1, c_2 \\text{ y } n_0 \\text{ tal que } \\right.\\\\\n    ~ & \\left. 0 \\leq c_1 g(n) \\leq f(n) \\leq c_2 g(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nesto es, una función \\(f(n)\\) pertenece al conjunto \\(g(n)\\) si \\(c_1 g(n)\\) y \\(c_2 g(n)\\) pueden cubrirla por abajo y por arriba, para esto deben existen las constantes positivas \\(c_1\\) y \\(c_2\\) y una \\(n\\) lo suficientemente larga, e.g., para eso la constante \\(n_0\\). La notación propiamente de conjuntos puede usarse \\(f(n) \\in \\Theta(g(n))\\) pero es común en el área usar \\(f(n) = \\Theta(g(n))\\) para expresar la pertenencia; este abuso de la notación tiene ventaja a la hora de plantear los problemas de análisis.\n\n\n2.4.2 Notación \\(O\\)\nSe utiliza para indicar una cota asintótica superior. Una función \\(f(n)\\) se dice que esta en \\(O(g(n))\\) si esta en el siguiente conjunto:\n\\[\\begin{align}\nO(g(n)) &=  \\left\\{ f(n)  \\mid \\text{ existen las constantes positivas }c \\text{ y } n_0 \\text{ tal que } \\right.\\\\\n    ~& \\left. 0 \\leq f(n) \\leq c g(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nLa notación \\(O\\) se usa para dar una cota superior, dentro de un factor constante. Al escribir \\(f(n) = O(g(n))\\) se indica que \\(f(n)\\) es miembro del conjunto \\(O(g(n))\\); hay que notar que \\(f(n) = \\Theta(g(n))\\) implica que \\(f(n) = O(g(n))\\), i.e., \\(\\Theta(g(n)) \\subseteq O(g(n))\\).\n\n\n2.4.3 Notación \\(\\Omega\\)\nAl contrario de \\(O\\), la notación \\(\\Omega\\) da una cota asintótica inferior. Una función \\(f(n)\\) se dice que esta en \\(\\Omega(g(n))\\) si esta en el siguiente conjunto:\n\\[\\begin{align}\n\\Omega(g(n)) = & \\left\\{ f(n)  \\mid \\text{ existen las constantes positivas }c \\text{ y } n_0 \\text{ tal que } \\right. \\\\\n    & \\left. 0 \\leq c g(n) \\leq f(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nDado que la \\(\\Omega\\) define una cota superior, basicamente si \\(f(n) = \\Omega(g(n))\\), entonces \\(f(n)\\) debe estar por encima de \\(g(n)\\) con las constantes \\(c\\) y \\(n_0\\) adecuadas. Al igual que la notación \\(O\\), la notación \\(\\Omega\\) es menos estricta que \\(\\Theta\\), esto es \\(f(n) = \\Theta(g(n))\\) implica que \\(f(n) = \\Omega(g(n))\\), por lo que \\(\\Theta(g(n)) \\subseteq \\Omega(g(n))\\).\nPor tanto, si \\(f(n) = O(g(n))\\) y \\(f(n) = \\Omega(g(n))\\) entonces \\(f(n) \\in \\Theta(g(n))\\).\n\nEs importante conocer los ordenes de crecimiento más comunes de tal forma que podamos realizar comparaciones rápidas de costos, y dimensionar las diferencias de recursos entre diferentes tipos de costos. La notación asintótica hace uso extensivo de la diferencia entre diferentes ordenes de crecimiento para ignorar detalles y simplificar el análisis de algoritmos.\n\n\n\n2.4.4 Apoyo audio-visual\nEn los siguientes videos se profundiza sobre los modelos de cómputo y los diferentes tipos de análisis sobre algoritmos.\n\nParte 1: \nParte 2: \nParte 3: \n\n\n\n2.4.5 Ordenes de crecimiento\n\n\nDado que la idea es realizar un análisis asintótico, las constantes suelen ignorarse, ya que cuando el tamaño de la entrada es suficientemente grande, los términos con mayor orden de magnitud o crecimiento dominarán el costo. Esto es, es una simplificación necesaría.\nLos ordenes de crecimiento son maneras de categorizar la velocidad de crecimiento de una función, y para nuestro caso, de una función de costo. Junto con la notación asimptótica nos permite concentrarnos en razgos gruesos que se mantienen para entradas grandes, más que en los detalles, y no perder el punto de interés. A continuación veremos algunas funciones con crecimientos paradigmáticos; las observaremos de poco en poco para luego verlos en conjunto.\n\n2.4.5.1 Costo constante, logaritmo y lineal\nLa siguiente figura muestra un crecimiento nulo (constante), logaritmico y lineal. Note como la función logarítmica crece lentamente.\n\nusing Plots, LaTeXStrings\nn = 300 # 300 puntos\n\nplot(1:n, [10 for x in 1:n], label=L\"c\")\nplot!(1:n, [log2(x) for x in 1:n], label=L\"\\log{n}\")\nplot!(1:n, [x for x in 1:n], label=L\"n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.2 Costo \\(n \\log n\\) y polinomial\nA continuación veremos tres funciones, una función con \\(n\\log n\\) y una función cuadrática y una cúbica. Note como para valores pequeños de \\(n\\) las diferencias no son tan apreciables para como cuando comienza a crecer \\(n\\); así mismo, observe los valores de \\(n\\) de las figuras previas y de la siguiente, este ajuste de rangos se hizo para que las diferencias sean apreciables.\n\nn = 7 # note que se usan menos puntos porque 300 serían demasiados para el rango\n\nplot(1:n, [x * log2(x) for x in 1:n], label=L\"n\\log_2{n}\")\nplot!(1:n, [x^2 for x in 1:n], label=L\"n^2\")\nplot!(1:n, [x^3 for x in 1:n], label=L\"n^3\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.3 Exponencial\nA continuación se compara el crecimiento de una función exponencial con una función polinomial. Note que la función polinomial es de grado 4 y que la función exponencial tiene como base 2; aún cuando para números menores de aproximadamente 16 la función polinomial es mayor, a partir de ese valor la función \\(2^n\\) supera rapidamente a la polinomial.\n\nn = 20\n\nplot(1:n, [x^4 for x in 1:n], label=L\"n^4\")\nplot!(1:n, [2^x for x in 1:n], label=L\"2^n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.4 Crecimiento factorial\nVease como la función factorial crece mucho más rápido que la función exponencial para una \\(n\\) relativamente pequeña. Vea las magnitudes que se alcanzan en el eje \\(y\\), y comparelas con aquellas con los anteriores crecimientos.\n\nn = 20\n\nplot(1:n, [2^x for x in 1:n], label=L\"2^n\")\nplot!(1:n, [factorial(x) for x in 1:n], label=L\"n!\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.5.5 Un poco más sobre funciones de muy alto costo\n\nn = 10\n\nplot(1:n, [factorial(x) for x in 1:n], label=L\"n!\")\nplot!(1:n, [x^x for x in Int128(1):Int128(n)], label=L\"n^n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVea la figura anterior, donde se compara \\(n!\\) con \\(n^n\\), observe como es que cualquier constante se vuelve irrelevante rapidamente; aun para \\(n^n\\) piense en \\(n^{n^n}\\).\nNote que hay problemas que son realmente costosos de resolver y que es necesario conocer si se comporta así siempre, si es bajo determinado tipo de entradas. Hay problemas en las diferentes áreas de la ciencia de datos, donde veremos este tipo de costos, y habrá que saber cuando es posible solucionarlos, o cuando se deben obtener aproximaciones que nos acerquen a las respuestas correctas con un costo manejable, es decir, mediar entre exactitud y costo. En este curso se abordaran problemas con un costo menor, pero que por la cantidad de datos, i.e., \\(n\\), se vuelven muy costosos y veremos como aprovechar supuestos como las distribuciones naturales de los datos para mejorar los costos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#el-enfoque-experimental",
    "href": "cap2-analisis.html#el-enfoque-experimental",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "2.5 El enfoque experimental",
    "text": "2.5 El enfoque experimental\nLa notación asintótica nos permite alcanzar un lenguaje común y preciso sobre los costos de problemas y algoritmos; es de especial importancia para la evaluación de las alternativas en la literatura especializada, y elegir algoritmos aún sin la necesidad de implementación. El análisis asintótico da la posibilidad de conocer el desempeño desde diferentes perspectivas como peor caso o caso promedio, utilizando un módelo de computación, y siempre pensando en entradas lo suficientemente grandes.\nEn la práctica, existe una múltitud de razones por los cuales los problemas que se resuelven podrian no ser tan grandes como para que un algoritmo domine a otros de manera asintótica, las instancias podrían no ser tan generales como para preocuparse en el peor caso, o el caso promedio general. En muchas situaciones, es importante sacar provecho de los casos fáciles, sobre todo cuando el problema a resolver podría asegurar que dichos casos simples sean abundantes. Dada la complejidad detrás de definir sub-conjuntos de instancias y llevar a cabo un análisis formal, se vuelve imperativo realizar pruebas experimentales.\nPor otra parte, dada la complejidad de una computadora moderna, es necesario realizar evaluaciones experimentales de los algoritmos que tengan una complejidad similar. Las computadoras reales tienen una jerarquia de memoria con tamaños y velocidades de acceso divergentes entre sí, con optimizaciones integradas sobre la predicción de acceso y cierto nivel de paralelismo. Incluso, cada cierto tiempo se obtienen optimizaciones en los dispositivos que podrían mejorar los rendimientos, por lo que es posible que con una generación a otra, lo que sabemos de los algoritmos y su desempeño en computadoras y cargas de trabajo reales cambie.\n\n2.5.1 Metodología experimental\nAlgunos de los algoritmos que se verán en este libro son sumamente rapidos en la práctica para resolver una instancia práctica por lo que medir el desempeño de instancias solas podría no tener sentido. La acumulación de operaciones es fundamental, así como la diversidad de las instancias también lo es. Caracterizar las entradas es de vital importancia ya que la adaptabilidad a las instancias es parte de los objetivos.\nEntonces, estaremos probando conjuntos de instancias, caracterizadas y estaremos utilizando tiempos promedios. También estaremos usando conteo de operaciones, por lo que los algoritmos en cuestión muchas veces serán adaptados para poder realizar este conteo.\nEn Julia etaremos utilizando las siguientes instrucciones:\n\n@time expr macro que mide el tiempo en segundo utilizado por expr, también reporta el número de alojaciones de memoria. Note que reducir la cantidad de memoria alojada puede significar reducir el tiempo de una implementación, ya que el manejo de memoria dinámica es costoso.\n@benchmark expr params macro del paquete BenchmarkTools que automatiza la repetición de expr para obtener diferentes mediciones y hacer un reporte, params permite manipular la forma en que se reliza la evaluación.\n@btime expr params macro del paquete BenchmarkTools que mimetiza la salida de @time.\n\n\na = rand(Float32, 3, 3)\n1@time a * a\n2@time a * a\n\n\n1\n\nTodas las fuciones se deben compilar, la primera llamada uncluye los costos de compilación.\n\n2\n\nEl costo sin compilación, hay una alojación que es la matriz donde se guarda el resultado.\n\n\n\n\n  1.149417 seconds (2.00 M allocations: 135.521 MiB, 4.97% gc time, 99.97% compilation time)\n  0.000013 seconds (1 allocation: 96 bytes)\n\n\n3×3 Matrix{Float32}:\n 0.192604  0.768473  0.844105\n 0.388769  0.845516  1.38606\n 0.613623  0.4825    0.975766\n\n\nTanto @benchmark como @btime aceptan interpolación de variables con el prefijo $ para controlar la evaluación de una expresión se debe contar como parte de lo que se quiere medir o no. Se puede combinar con el parametro setup para controlar de manera precisa las entradas para evaluar cada una de las repeticiones de expr.\n\nusing BenchmarkTools\n\n@benchmark a * a setup=(a=rand(Float32, 3, 3))\n\nBenchmarkTools.Trial: 10000 samples with 984 evaluations.\n Range (min … max):  50.088 ns …  4.631 μs  ┊ GC (min … max): 0.00% … 96.38%\n Time  (median):     61.026 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   70.964 ns ± 82.403 ns  ┊ GC (mean ± σ):  4.22% ±  4.11%\n\n    ▅█▄                                                        \n  ▁▅████▅▅▅▅▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂\n  50.1 ns         Histogram: frequency by time         167 ns &lt;\n\n Memory estimate: 96 bytes, allocs estimate: 1.\n\n\n\n\na = rand(Float32, 3, 3)\n@btime a * a setup=(a=$a)\n\n  52.337 ns (1 allocation: 96 bytes)\n\n\n3×3 Matrix{Float32}:\n 1.06282  0.208756  0.60189\n 2.21355  1.4028    2.01148\n 1.44996  1.06617   1.53792\n\n\nEl parametro sample controla el número máximo de muestras que se tomarán para el análisis, y seconds limita el tiempo sobre el cual se tomarán muestras; se asegura que al menos se tomará una muestra, se debe tener en cuenta que puede costar más que seconds.1\n\na = rand(Float32, 3, 3)\nb = rand(Float32, 3, 3)\n@benchmark a * b setup=(a=$a, b=$b) samples=1000 seconds=0.33\n\nBenchmarkTools.Trial: 1000 samples with 977 evaluations.\n Range (min … max):  65.705 ns …  1.344 μs  ┊ GC (min … max): 0.00% … 91.31%\n Time  (median):     79.439 ns              ┊ GC (median):    0.00%\n Time  (mean ± σ):   86.416 ns ± 57.817 ns  ┊ GC (mean ± σ):  2.75% ±  4.06%\n\n   ▇▆█▇▅▂▁▂▂▂▅▂                                                \n  ▆█████████████▆▆▆▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▂▃▂▃▂▃▂▁▁▃▂▃▂▂▁▁▂▂▂▂▂▂▂▁▂▁▂ ▄\n  65.7 ns         Histogram: frequency by time         164 ns &lt;\n\n Memory estimate: 96 bytes, allocs estimate: 1.\n\n\n\n\n2.5.2 Ejemplo del cálculo de máximo de un arreglo y diferentes tipos de costo.\n–\n\n\n1function maximo(col)\n    maxpos = 1\n    actualizaciones = 1\n    i = 2\n\n    while i &lt; length(col)\n        if col[maxpos] &lt; col[i]\n            maxpos = i\n            actualizaciones += 1\n        end\n        i += 1\n    end\n\n    maxpos, actualizaciones\nend\n\n\n1\n\nFunción que encuentra el máximo en una secuencia y devuelve su posición, y además devuelve el número de veces que se actualizó el máximo en el recorrido.\n\n\n\n\nmaximo (generic function with 1 method)\n\n\n\na = rand(UInt32, 128)\n1@benchmark maximo($a) samples=100 seconds=3\n\n\n1\n\nUn análisis de desempeño usando @benchmark; probando con máximo 100 samples en 3 segundos.\n\n\n\n\nBenchmarkTools.Trial: 100 samples with 815 evaluations.\n Range (min … max):  174.276 ns … 247.742 ns  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     186.936 ns               ┊ GC (median):    0.00%\n Time  (mean ± σ):   188.047 ns ±  12.573 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n  ▆    ▇▄   █▄    ▄                                              \n  █▅▁▁▁██▇▁▅██▅█▁▁█▇█▁▅▅▅▅▁▁▁▅▁▁▁▇▅▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅ ▅\n  174 ns        Histogram: log(frequency) by time        247 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n\n\nNote que aunque se tiene un análisis muy detallado del desempeño, otras medidas de costo caen fuera del diseño del paquete, por lo que es necesario hacerlas por otros medios. Por ejemplo, suponga que el número de actualizaciones es nuesta medida de desempeño, un código donde se capturen las actualizaciones\n\n1using StatsBase\n2a = [maximo(rand(UInt32, 128))[2] for i in 1:100]\n3quantile(a, [0.0, 0.25, 0.5, 0.75, 1.0])\n\n\n1\n\nInclusión de un paquete para cálculo de estadísticas básicas.\n\n2\n\nDefinición de 100 experimentos que calculan maximo sobre arreglos aleatorios.\n\n3\n\nCálculo del mínimo, cuantiles 0.25, 0.5, 0.75, y el máximo, para determinar el desempeño.\n\n\n\n\n5-element Vector{Float64}:\n  1.0\n  4.0\n  5.0\n  6.0\n 10.0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#actividades",
    "href": "cap2-analisis.html#actividades",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "2.6 Actividades",
    "text": "2.6 Actividades\nComparar mediante simulación en un notebook de Jupyter o Quarto los siguientes órdenes de crecimiento:\n\n\\(O(1)\\) vs \\(O(\\log n)\\)\n\\(O(n)\\) vs \\(O(n \\log n)\\)\n\\(O(n^2)\\) vs \\(O(n^3)\\)\n\\(O(a^n)\\) vs \\(O(n!)\\)\n\\(O(n!)\\) vs \\(O(n^n)\\)\nEscoja los rangos adecuados para cada comparación, ya que como será evidente después, no es práctico fijar los rangos.\nCree una figura por comparación, i.e., cinco figuras. Discuta lo observado por figura.\nCree una tabla donde muestre tiempos de ejecución simulados para algoritmos ficticios que tengan los órdenes de crecimiento anteriores, suponiendo que cada operación tiene un costo de 1 nanosegundo.\n\nUse diferentes tamaños de entrada \\(n=100\\), \\(n=1000\\), \\(n=10000\\) y \\(n=100000\\).\nNote que para algunas fórmulas, los números pueden ser muy grandes, tome decisiones en estos casos y defiendalas en el reporte.\n\nDiscuta las implicaciones de costos de cómputo necesarios para manipular grandes volúmenes de información, en el mismo notebook.\n\n\n2.6.1 Entregable\nSu trabajo se entregará en PDF y con el notebook fuente; deberá estar plenamente documentado, con una estructura que permita a un lector interesado entender el problema, sus experimentos y metodología, así como sus conclusiones. Tenga en cuenta que los notebooks pueden alternar celdas de texto y código.\nNo olvide estructurar su reporte, en particular el reporte debe cubrir los siguientes puntos:\n\nTítulo del reporte, su nombre.\nIntroducción.\nCódigo cercano a la presentación de resultados.\nFiguras y comparación de los órdenes de crecimiento.\nAnálisis y simulación de costo en formato de tabla.\nConclusión. Debe abordar las comparaciones hechas y la simulación; también toque el tema de casos extremos y una \\(n\\) variable y asintóticamente muy grande.\nLista de referencias. Nota, una lista de referencias que no fueron utilizadas en el cuerpo del texto será interpretada como una lista vacía.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#bibliografía",
    "href": "cap2-analisis.html#bibliografía",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "2.7 Bibliografía",
    "text": "2.7 Bibliografía\nCormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2022). Introduction to Algorithms (2nd ed.). MIT Press.\n\nParte I: Cap. 1, 2, 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#footnotes",
    "href": "cap2-analisis.html#footnotes",
    "title": "2  Introducción al análisis de algoritmos con Julia",
    "section": "",
    "text": "Se recomienda visitar el sitio https://juliaci.github.io/BenchmarkTools.jl/stable/ para más información sobre el paquete BenchmarkTools, y en particular para sus parametros, como guardar información de corridas.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción al análisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html",
    "href": "cap3-estructuras.html",
    "title": "3  Estructuras de datos elementales",
    "section": "",
    "text": "Objetivo\nImplementar, aplicar y caracterizar el desempeño de algoritmos en peor caso y adaptativos para búsqueda en arreglos ordenados. Se discutirán estructuras de datos básicas que serán de gran utilidad al momento de construir programas y de resolver problemas más complejos; nos enfocaremos en las estructuras de datos .",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#introducción",
    "href": "cap3-estructuras.html#introducción",
    "title": "3  Estructuras de datos elementales",
    "section": "3.1 Introducción",
    "text": "3.1 Introducción\nEn esta unidad se discutirán las propiedades y operaciones básicas de estructuras como conjuntos, listas, pilas, colas, arreglos, vectores, matrices y matrices dispersas. La intención es utilizar código en el lenguaje de programación Julia, que pueda ser traducido fácilmente en otros lenguajes de programación; así como explicar las particularidades de las estructuras.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#conjuntos",
    "href": "cap3-estructuras.html#conjuntos",
    "title": "3  Estructuras de datos elementales",
    "section": "3.2 Conjuntos",
    "text": "3.2 Conjuntos\nLos conjuntos son estructuras abstractas que representan una colección de elementos, en particular, dado las posibles aplicaciones un conjunto puede tener contenido inmutable o mutable, esto es que puede aceptar modificaciones a dicha colección. Un conjunto puede estar vacio (\\(\\emptyset\\)) o contener elementos, e.g., \\(\\{a, b, c\\}\\). Un conjunto puede unirse con otro conjunto, e.g., \\(\\{a, b\\} \\cup \\{c\\} = \\{a, b, c\\}\\), así como puede intersectarse con otros conjuntos, e.g. \\(\\{a, b, c\\} \\cap \\{b, d\\} = \\{b\\}\\). El tamaño de una colección lo representamos con barras, e.g., \\(|\\{a, b\\}| = 2\\). También es útil consultar por membresia \\(a \\in \\{a, b, c\\}\\) o por la negación de membrsia, i.e., \\(a \\not\\in \\{a, b, c\\}\\). En contraste con la definición matemática de conjunto, es común necesitar conjuntos mutables en diferentes algoritmos, esto es, que permitan inserciones y borrados sobre la misma estructura. Esto es sumamente útil ya que nos permite hacer una representación en memoria que no requiera realizar copias y gestionar más memoria. Suponga el conjunto \\(S = \\{a, b, c\\}\\), la función \\(pop!(S, b)\\) resultaría en \\(\\{a, c\\}\\), y la función \\(push!(S, d)\\) resultaría en \\(\\{a, c, d\\}\\) al encadenar estas operaciones. Note que el símbolo \\(!\\) solo se esta usando en cooncordancia con el lenguaje de programación Julia para indicar que la función cambiaría el argumento de entrada, y es solo una convención, no un operador en sí mismo. Así mismo, note que estamos usando una sintaxis muy sencilla \\(fun(arg1, arg2, ...)\\) para indicar la aplicación de una función u operación a una serie de argumentos.\nEs importante hacer notar, que aunque es uno de los conceptos fundamentales, no existe una única manera de representar conjuntos, ya que los requerimientos de los algoritmos son diversos y tener la representación correcta puede ser la diferencia. Las implementaciones y algoritmos alrededor pueden llegar a ser muy sofisticados, dependiendo de las características que se desean, algunas de las cuales serán el centro de estudio de este curso.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#tuplas-y-estructuras",
    "href": "cap3-estructuras.html#tuplas-y-estructuras",
    "title": "3  Estructuras de datos elementales",
    "section": "3.3 Tuplas y estructuras",
    "text": "3.3 Tuplas y estructuras\nLas tuplas son colecciones abstractas ordenadas, donde incluso puede haber repetición, pueden verse como una secuencia de elementos, e.g., \\(S = (a, b, c)\\); podemos referirnos a la \\(i\\)ésima posición de la forma \\(S_i\\), o incluso \\(S[i]\\), si el contexto lo amérita, e.g., pseudo-código que pueda ser transferido a un lenguaje de programación más fácilmente. Es común que cada parte de la tupla pueda contener cierto tipo de dato, e.g., enteros, números de punto flotante, símbolos, cadenas de carácteres, etc. Una tupla es muy amena para ser representada de manera contigua en memoria. En el lenguaje de programación Julia, las tuplas se representan entre paréntesis, e.g., \\((1, 2, 3)\\).\n\nt = (10, 20, 30)\n\nt[1] * t[3] - t[2]\n\n280\nDefinición y acceso a los campos de una tupla en Julia\n\n\n\n\nDado que es amena para representarse de manera contigua en memoria, en los lenguajes de programación que aprovechen este hecho, una tupla puede enviarse como valor (copiar) cuando se utiliza en una función; por lo mismo, puede guardarse en el stack, que es la memoria inmediata que se tiene en el contexto de ejecución de una función. En esos casos, se puede optimizar el manejo de memoria (alojar y liberar), lo cuál puede ser muy beneficioso para un algoritmo en la práctico. El otro esquema posible es el heap, que es una zona de memoria que debe gestionarse (memoria dinámica); es más flexible y duradera entre diferentes llamadas de funciones en un programa. Los patrones esperados son dispersos y puede generar fragmentación\nUna estructura es una tupla con campos nombrados; es muy útilizada en lenguajes de programación, por ejemplo, en Julia la siguiente estructura puede representar un punto en un plano:\n\nstruct Point\n  x::Float32\n  y::Float32\nend\n\nNote la especificación de los tipos de datos que en conjunto describirán como dicha estructura se maneja por una computadora, y que en términos prácticos, es determinante para el desempeño. Es común asignar valores satelitales en programas o algoritmos, de tal forma que un elemento simple sea manipulado o utilizado de manera explicita en los algoritmos y tener asociados elementos secundarios que se vean afectados por las operaciones. Los conjuntos, tuplas y las estructuras son excelentes formas de representar datos complejos de una manera sencilla.\nEn Julia, es posible definir funciones o métodos al rededor del tipo de tuplas y estructuras.\n\n\nEs importante saber que si algunos de los campos o datos de una tupla o estructura estan en el heap entonces solo una parte estará en el stack; i.e., en el caso extremo solo serán referencias a datos en el heap. Esto puede llegar a complicar el manejo de memoria, pero también puede ser un comportamiento sobre el que se puede razonar y construir.\n\n\"\"\"\n  Calcula la norma de un vector representado\n  como un tupla\n\"\"\"\nfunction norm(u::Tuple)\n  s = 0f0\n  for i in eachindex(u)\n    s = u[i]^2\n  end\n  sqrt(s)\nend\n\n\"\"\"\n  Calcula la norma de un vector de 2 dimensiones\n  representado como una estructura\n\"\"\"\nfunction norm(u::Point)\n  sqrt(u.x^2 + u.y^2)\nend\n\n(norm((1, 1, 1, 1)), norm(Point(1, 1)))\n\n(1.0, 1.4142135f0)\nFunciones sobre diferentes tipos de datos\n\n\nNote que la función es diferente para cada tipo de entrada; a este comportamiento se le llamada despacho múltiple y será un concepto común este curso. En otros lenguajes de programación se implementa mediante orientación a objetos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#arreglos",
    "href": "cap3-estructuras.html#arreglos",
    "title": "3  Estructuras de datos elementales",
    "section": "3.4 Arreglos",
    "text": "3.4 Arreglos\nLos arreglos son estructuras de datos que mantienen información de un solo tipo, tienen un costo constante \\(O(1)\\) para acceder a cualquier elemento (también llamado acceso aleatorio) y tipicamente se implementan como memoria contigua en una computadora. Al igual que las tuplas, son colecciones ordenadas, las estaremos accediendo a sus elementos con la misma notación. En este curso usaremos arreglos como colecciones representadas en segmentos contiguos de memoria con dimensiones lógicas fijas. A diferencia de las tuplas, es posible reemplazar valores, entonces \\(S_{ij} \\leftarrow a\\), reemplazará el contenido de \\(S\\) en la celda especificada por \\(a\\).\n\n\nJulia tiene un soporte para arreglos excepcional, el cual apenas trataremos ya que se enfoca en diferentes áreas del cómputo numérico, y nuestro curso esta orientado a algoritmos. En Python, estructuras similares se encuentra en el paquete Numeric Python o numpy; tenga en cuenta que las afirmaciones sobre el manejo de memoria y representación que estaremos usando se apegan a estos modelos, y no a las listas nativas de Python.\nA diferencia de las tuplas, pueden tener más que una dimensión. La notación para acceder a los elementos se extiende, e.g. para una matriz \\(S\\) (arreglo bidimensional) \\(S_{ij}\\) se refiere a la celda en la fija \\(i\\) columna \\(j\\), lo mismo que \\(S[i, j]\\). Si pensamos en datos numéricos, un arreglo unidimensional es útil para modelar un vector de múltiples dimensiones, un arreglo bidimensional para representar una mátriz de tamaño \\(m \\times n\\), y arreglos de dimensión mayor pueden usarse para tensores. Se representan en memoria en segmentos contiguos, y los arreglos de múltiples dimensiones serán representados cuyas partes pueden ser delimitadas mediante aritmética simple, e.g., una matriz de tamaño \\(m \\times n\\) necesitará una zona de memoria de \\(m \\times n\\) elementos, y se puede acceder a la primera columna mediante en la zona \\(1,\\dots,m\\), la segunda columna en \\(m+1,\\dots,2m\\), y la \\(i\\)ésima en \\((i-1)m+1,\\dots,im\\); esto es, se implementa como el acceso en lotes de tamaño fijo en un gran arreglo unidimensional que es la memoria.\n\n\nEsta es la manera que en general se manejan los datos en una computadora, y conocerlo de manera explícita nos permite tomar decisiones de diseño e implementación.\n\n\n\n\n\n\n\n\nlista\n\n\n\nRAM\n\nmemoria RAM\n\notros\ndatos\n\ncolumna 1 - x[:, 1]\n\nx[1,1]\n\nx[2,1]\n\nx[3,1]\n\nx[4,1]\n\ncolumna 2 - x[:, 2]\n\nx[1,2]\n\nx[2,2]\n\nx[3,2]\n\nx[4,2]\n\ncolumna 3 - x[:, 3]\n\nx[1,3]\n\nx[2,3]\n\nx[3,3]\n\nx[4,3]\n\ncolumna 4 - x[:, 4]\n\nx[1,4]\n\nx[2,4]\n\nx[3,4]\n\nx[4,4]\n\notros\ndatos\n\n\n\n\n\n\nFigura 3.1: Esquema de una matriz en memoria.\n\n\n\n\n\nLa representación precisa en memoria es significativa en el desempeño de operaciones matriciales como pueden ser el producto entre matrices o la inversión de las mismas. La manera como se acceden los datos es crucial en el diseño de los algoritmos.\nEl siguiente ejemplo define un vector \\(u\\) de \\(m\\) elementos y una matriz \\(X\\) de tamaño \\(m \\times n\\), ambos en un cubo unitario de 4 dimensiones, y define una función que selecciona el producto punto máximo del vector \\(u\\) a los vectores columna de \\(X\\):\n\n\nfunction mydot(u, x)\n  s = 0f0\n  for i in eachindex(u, x)\n    s += u[i] * x[i]\n  end\n  s\nend\n\nfunction getmaxdot(u::Vector, X::Matrix)\n  maxpos = 1\n  # en la siguiente linea, @view nos permite controlar que\n  # no se copien los arreglos, y en su lugar, se usen referencias\n  maxdot = mydot(u, @view X[:, 1])\n  # obtiene el número de columnas e itera apartir del 2do indice \n  mfilas, ncols = size(X)\n  for i in 2:ncols\n    d = mydot(u, @view X[:, i]) \n    if d &gt; maxdot\n      maxpos = i\n      maxdot = d\n    end\n  end\n\n  (maxpos, maxdot)\nend\n\ngetmaxdot(rand(Float32, 4), rand(Float32, 4, 1000))\n\n(740, 2.5505784f0)\n\n\nEn este código puede verse como se separa el cálculo del producto punto en una función, esto es porque en sí mismo es una operación importante; también podemos aislar de esta forma la manera que se accede (el orden) a los vectores. La idea fue acceder columna a columna, lo cuál asegura el uso apropiado de los accesos a memoria. En la función \\(getmaxdot\\) se resuelve el problema de encontrar el máximo de un arreglo, y se puede observar que sin conocimiento adicional, este requiere \\(O(n)\\) comparaciones, para una mátriz de \\(n\\) columnas. Esto implica que cada producto punto se cuenta como \\(O(1)\\), lo cual simplifica el razonamiento. Por la función \\(mydot\\) podemos observar que el producto punto tiene un costo de \\(O(m)\\), por lo que la \\(getmaxdot\\) tiene un costo de \\(O(mn)\\) operaciones lógicas y aritméticas.\nEl producto entre matrices es un caso paradigmático por su uso en la resolución de problemas prácticos, donde hay una gran cantidad de trabajo al rededor de los costos necesarios para llevarlo a cabo. En particular, el algoritmo naïve, es un algoritmo con costo cúbico, como se puede ver a continuación:\n\nfunction myprod(A::Matrix, B::Matrix)\n  mA, nA = size(A)\n  mB, nB = size(B)\n  @assert nA == mB\n  C = Matrix{Float32}(undef, mA, nB)\n\n  for i in 1:mA\n    for j in 1:mB\n      rowA = @view A[i, :]\n      colB = @view B[:, i]\n      C[i, j] = mydot(rowA, colB)\n    end\n  end\n\n  C\nend\n\nA = rand(Float32, 5, 3)\nB = rand(Float32, 3, 5)\nC = myprod(A, B)\ndisplay(C)\n\n5×5 Matrix{Float32}:\n 1.15099   1.15099   1.15099   0.0         8.11f-43\n 0.159122  0.159122  0.159122  7.34f-43    4.3639f-41\n 1.16537   1.16537   1.16537   4.3639f-41  3.36f-43\n 1.487     1.487     1.487     3.36f-43    0.0\n 1.32428   1.32428   1.32428   0.0         8.13f-43\nFunciones sobre diferentes tipos de datos\n\n\nSe pueden ver dos ciclos iterando a lo largo de filas y columnas, adicionalmente un producto punto, el cual tiene un costo lineal en la dimensión del vector, por lo que el costo es cúbico. Esta implementación es directa con la definición misma del producto matricial. Dado su implacto, existen diferentes algoritmos para hacer esta operación más eficiente, incluso hay áreas completas dedicadas a mejorar los costos para diferentes casos o características de las matrices.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#listas",
    "href": "cap3-estructuras.html#listas",
    "title": "3  Estructuras de datos elementales",
    "section": "3.5 Listas",
    "text": "3.5 Listas\nLas listas son estructuras de datos ordenadas lineales, esto es, no se asume que los elementos se guardan de manera contigua y los accesos al \\(i\\)-ésimo elemento cuestan \\(O(i)\\). Se soportan inserciones y borrados. Por ejemplo, sea \\(L = [a, b, c, d]\\) una lista con cuatro elementos, \\(L_2 = b\\), \\(insert!(L, 2, z)\\) convertirá \\(L = [a, z, b, c, d]\\) (note que \\(b\\) se desplazó y no se reemplazó como se esperaría en un arreglo). La operación \\(deleteat!(L, 2)\\) regresará la lista a su valor previo a la inserción. Estas operaciones que modifican la lista también tienen diferentes costos dependiendo de la posición, e.g., donde el inicio y final de la secuencia (también llamados cabeza y cola) suelen ser más eficientes que accesos aleatorios, ya que se tienen referencias a estas posiciones en memoria. Es de especial importancia la navegación por la lista mediante operaciones de sucesor \\(succ\\) y predecedor \\(pred\\), que pueden encadenarse para obtener acceso a los elementos. A diferencia de un arreglo, las listas no requieren una notación simple para acceso a los elementos y sus reemplazos, ya que su aplicación es diferente.\n\n\n\n\n\n\n\n\nlista\n\n\n\nlist\n\nhead\n\ntail\n\n\n\na\n\na\n\n \n\n\n\nlist:n-&gt;a:n\n\n\n\n\n\nc\n\nc\n\n \n\n\n\nlist:s-&gt;c:s\n\n\n\n\n\nb\n\nb\n\n \n\n\n\na:c-&gt;b:w\n\n\n\n\n\nb:c-&gt;c:w\n\n\n\n\n\nnothing\n\nnothing\n\n\n\nc:c-&gt;nothing\n\n\n\n\n\n\n\n\nFigura 3.2: Una lista ligada simple\n\n\n\n\n\nLa Figura 3.2 muestra una lista ligada, que es una implementación de lista que puede crecer fácilmente, funciona en el heap de memoria por lo que cada bloque requiere memoria dinámica. Cada bloque es una estructura; se pueden distinguir dos tipos, la lista que contiene referencias al primer nodo y al último nodo. Los nodos de de datos contienen los elementos de la colección y referencias al siguiente nodo, también llamado sucesor. El nodo nothing es especial y significa que no hay más elementos.\nEl siguiente código muestra como la definición de lista ligada.\n\n\n\n\nListado 3.1: Código para una lista ligada simple\n\n\nstruct Nodo\n  data::Int\n  next::Union{Nodo,Nothing}\nend\n\nnodo = Nodo(10, Nodo(20, Nodo(30, nothing)))\n\nprintln(nodo)\n(nodo.data, nodo.next.data, nodo.next.next.data)\n\n\n\n\nNodo(10, Nodo(20, Nodo(30, nothing)))\n\n\n(10, 20, 30)\n\n\nEn el Listado 3.1 se ignora la referencia a tail (head se guarda en nodo), por lo que las operaciones sobre tail requieren recorrer la lista completa, costando \\(O(n)\\) en el peor caso para una lista de \\(n\\) elementos.\nPor su manera en la cual son accedidos los datos, se tienen dos tipos de listas muy útiles: las colas y las pilas. Las colas son listas que se acceden solo por sus extremos, y emulan la política de el primero en entrar es el primero en salir (first in - first out, FIFO), y es por eso que se les llama colas haciendo referencia a una cola para realizar un trámite o recibir un servicio. Las pilas o stack son listas con la política el último en entrar es el primero en salir (last in - first out, LIFO). Mientras que cualquier lista puede ser útil para implementarlas, algunas maneras serán mejores que otras dependiendo de los requerimientos de los problemas siendo resueltos; sin embargo, es importante recordar sus políticas de acceso para comprender los algoritmos que las utilicen.\nEn este curso, se tienen en cuenta las siguientes operaciones, nombrando diferente cada operación:\n\npush!(L, a): insertar \\(a\\) al final de la lista \\(L\\).\npop!(L): remueve el último elemento en \\(L\\).\ndeleteat!(L, pos): remueve el elemento en la posición \\(pos\\), se desplazan los elementos.\ninsert!(L, pos, valor): inserta \\(valor\\) en la posición \\(pos\\) desplazando los elementos anteriores.\n\n\n3.5.0.1 Ejercicios\n\nImplemente insert! y deleteat!\n¿Cuál sería la implementación de succ y pred en una lista ligada?\n¿Cuales serían sus costos?\nAñadiendo más memoria, como podemos mejorar pred?\n\n\n\n3.5.1 Grafos\nOtras estructuras de datos elementales son los grafos. Un grafo \\(G = (V, E)\\) es una tupla compuesta por un conjunto de vertices \\(V\\) y el conjunto de aristas \\(E\\). Por ejemplo, el grafo con \\(A = (\\{a, b, c, d\\}, \\{(a, b), (b, c), (c, d), (d, a)\\})\\)\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na-&gt;b\n\n\n\n\n\nc\n\nc\n\n\n\nb-&gt;c\n\n\n\n\n\nd\n\nd\n\n\n\nc-&gt;d\n\n\n\n\n\nd-&gt;a\n\n\n\n\n\n\n\n\nFigura 3.3: Un grafo dirigido simple\n\n\n\n\n\nLos grafos son herramientas poderosas para representar de manera abstracta problemas que implican relaciones entre elementos. En algunos casos es útil asociar funciones a los vértices y las aristas. Tenga en cuenta los siguientes ejemplos:\n\n\\(peso: V \\rightarrow \\mathbb{R}\\), la cual podría usarse como \\(peso(a) = 1.5\\).\n\\(costo: V \\times V \\rightarrow \\mathbb{R}\\), la cual podría usarse como \\(costo(a, b) = 2.0\\).\n\nLa estructura del grafo puede accederse mediante las funciones:\n\n\\(in(G, v) = \\{ u \\mid (u, v) \\in E\\}\\)\n\\(out(G, u) = \\{ v \\mid (u, v) \\in E\\}\\)\n\nasí como el número de vertices que entran y salen como:\n\n\\(indegree(G, v) = |in(G, v)|\\).\n\\(outdegree(G, u) = |out(G, u)|\\).\n\nUn grafo puede tener aristas no dirigidas, el grafo con \\(B=(\\{a, b, c, d\\}, \\{\\{a, b\\}, \\{b, c\\}, \\{c, d\\}, \\{d, a\\}\\})\\), no reconocerá orden en las aristas.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\nd\n\nd\n\n\n\nc--d\n\n\n\n\nd--a\n\n\n\n\n\n\n\nFigura 3.4: Un grafo cuyas aristas no estan dirigidas\n\n\n\n\n\nPor lo tanto, podremos decir que \\((a, b) \\in E_A\\) pero \\((b, a) \\not\\in E_A\\). Por otro lado tenemos que \\(\\{a, b\\} \\in E_B\\), y forzando un poco la notación, \\((a, b) \\in E_B\\), \\((b, a) \\in E_B\\); para los conjuntos de aristas de \\(A\\) y \\(B\\). La estructura puede ser accedida mediante \\(neighbors(G, u) = \\{ v \\mid \\{u, v\\} \\in E \\}\\).\nUn grafo puede estar representado de diferentes maneras, por ejemplo, un arreglo bidimensional (matriz), donde \\(S_{ij} = 1\\) si hay una arista entre los vértices \\(i\\) y \\(j\\); y \\(S_{ij} = 0\\) si no existe una arista. A esta representación se le llama matriz de adjacencia. Si el grafo tiene pocos \\(1\\)’s vale la pena tener una representación diferente; este es el caso de las listas de adjacencia, donde se representa cada fila o cada columna de la matriz de adjacencia como una lista de los elementos diferentes de cero.\nExisten otras representaciones como la lista de coordenadas, coordinate lists (COO), o las representaciones dispersas compimidas, sparse row (CSR) y compressed sparse column (CSC) (Scott y Tůma 2023). Todas estas representaciones tratan de disminuir el uso de memoria y aprovechar la gran dispersión para realizar operaciones solo cuando sea estrictamente necesario.\nUn árbol es un grafo en el cual no existen ciclos, esto es, no existe forma que en una caminata sobre los vértices, a traves de las aristas y prohibiendo revisitar aristas, es imposible regresar a un vértice antes visto.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\nd\n\nd\n\n\n\na--d\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\ne\n\ne\n\n\n\nd--e\n\n\n\n\nf\n\nf\n\n\n\nd--f\n\n\n\n\n\n\n\nFigura 3.5: Árbol con aristas no dirigidas\n\n\n\n\n\nEn algunos casos, es conveniente identificar vértices especiales en un árbol \\(T=(V, E)\\). Un vértice es la raíz del árbol, \\(root(T)\\), es especial ya que seguramente se utilizará como acceso al árbol y por tanto contiene un camino a cada uno vértices en \\(V\\). Cada vértice puede tener o no hijos, \\(children(T, u) = \\{ v \\mid (u, v) \\in E \\}\\). Se dice que \\(u\\) es un hoja (leaf) si \\(children(T, u) = \\emptyset\\), e interno (inner) si no es ni raíz ni hoja.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na-&gt;b\n\n\n\n\n\nd\n\nd\n\n\n\na-&gt;d\n\n\n\n\n\nc\n\nc\n\n\n\nb-&gt;c\n\n\n\n\n\ne\n\ne\n\n\n\nd-&gt;e\n\n\n\n\n\nf\n\nf\n\n\n\nd-&gt;f\n\n\n\n\n\n\n\n\nFigura 3.6: Árbol con aristas dirigidas, note que es fácil saber si hay un vértice o nodo que se distinga como raíz, o nodos que sean hojas.\n\n\n\n\n\nAl igual que en los grafos más generales, en los árboles es útil definir funciones sobre vértices y aristas, así como marcar tipos de vértices, e.g., posición u color, que simplifiquen el razonamiento para con los algoritmos asociados.\nLos nodos y las aristas de un grafo pueden recorrerse de diferentes maneras, donde se aprovechan las relaciones representadas. En un grafo general podría ser importante solo visitar una vez cada vértice, o guiarse en el recorrido por alguna heurística o función asociada a vértices o aristas.\nEl recorrido primero a lo profundo, Depth First Search (DFS), comienza en un nodo dado y de manera voraz avanzará recordando orden de visita y avanzando al ver un nuevo nodo repitiendo el procedimiento hasta que todos los vértices alcanzables sean visitados. El siguiente pseudo-código lo implementa:\n#| lst-label: lst-dfs\n#| lst-cap: Psudo-código DFS\n\nfunction operación!(vértice)\n  #... operaciones sobre el vértice siendo visitado ...\nend\n\nfunction DFS(grafo, vértice, visitados)\n  operación!(vértice)\n  push!(visitados, vértice)\n  for v in neighbors(grafo, vértice)\n    if v ∉ visitados\n      operación!(v)\n      push!(visitados, v)\n      DFS(grafo, v, visitados)\n    end\n  end\nend\n\n# ... código de preparación del grafo\nvisitados = Set()\nDFS((vértices, aristas), vérticeinicial, visitados)\n# ... código posterior a la visita DFS\nLas llamadas recursivas a DFS tienen el efecto de memorizar el orden de visita anterior y regresarlo cuando se sale de este, por lo que hay una memoria implicita utilizada, implementanda por el stack de llamadas. La función operación! es una abstracción de cualquier cosa que deba hacerse sobre los nodos siendo visitados.\nEl recorrido a lo ancho, Breadth First Search (BSF), visita los vértices locales primero que los alejados contrarío al avance voraz utilizado por DFS.\n#| lst-label: lst-bfs\n#| lst-cap: Psudo-código BFS\n\nfunction BFS(grafo, vértice, visitados, cola)\n  operación!(vértice)\n  push!(visitados, vértice)\n  push!(cola, vértice)\n\n  while length(cola) &gt; 0\n    u = popfirst!(cola)\n    for v in neighbors(grafo, u)\n      if v ∉ visitados\n        operación!(v)\n        push!(visitados, v)\n        push!(cola, v)\n      end\n    end\n  end\nend\n\n# ... código de preparación del grafo\nvisitados = Set()\nBFS((vértices, aristas), vérticeinicial, visitados)\n# ... código posterior a la visita BFS\nEl BFS hace uso explícito de la memoria para guardar el orden en que se visitarán los vértices (cola); se utiliza un conjunto para marcar vértices ya visitados (visitados) con la finalidad de evitar un recorrido infinito.\n\n3.5.1.1 Ejercicios\n\nImplemente un grafo dirigido mediante listas de adyacencia.\nImplemente un grafo no dirigido mediante lista de adyacencia.\nImplemente el algoritmo de recorrido DFS y BFS con implementaciones de grafos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#actividades",
    "href": "cap3-estructuras.html#actividades",
    "title": "3  Estructuras de datos elementales",
    "section": "3.6 Actividades",
    "text": "3.6 Actividades\nImplementar los siguientes algoritmos sobre matrices. - Multiplicación de matrices - Eliminación gaussiana / Gauss-Jordan Compare los desempeños de ambos algoritmos contando el número de operaciones y el tiempo real para matrices aleatorias de tamaño ( n n ) para ( n= 100, 300, 1000). Maneje de manera separada los datos de conteo de operaciones (multiplicaciones y sumas escalares) y las de tiempo real. Discuta sus resultados experimentales; ¿qué puede concluir? ¿Cuál es el impacto de acceder los elementos contiguos en memoria de una matriz? ¿Qué cambiaría si utiliza matrices dispersas? ¿Cuáles serían los costos?\nEntregable\nSu trabajo se entregará en PDF y con el notebook fuente; deberá estar plenamente documentado, con una estructura que permita a un lector interesado entender el problema, sus experimentos y metodología, así como sus conclusiones. Tenga en cuenta que los notebooks pueden alternar celdas de texto y código.\nNo olvide estructurar su reporte, en particular el reporte debe cubrir los siguientes puntos:\n\nTítulo del reporte, su nombre.\nIntroducción.\nCódigo cercano a la presentación de resultados.\nFiguras y tablas\nAnálisis de los resultados\nConclusión, discusiones de las preguntas\nLista de referencias. Nota, una lista de referencias que no fueron utilizadas en el cuerpo del texto será interpretada como una lista vacía.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#bibliografía",
    "href": "cap3-estructuras.html#bibliografía",
    "title": "3  Estructuras de datos elementales",
    "section": "3.7 Bibliografía",
    "text": "3.7 Bibliografía\nCormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2022). Introduction to Algorithms (2nd ed.). MIT Press.\n\nParte III: Cap 10 Elementary Data Structures.\nParte VI: Cap 22 Elementary Graph Algorithms.\nParte VII: Cap 28 Matrix Operations.\n\n\n\n\n\n\n\nScott, Jennifer, y Miroslav Tůma. 2023. “An Introduction to Sparse Matrices”. En Algorithms for Sparse Linear Systems, 1–18. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-25820-6_1.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html",
    "href": "cap4-ordenamiento.html",
    "title": "4  Algoritmos de ordenamiento",
    "section": "",
    "text": "Objetivo\nImplementar y analizar algoritmos de ordenamiento de arreglos con costo óptimo en el peor caso, así como algoritmos adaptativos a la entrada para caracterizar su desempeño bajo un enfoque experimental para la solución efectiva de problemas informáticos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#introducción",
    "href": "cap4-ordenamiento.html#introducción",
    "title": "4  Algoritmos de ordenamiento",
    "section": "4.1 Introducción",
    "text": "4.1 Introducción\nEn este tema se aborda el ordenamiento basado en comparación, esto es, existe un operador \\(&lt;\\) que es capaz de distinguir si un elemento \\(a\\) es menor que un elemento \\(b\\).\nEl operador cumple con las siguientes propiedades:\n\nsi \\(a &lt; b\\) y \\(b &lt; c\\) entonces \\(a &lt; c\\) (transitividad); e.g., \\(1 &lt; 10\\) y \\(10 &lt; 100\\) entonces \\(1 &lt; 100\\).\ntricotomía:\n\nsi \\(a &lt; b\\) es falso y \\(b &lt; a\\) es falso, entonces \\(a = b\\) (antisímetria); dicho de otras formas:\n\nsi \\(a\\) no es menor que \\(b\\) ni \\(b\\) menor que \\(a\\) entonces \\(a\\) es igual a \\(b\\),\ndesvelando variables, \\(1 &lt; 1\\) es falso, el intercambio es obvio, entonces \\(1=1\\).\n\nen otro caso, \\(a &lt; b\\) o \\(a &lt; b\\).\n\n\n\n\nUsar un operador como \\(&lt;\\) es suficiente para crear algoritmos correctos y eficientes, sin embargo, en la práctica y en una computadora real, también es válido utilizar operadores como \\(=\\) o \\(\\leq\\), o intercambiar por \\(&gt;\\) y \\(\\geq\\) según convenga. No hay impacto en la eficiencia.\nSin perdida de generalidad, podemos planter el problema de ordenamiento sin permitir repeticiones como sigue: dado un arreglo \\(A[1, n] = a_1, a_2, \\cdots, a_n\\); un algoritmo de ordenamiento obtiene la permutación \\(\\pi\\) tal que \\(a_{\\pi(1)} &lt; a_{\\pi(2)} &lt; \\cdots &lt; a_{\\pi(n)}\\).\n\n\nCuando se permiten elementos repetidos, se le llama ordenamiento estable i se asegura que en el arreglo ordenado se preserven el orden original posicional cuando \\(a = b\\). Esta propiedad es importante cuando hay datos satélitales asociados a la llave de comparación.\nEn términos prácticos, la idea es reorganizar \\(A\\), mediante el cálculo implicito de la permutación \\(\\pi\\), de tal forma que después de terminar el proceso de ordenamiento se obtenga que \\(A\\) esta ordenado, i.e., \\(a_i \\leq a_{i+1}\\). En sistemas reales, el alojar memoria para realizar el ordenamiento implica costos adicionales, y es por esto muchas veces se busca modificar directamente \\(A\\).\n\n\nUtilizar \\(\\pi\\) solo es necesario cuando no es posible modificar \\(A\\). También es muy común utilizar datos satélite asociados con los valores a comparar, de esta manera es posible ordenar diversos tipos de datos. Un ejemplo de esto es ordenar un dataframe, pero también estructuras de datos donde existe un campo especial y el resto de los datos asociados es de importancia para una aplicación.\n\n4.1.1 Costo del problema\nPara una entrada de tamaño \\(n\\) existen \\(n!\\) permutaciones posibles; cada una de estas permutaciones es una instancia del problema de ordenamiento de tamaño \\(n\\).\nExiste una permutación objetivo \\(\\pi^*\\), i.e., que cumple con la definición de que esta ordenada; ahora pensemos en un grafo donde cada \\(\\pi_i\\) esta conectada con todas las permutaciones en las que se puede transformar haciendo una única operación, e.g., intercambiando un elemento. El algoritmo forma ese grafo con sus posibles decisiones, por lo que el camino más largo i.e., ruta sin ciclos, entre cualquier \\(\\pi_i\\) y la permutación \\(\\pi^*\\) es el costo de peor caso del algoritmo.\nAhora, cada operación que realicemos en un algoritmo nos acercará más a \\(\\pi^*\\), descartando una cierta cantidad de instancias posibles pero no viables; si nuestra función de transición en el grafo viene dada con respecto a colocar cada par de elementos en su orden relativo, entonces, la mitad de las permutaciones se han descartado, ya que ese par no puede estar en el orden contrario. Por tanto, el costo de cualquier algoritmo que realice comparaciones y descarte la mitad del espacio de búsqueda, es \\(\\log_2(n!)\\), que usando la aproximación de Stirling,1 lo podemos reescribir como sigue:\n\\[\\log_2(n!) = n \\log_2 n - n \\log_2 e + O(\\log_2 n)\\]\nEsto se puede simplemente escribir como \\(O(n \\log n)\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#algoritmos-de-ordenamiento",
    "href": "cap4-ordenamiento.html#algoritmos-de-ordenamiento",
    "title": "4  Algoritmos de ordenamiento",
    "section": "4.2 Algoritmos de ordenamiento",
    "text": "4.2 Algoritmos de ordenamiento\nExisten muchos algoritmos que pueden resolver el problema de ordenamiento, es común contar el número de comparaciones ya que produce la información necesaria para la navegación en el grafo de instancias; también es común contar las operación de intercambiar elementos. Las pruebas y la navegación en el grafo determina el costo del algoritmo. Es necesario mencionar que mover datos entre diferentes zonas de memoria puede llegar a ser más costoso que solo acceder a esas zonas por lo que hay una asimetría en el costo de estas dos operaciones.\nNote que algunos de los algoritmos más simples pueden tener un comportamiento oportunistas y que son capaces de obtener ventaja en instancias sencillas, por lo que no debería saltarse esas secciones si solo conoce su comportamiento en peor caso.\n\n4.2.1 Bubble sort\nEl algoritmo de ordenamiento de burbuja o bubble sort realiza una gran cantidad de comparaciones, como puede verse en Listado 4.1, el algoritmo usa dos ciclos anidados para realizar una comparación y una posible transposición, formando un triángulo, i.e., \\[ \\sum_{i=1}^{n-1} \\sum_{j=1}^{n-i} O(1);\\] por lo tanto su costo esta dominado por el triangulo formado, i.e., \\(\\sim n^2/2\\) lo que puede escribirse simplemente como \\(O(n^2)\\).\n\n\n\n\nListado 4.1: Bubble sort de peor caso\n\n\nfunction bubble_sort!(A)\n  n = length(A)\n  for i in 1:n-1\n    for j in 1:n-i\n      if A[j] &gt; A[j+1]\n        A[j], A[j+1] = A[j+1], A[j]\n      end\n    end\n  end\n  \n  A\nend\n\nbubble_sort!([8, 4, 3, 1, 6, 5, 2, 7])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nCiclo que recorre \\(n-1\\) veces todo el arreglo; y pone el elemento máximo en su posición final.\nCiclo que recorre \\(n-i\\) veces el arreglo; ya que en cada corrida se pone el máximo en su posición.\nIntercambio cuando hay pares en desorden.\n\nEl algoritmo mostrado en Listado 4.1 es un algoritmo de peor caso, ya que sin importar la complejidad de la instancia (i.e., que tal alejada esta \\(\\pi_i\\) de \\(\\pi^*\\)), se comporta igual.\nEs relativamente fácil hacer un bubble sort que tenga en cuenta la complejidad de la instancia, medida como el número de intercambios necesarios.\n\n\n\n\nListado 4.2: Bubble sort adaptable\n\n\nfunction adaptive_bubble_sort!(A)\n  n = length(A)\n\n  for i in 1:n-1     \n    s = 0            \n    for j in 1:n-i\n      if A[j] &gt; A[j+1]\n        s += 1\n        A[j], A[j+1] = A[j+1], A[j] \n      end\n    end\n    s == 0 && break\n  end\n  \n  A\nend\n\nadaptive_bubble_sort!([7, 8, 4, 3, 1, 6, 5, 2])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nLa idea es que si no hay intercambios en una iteración, entonces el arreglo ya esta ordenado.\nContador de intercambios.\nCondición de paro, i.e., no hubo intercambios.\n\nEn la forma Listado 4.2, bubble sort es capaz de términar en \\(n-1\\) comparaciones si el arreglo esta ordenado; sacando provecho de casos simples en términos de instancias casi ordenadas.\n\n\n4.2.2 Insertion sort\nEl algoritmo de ordenamiento por inserción o insertion sort es un algoritmo simple que al igual que bubble sort tiene un mal peor caso y puede aprovechar casos simples\n\n\n\n\nListado 4.3: Algoritmo insertion sort\n\n\nfunction insertion_sort!(A)\n  n = length(A)\n  for i in 2:n\n    key = A[i]\n    j = i - 1   \n    while j &gt;= 1 && A[j] &gt; key\n      A[j + 1] = A[j]\n      j -= 1\n    end\n\n    A[j + 1] = key\n  end\n  \n  A\nend\n\ninsertion_sort!([5, 1, 4, 8, 2, 6, 3, 7])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nEl algoritmo comienza en la segunda posición del arreglo y revisará todos los elementos.\nEs importante hacer una copia de key para simplificar la implementación.\nLa idea general es ordenar las posiciones de \\(1..i\\), para esto se debe recorrer hacia atrás el arreglo completo, para determinar la posición de inserción de key.\nIntercambio de elementos para colocar key en su lugar ordenado.\nkey se pone en su lugar final.\n\nPara analizar Listado 4.3, es importante notar que el ciclo más externo termina con el subarreglo \\(A[1..i]\\) ordenado; por lo que cuando se comienza el ciclo, si key se prueba estar en su posición correcta, entonces ya no es necesario revisar el resto del subarreglo, esto determina que un arreglo ordenado tendrá un costo de \\(O(n)\\) comparaciones; si esta casi ordenado en términos del número de intercambios necesarios, entonces, el algoritmo se adaptará sacando provecho de la instancia.\nEn el peor caso de insertion sort, el algoritmo no puede parar de manera prematura, e.g., un arreglo en orden reverso, el ciclo for se ejecutara \\(n-1\\) veces, mientras que el ciclo while deberá revisar el subarreglo completo en cada iteración, sumando un costo de \\(i\\) operaciones en cada iteración, i.e., \\(\\sum_{i=1}^n i\\), esta forma produce un triángulo, resultando en un costo \\(O(n^2)\\).\n\n\n4.2.3 Quick sort\nQuick sort (ver Cormen et al. 2022, cap. 7) es un algoritmo tipo dividir para vencer; esto es, un algoritmo que divide un problema grande en instancias pequeñas más sencillas. Es uno de los algoritmos más veloces en la práctica por su buen manejo de memoria, aun cuando tiene un peor caso cuadrático, en promedio el costo es \\(O(n \\log n)\\).\n\n\n\n\nListado 4.4: Algoritmo quick sort.\n\n\nusing Random\n\nfunction qsort!(A, low=1, high=length(A))\n  if low &lt; high\n      piv = part!(A, low, high)\n      qsort!(A, low, piv - 1)\n      qsort!(A, piv + 1, high)\n  end\n  \n  A\nend\n\nfunction part!(A, low, high)\n  ipiv = rand(low:high)\n  A[ipiv], A[high] = A[high], A[ipiv]\n  piv = A[high]\n\n  i = low - 1  # uno antes porque se accede después de un i+1\n  for j in low:high - 1\n      if A[j] &lt; piv\n          i += 1\n          A[i], A[j] = A[j], A[i]\n      end\n  end\n  \n  ipiv = i + 1\n  A[ipiv], A[high] = A[high], A[ipiv]\n  ipiv\nend\n\nqsort!([6, 8, 3, 7, 4, 1, 2, 5])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nEl arreglo se divide en 3 partes, ordenadas entre sí, un subarreglo izquierdo, un pivote, y un subarreglo derecho; los subarreglos no estan ordenados localmente, pero el pivote esta en su posición final.\nSe resuelve el problema izquierdo y el problema derecho por separado.\nLa función part! particiona el arreglo \\(A[low:end]\\) en 3 partes como se específico en el punto 1; para eso selecciona de manera aleatoria un pivote. Lo ponemos al final del arreglo para simplificar el código siguiente.\nEste ciclo itera por todo el subarreglo, su objetivo es asegurar que \\(A[i] &lt; piv\\) para todo \\(i \\in low:piv-1\\) y \\(piv &lt; A[i]\\) para todo \\(i \\in piv+1:high\\).\nIntercambia elementos si \\(A[j] &lt; piv\\), hacemos seguimiento de \\(i\\) ya que esta posición determinará al pivote.\nComo piv se encontraba en high, entonces hay que intercambiarlos para que qsort! sepa como manejarlos; recordando que los subarreglos no estan ordenados dentro de sí.\n\nEl código Listado 4.4 es relativamente simple, usa recurrencias sobre qsort! sobre dos partes extremas divididas por un pivote; estos tres elementos son encontrados en part!. La función part! es muy eficiente en términos de memoria, lo que puede hacer la diferencia en la práctica. La correcta selección del pivote es muy importante para evitar casos malos, i.e., costo cuadrático; en esta implementación se realiza una selección aleatoría de pivote que funcionará en la mayoría de los casos.\nEl peor de los casos en qsort! es debido a una mala selección del pivote, de tal forma que \\[|A[low:piv-1]| \\ll |A[piv+1:high]|,\\] o lo contrario en toda selección, en el extremo una de los subarreglos puede verse como de tamaño constante o cero, i.e., selección de pivote como el minimo o el máximo. Esta estrategía reduce a qsort! a un costo \\(O(n^2)\\).\nSi se realiza un particionado donde \\[|A[low:piv-1]| \\approx |A[piv+1:high]|,\\] entonces tenemos un algoritmo \\(O(n \\log n)\\); ya que hace una división en dos partes casi iguales en cada recurrencia a qsort!, y esto solo puede profundizar a \\(\\log n\\) veces, y en cada nivel part! tiene un costo lineal.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#skip-list",
    "href": "cap4-ordenamiento.html#skip-list",
    "title": "4  Algoritmos de ordenamiento",
    "section": "4.3 Skip list",
    "text": "4.3 Skip list\nUna skip list (Pugh 1990) es una lista ligada con capacidades de búsqueda eficiente con garantías probabilísticas, esto es que se cumplen con alta probabilidad. Para esto, la idea es que cada dato tiene asociado un arreglo de punteros o referencias hacia nodos sucesores, i.e., los nodos a nivel \\(i\\) se conectan con el siguiente nodo a nivel \\(i\\). En el nivel más bajo, la skip list es una simple lista ligada, mientras que sube, se vuelve más dispersa dando saltos más largos.\n\n\n\n\n\n\n\n\nlista\n\n\n\nhead\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\n(head)\n\n\n\na\n\n(2)\n\n(1)\n\na\n\n\n\nhead:1-&gt;a:1\n\n\n\n\n\nhead:2-&gt;a:2\n\n\n\n\n\n\ne\n\n(3)\n\n(2)\n\n(1)\n\ne\n\n\n\nhead:3-&gt;e:3\n\n\n\n\n\nh\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\nh\n\n\n\nhead:e-&gt;h:w\n\n\n\n\n\nb\n\n(1)\n\nb\n\n\n\na:1-&gt;b:1\n\n\n\n\n\n\nc\n\n(2)\n\n(1)\n\nc\n\n\n\na:2-&gt;c:2\n\n\n\n\n\nb:1-&gt;c:1\n\n\n\n\n\n\nd\n\n(1)\n\nd\n\n\n\nc:1-&gt;d:1\n\n\n\n\n\n\nc:2-&gt;e:2\n\n\n\n\n\nd:1-&gt;e:1\n\n\n\n\n\n\nf\n\n(1)\n\nf\n\n\n\ne:1-&gt;f:1\n\n\n\n\n\n\ng\n\n(2)\n\n(1)\n\ng\n\n\n\ne:2-&gt;g:2\n\n\n\n\n\ne:3-&gt;h:3\n\n\n\n\n\nf:1-&gt;g:1\n\n\n\n\n\n\ng:1-&gt;h:1\n\n\n\n\n\ng:2-&gt;h:2\n\n\n\n\n\n\ni\n\n(1)\n\ni\n\n\n\nh:1-&gt;i:1\n\n\n\n\n\n\nj\n\n(3)\n\n(2)\n\n(1)\n\nj\n\n\n\nh:2-&gt;j:2\n\n\n\n\n\nh:3-&gt;j:3\n\n\n\n\n\ntail\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\n(tail)\n\n\n\nh:e-&gt;tail:w\n\n\n\n\n\ni:1-&gt;j:1\n\n\n\n\n\n\nj:1-&gt;tail:1\n\n\n\n\n\nj:2-&gt;tail:2\n\n\n\n\n\nj:3-&gt;tail:3\n\n\n\n\n\n\n\n\n\nFigura 4.1: Ejemplo de una skip list\n\n\n\n\n\nA diferencia de los algoritmos vistos anteriormente, en este caso, ya se tiene una estructura de datos, que conlleva un costo en memoría explícito por nodo. Figura 4.1 ilustra la estructura.\nLa altura de cada nodo es calculada de manera probabilística, dada la probababilidad \\(p\\). Un valor común de \\(p=0.5\\). La altura de cada nodo se calcula como sigue:\n\nfunction levels(p)\n  i = 1\n  while rand() &lt; p\n    i += 1\n  end\n\n  i\nend\n\nlevels (generic function with 1 method)\n\n\nSi tenemos \\(n\\) evaluaciones de levels, Los niveles pequeños son relativamente probables, mientras que niveles grandes son relativamente poco probables. De hecho, los niveles \\(\\log_{1/p} n\\) son cercanos a una constante, \\(\\log_{1/p}{n} - 1\\) son \\(1/p\\) veces la constante, \\(\\log_{1/p}{n} - 2\\) son \\(1/p^2\\) veces la constante, etc.\nA diferencia de los algoritmos anteriores, una skip list comienza vacia, y se va poblando insertando elementos a la lista. Se va colocando en la posición que no viola el orden; generando el nodo correspondiente con nivel calculado. Los nodos especiales head y tail siempre tienen el nivel máximo posible. La inserción de un valor encapsulado en el nodo \\(u\\) comienza por visitar el máximo nivel en head e ir bajando hasta determinar \\(u.dato &gt; head[level].dato\\); en ese momento se debe avanzar al nodo apuntado por \\(head[level]\\) y repetir el algoritmo hasta que \\(level=1\\), en cuyo caso encontramos el lugar de inserción del nuevo dato. Se procede a reasignar los punteros de los sucesores y ajustar los punteros hacia los nodos sucesores a los niveles que tiene \\(u\\).\nCada inserción tiene un costo \\(O(\\log_{1/p} n)\\), garantía probabilística; por lo que insertar \\(n\\) elementos tiene un costo: \\[ \\sum_{i=1}^n O(\\log_{1/p} i) = O(\\log_{1/p} \\prod_{i=1}^n i) = O(\\log_{1/p} {n!}) = O(n \\log n); \\] usando la aproximación de Stirling.\nA diferencia de la versión basada en arreglos, una skip list es capaz de aceptar nuevos elementos y mantener el orden de manera eficiente.\n\n4.3.1 Ejercicios:\n\nInvestigue, implemente y pruebe merge sort. 1.1 ¿Cuales son las ventajas y desventajas de merge sort? 1.2 ¿Por qué merge sort se puede utilizar en algoritmos paralelos y otros pueden tener muchas dificultades? 1.3 ¿Cómo se puede reducir la memoria extra necesaria de merge sort?\nInvestigue, implemente y pruebe heap sort. 2.1 ¿Cuales son las ventajas y desventajas de heap sort?\n¿Cuál es el costo en memoria de una skip list?. 3.1 Investigue, implemente y pruebe un skip list.\nInvestigue, implemente y pruebe un árbol binario de búsqueda.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#lecturas",
    "href": "cap4-ordenamiento.html#lecturas",
    "title": "4  Algoritmos de ordenamiento",
    "section": "4.4 Lecturas",
    "text": "4.4 Lecturas\nLas lecturas de este tema corresponden al capítulo 5 de (Knuth 1998), en específico 5.2 Internal sorting. También se recomienda leer y comprender la parte II de (Cormen et al. 2022), que corresponde a Sorting and order statistics, en partícular Cap. 6 y 7, así como el Cap. 8.1. El artículo de wikipedia https://en.wikipedia.org/wiki/Sorting_algorithm también puede ser consultado con la idea de encontrar una explicación rápida de los algoritmos.\nEn la práctica, pocos algoritmos son mejores que quicksort. En (Loeser 1974) se detalla una serie de experimentos donde se compara quicksort contra otros algoritmos relacionados; por lo que es una lectura recomendable.\nLa parte adaptable, esto es para algoritmos oportunistas que toman ventaja de instancias simples, esta cubierta por el artículo (Estivill-Castro y Wood 1992). En especial, es muy necesario comprender las secciones 1.1 y 1.2, el resto del artículo debe ser leído aunque no invierta mucho tiempo en comprender las pruebas expuestas si no le son claras. En especial, en las secciones indicadas se establecen las medidas de desorden contra las cuales se mide la complejidad. En (Cook y Kim 1980) realiza una comparación del desempeño de varios algoritmos para ordenamiento de listas casi ordenadas, esto es, en cierto sentido donde los algoritmos adaptables tienen sentido. Este artículo es anterior a (Estivill-Castro y Wood 1992) pero tiene experimentos que simplifican el entendimiento de los temas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#material-audio-visual-sobre-algoritmos-de-ordenamiento",
    "href": "cap4-ordenamiento.html#material-audio-visual-sobre-algoritmos-de-ordenamiento",
    "title": "4  Algoritmos de ordenamiento",
    "section": "4.5 Material audio-visual sobre algoritmos de ordenamiento",
    "text": "4.5 Material audio-visual sobre algoritmos de ordenamiento\n\n\n\n\n\n\n\n\nCook, Curtis R, y Do Jin Kim. 1980. “Best sorting algorithm for nearly sorted lists”. Communications of the ACM 23 (11): 620–24.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, y Clifford Stein. 2022. Introduction to algorithms. MIT press.\n\n\nEstivill-Castro, Vladmir, y Derick Wood. 1992. “A survey of adaptive sorting algorithms”. ACM Computing Surveys (CSUR) 24 (4): 441–76.\n\n\nKnuth, Donald. 1998. The Art Of Computer Programming, vol. 3 (2nd ed): Sorting And Searching. Vol. 3. Redwood City, CA, USA.: Addison Wesley Longman Publishing Co. Inc.\n\n\nLoeser, Rudolf. 1974. “Some performance tests of ‘quicksort’ and descendants”. Communications of the ACM 17 (3): 143–52.\n\n\nPugh, William. 1990. “Skip lists: a probabilistic alternative to balanced trees”. Commun. ACM 33 (6): 668–76. https://doi.org/10.1145/78973.78977.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#footnotes",
    "href": "cap4-ordenamiento.html#footnotes",
    "title": "4  Algoritmos de ordenamiento",
    "section": "",
    "text": "Aproximación de Stirling https://en.wikipedia.org/wiki/Stirling%27s_approximation.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html",
    "href": "cap5-busqueda.html",
    "title": "5  Algoritmos de búsqueda en el modelo de comparación",
    "section": "",
    "text": "5.0.1 Listas ordenadas\nEsta unidad esta dedicada a la implementación y análisis de algoritmos de búsqueda sobre arreglos ordenados, esto es que presentan un orden total. Un arreglo es una estructura lineal de elementos contiguos en memoría donde la posición es importante. En esta unidad se estudian algoritmos que para localizar elementos que cumplan con predicados simples de orden. Como restricción adicional, se limita la duplicidad de elementos en los arreglos, esto sin reducir la generalidad de los algoritmos estudiados. Para cualquier tripleta de elementos \\(a, b, c\\) en el a arreglo se cumple lo siguiente:\nNote que dada la condición de arreglo consecutivo en memoria, para dos elementos \\(u_i\\) y \\(u_j\\), donde \\(i\\) y \\(j\\) son posiciones:\nLos algoritmos tomarán ventaja de este hecho para localizar de manera precisa y eficiente elementos deseados, descritos mediante los mismos operadores.\nEn esta unidad se aborda la búsqueda en arreglos ordenados, y abusando del término, muchas veces les llamaremos listas ordenadas. Recuerde que a lo largo de este curso, esta será nuestra representación para conjuntos.\nEn la literatura es común que se aborde el tema con un modelo de costo basado en comparaciones, esto es, cada comparación \\(\\le\\) provoca costo constante \\(O(1)\\). Este curso no es la excepción. La comparación como unidad de costo es un excelente factorizador de las operaciones satelitales en los algoritmos de búsqueda; esto debería quedar claro una vez que se comprendan los algoritmos.\nUtilizaremos como base el artículo (Jon Louis Bentley y Yao 1976), que es de lectura forzosa. Nos apoyaremos en una serie de lecturas adicionales para comprender y madurar el concepto.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Algoritmos de búsqueda en el modelo de comparación</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#material-audio-visual",
    "href": "cap5-busqueda.html#material-audio-visual",
    "title": "5  Algoritmos de búsqueda en el modelo de comparación",
    "section": "5.1 Material audio-visual",
    "text": "5.1 Material audio-visual\nEn el siguiente video se adentraran en diferentes estrategías de búsqueda, notoriamente aquellas que llamaremos oportunistas o adaptables (adaptative). Estas técnicas nos permitirán tomar provecho de instancias sencillas de problemas e incrementar el desempeño en ese tipo de instancias.\nTenga en cuenta que, honrando la literatura, usaremos de forma indiscriminada listas ordenadas como sinónimo de arreglos ordenados.\n\n5.1.1 Búsqueda",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Algoritmos de búsqueda en el modelo de comparación</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#actividades",
    "href": "cap5-busqueda.html#actividades",
    "title": "5  Algoritmos de búsqueda en el modelo de comparación",
    "section": "5.2 Actividades",
    "text": "5.2 Actividades\n\n5.2.1 Actividad 0 [sin entrega]\nRealizar las actividades de lectura y comprensión, apoyosé en el video de esta unidad. De preferencia realice los ejercicios de las secciones relacionadas.\n\nEl artículo sobre búsqueda no acotada, como representativo sobre búsqueda adaptativa (Jon Louis Bentley y Yao 1976).\nCap. 12 de (Sedgewick 1998), en partícular Sec. 12.3 y 12.4.\nCap. 6 de (Knuth 1998), en partícular Sec. 6.1 y 6.2.\nEl artículo sobre búsqueda adaptativa secuencial (Jon L. Bentley y McGeoch 1985).\nRecuerde la referencia básica para la notación y conceptos es (Cormen et al. 2022).\n\n\n\n5.2.2 Actividad 1 [con reporte]\nRealice y reporte el siguiente experimento:\n\nUse el archivo listas-posteo-100.json, contiene las 100 listas de posteo más frecuentes, se encuentran en formato JSON.\nUtilice las listas (sin el término asociado).\nLos usuarios de Julia deberán asegurar que los tipos de los arreglos es Int y no Any para asegurar la velocidad adecuada\nSeleccione 1000 identificadores de documentos al azar, entre \\(1\\) y \\(n\\), recuerde que \\(n=50,000\\).\nGrafique el tiempo promedio de buscar los 1000 identificadores en todas las listas (un solo número que represente las \\(100\\times 1000\\) búsquedas). Nota: lo que determinará al buscar es la posición de inserción que se define como el lugar donde debería estar el identificador si se encontrara en la lista.\nLos algoritmos que caracterizará son los siguientes (nombres con referencia a (Jon Louis Bentley y Yao 1976)):\n\nBúsqueda binaria acotada\nBúsqueda secuencial \\(B_0\\)\nBúsqueda no acotada \\(B_1\\)\nBúsqueda no acotada \\(B_2\\)\nImportante: Tal vez deba repetir varias veces cada búsqueda si los tiempos son muy pequeños.\n\nBosqueje en pseudo-código la implementación de la búsqueda casí optima \\(B_k\\)\n\n\n\n5.2.3 Entregable\nEl reporte deberá ser en formato notebook y el PDF del mismo notebook. El notebook debe contener las implementaciones de los algoritmos solicitados. Recuerde que el reporte debe llevar claramente su nombre, debe incluir una introducción, la explicación de los experimentos realizados, las observaciones, conclusiones y bibliografía.\nNota: En las implementaciones podrá usar comparación \\(&lt;, \\leq\\), o incluso \\(cmp \\rightarrow \\{-1, 0, 1\\}\\), teniendo en cuenta que \\(cmp\\) es común en lenguajes modernos, solo debe indicarlo.\n\n\n5.2.4 Actividad 2 [sin entrega]\nRevisar el notebook crear-indice-invertido.ipynb para los detalles de como se generó la lista de posteo. Usted puede crear nuevas listas de posteo si lo desea usando los conjuntos de datos disponibles (listados en dicho notebook), y a su vez utilizarlas en las actividades de este Unidad. Solo deberá indicarlo; recuerde que los números de documentos y tamaño de vocabulario cambiarán.\n\n\n5.2.5 Leyendo las listas de posteo\nUsted no necesita generar las listas de posteo, solo leer las que se le han proporcionado en el archivo listas-posteo-100.json que corresponden a las 100 listas de posteo más pobladas (100 terminos más usados en el conjunto de datos). En el archivo listas-posteo-100.json , cada linea un JSON valido, donde se tiene el término y la lista de posteo.\n\nEn el notebook lectura-listas-de-posteo.ipynb se muestra como se leen las listas de posteo desde Julia\n\n\n\n\n\n\n\nBentley, Jon L., y Catherine C. McGeoch. 1985. “Amortized analyses of self-organizing sequential search heuristics”. Commun. ACM 28 (4): 404–11. https://doi.org/10.1145/3341.3349.\n\n\nBentley, Jon Louis, y Andrew Chi-Chih Yao. 1976. “An almost optimal algorithm for unbounded searching”. Information Processing Letters 5 (3): 82–87. https://doi.org/https://doi.org/10.1016/0020-0190(76)90071-5.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, y Clifford Stein. 2022. Introduction to algorithms. MIT press.\n\n\nKnuth, Donald. 1998. The Art Of Computer Programming, vol. 3 (2nd ed): Sorting And Searching. Vol. 3. Redwood City, CA, USA.: Addison Wesley Longman Publishing Co. Inc.\n\n\nSedgewick, Robert. 1998. Algorithms in c++, parts 1-4: fundamentals, data structure, sorting, searching. Addison-Wesley-Longman, 1998.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Algoritmos de búsqueda en el modelo de comparación</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html",
    "href": "cap6-intersecciones.html",
    "title": "6  Algoritmos de intersección de conjuntos con representación de listas ordenadas",
    "section": "",
    "text": "Objetivo\nImplementar y comparar algoritmos de intersección de conjuntos representados como listas ordenadas, utilizando una variedad de algoritmos de búsqueda que dan diferentes propiedades a los algoritmos de intersección.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmos de intersección de conjuntos con representación de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#introducción",
    "href": "cap6-intersecciones.html#introducción",
    "title": "6  Algoritmos de intersección de conjuntos con representación de listas ordenadas",
    "section": "6.1 Introducción",
    "text": "6.1 Introducción\nEn este tema se conocerán, implementarán y compararán algoritmos de intersección de listas ordenadas. El cálculo de la intersección es un proceso costoso en una máquina de búsqueda, sin embargo, es un procedimiento esencial cuando se trabaja con grandes colecciones de datos.\nEl índice invertido tal y como lo hemos creado, es capaz de manejar una cantidad razonablemente grande de documentos. Para asegurarnos del escalamiento con la cantidad de documentos, es necesario utilizar algoritmos de intersección que sean eficientes. Entonces, dadas las listas ordenadas \\(L_1, \\cdots, L_k\\) (e.g, correspondientes a las listas de posteo en un índice invertido), tomará dichas listas y producirá \\(L^* = \\bigcap_i L_i\\), esto es, si \\(u\\in L^*\\) entonces \\(u \\in L_i\\) para \\(1 \\leq i \\leq k\\).\nExisten varios algoritmos prominentes para llevar a cabo esta operación. Uno de los trabajos seminales viene de Hwang & Lin, en su algoritmo de merge entre dos conjuntos (Hwang y Lin 1971). En este trabajo se replantea el costo como encontrar los puntos de unión entre ambos conjuntos, esto se traslada de manera inmediata al problema de intersección. El problema correspondiente para intersectar dos conjuntos cualesquiera representados como conjuntos ordenados es entonces \\(\\log{{n+m} \\choose m}\\), que usando la aproximación de Stirling se puede reescribir como \\[n \\log \\frac{n}{m} + (n-m)\\log \\frac{n}{n-m},\\] donde \\(n\\) y \\(m\\) corresponden a al número de elementos en cada conjunto.\nUn algoritmo naïve para realizar la intersección, puede ser buscar todos los elementos del conjunto más pequeño en el más grande. Si para la búsqueda se utiliza búsqueda binaria, tenemos un costo de \\(m \\log n\\).\nEsta simple idea puede ser explotada y mejorada para obtener costos más bajos, por ejemplo, si en lugar de buscar sobre la lista más grande directamente, esta se divide en bloques de tamaño \\(m\\) para encontrar el bloque que contiene cada elemento (recuerde que el arreglo esta ordenado), para después buscar dentro del bloque. Haciendo esto, el costo se convierte en \\[ m \\log \\frac{n}{m} + m \\log m\\] cuyo costo se ajusta mejor al costo del problema. Este es el algoritmo propuesto, a groso modo, en (Hwang y Lin 1971).\nCuando \\(k&gt;2\\), la intersección se puede realizar usando las \\(k\\) listas a la vez, o se puede hace por pares. Se puede observar que la intersección de dos conjuntos da como resultado un conjunto igual o más pequeño que el más pequeño de los conjuntos intersectados. Adicionalmente, los conjuntos pequeños son “más faciles” de intersectar con un algoritmo na\"ive. Por tanto, una estrategía que funciona bien en el peor caso es intersectar los 2 arreglos más pequeños cada vez. Esta una idea muy popular llamada Small vs Small (SvS).\nExiste otra familia de algoritmos, basados en búsquedas adaptativas que pueden llegar a mejorar el desempeño bajo cierto tipo de entradas. En (Demaine, López-Ortiz, y Ian Munro 2001), (Barbay, López-Ortiz, y Lu 2006), (Barbay et al. 2010), y (Baeza-Yates y Salinger 2005) se muestran comparaciones experimentales de diversos algoritmos de intersección, entre ellos adaptables, que utilizan de manera creativa algoritmos de búsqueda adaptables para aprovechar instancias simples. Estos estudios se basan en contribuciones teoricas de los mismos autores (Demaine, López-Ortiz, y Munro 2000), (Demaine, López-Ortiz, y Ian Munro 2001), (Barbay y Kenyon 2002), (Baeza-Yates 2004).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmos de intersección de conjuntos con representación de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#recursos-audio-visuales-de-la-unidad",
    "href": "cap6-intersecciones.html#recursos-audio-visuales-de-la-unidad",
    "title": "6  Algoritmos de intersección de conjuntos con representación de listas ordenadas",
    "section": "6.2 Recursos audio-visuales de la unidad",
    "text": "6.2 Recursos audio-visuales de la unidad\nParte 1: Algoritmos de intersección (y unión) de listas ordenadas \nParte 2: Algoritmos de intersección y algunas aplicaciones",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmos de intersección de conjuntos con representación de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#actividades",
    "href": "cap6-intersecciones.html#actividades",
    "title": "6  Algoritmos de intersección de conjuntos con representación de listas ordenadas",
    "section": "6.3 Actividades",
    "text": "6.3 Actividades\nImplementación y comparación de diferentes algoritmos de intersección de conjuntos.\nLea cuidadosamente las instrucciones y desarrolle las actividades. Entregue el reporte correspondiente en tiempo.\n\n6.3.1 Actividad 0 [Sin entrega]\n\nLea y comprenda los artículos relacionados (listados en la introducción).\n\n\n\n6.3.2 Actividad 1 [Con reporte]\n\nCargue el archivo listas-posteo-100.json del tema 3. Si lo desea, puede usar listas de posteo generadas con otros conjuntos de datos, usando los scripts de las unidades pasadas. Si es necesario, repase los temas anteriores para recordar la naturaleza y propiedades de las listas.\n\n\nSea \\(P^{(2)}\\) el conjunto de todos los posibles pares de listas entre las 100 listas de posteo. Seleccione de manera aleatoria \\(A \\subset P^{(2)}\\), \\(|A| = 1000\\).\nSea \\(P^{(3)}\\) el conjunto de todas las posibles combinaciones de tres listas de posteo entre las 100 listas disponibles, Seleccione de manera aleatoria \\(B \\subset P^{(3)}\\), \\(|B| = 1000\\).\nSea \\(P^{(4)}\\) el conjunto de todas las posibles combinaciones de cuatro listas de posteo entre las 100 listas disponibles. Seleccione de manera aleatoria \\(C \\subset P^{(4)}\\), \\(|C| = 1000\\).\n\n\nImplemente los algoritmos de las secciones 3.1 Melding Algorithms y 3.2 Search algorithms (en especial 3.2.1 y 3.2.2) de (Barbay et al. 2010).\nRealice y reporte los siguientes experimentos:\n\n\nIntersecte cada par de listas \\(a, b \\in A\\), y reporte de manera acumulada el tiempo en segundos y el número de comparaciones.\nIntersecte cada tripleta de listas \\(a, b, c \\in B\\), y reporte de manera acumulada el tiempo en segundos y el número de comparaciones.\nIntersecte cada tetrapleta de listas \\(a, b, c, d \\in C\\), y reporte de manera acumulada el tiempo en segundos y el número de comparaciones.\nCree una figura boxplot que describa el tiempo en segundos para los tres experimentos.\nCree una figura boxplot que describa el número de comparaciones para los tres experimentos.\nCree una figura boxplot que describa las longitudes de las intersecciones resultantes para \\(A\\), \\(B\\), \\(C\\).\n\n\n\n6.3.3 Entregable\nEl reporte deberá ser en formato notebook y el PDF del mismo notebook. El notebook debe contener las implementaciones. Recuerde que el reporte debe llevar claramente su nombre, debe incluir una introducción, la explicación de los métodos usados, la explicación de los experimentos realizados, la discusión de los resultados, y finalizar con sus observaciones y conclusiones.\nNota sobre la generación del PDF: Jupyter no genera el PDF directamente, a menos que se tengan instalados una gran cantidad de paquetes, entre ellos una instalación completa de LaTeX. En su lugar, para generar el PDF en Jupyter primero guarde el notebook como HTML y luego genere el PDF renderizando e imprimiendo el HTML con su navegador. En lugar de imprimir, seleccione guardar como PDF.\n\n\n\n\n\n\nBaeza-Yates, Ricardo. 2004. “A fast set intersection algorithm for sorted sequences”. En Combinatorial Pattern Matching: 15th Annual Symposium, CPM 2004, Istanbul, Turkey, July 5-7, 2004. Proceedings 15, 400–408. Springer.\n\n\nBaeza-Yates, Ricardo, y Alejandro Salinger. 2005. “Experimental analysis of a fast intersection algorithm for sorted sequences”. En International Symposium on String Processing and Information Retrieval, 13–24. Springer.\n\n\nBarbay, Jérémy, y Claire Kenyon. 2002. “Adaptive intersection and t-threshold problems”. En Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms, 390–99. SODA ’02. USA: Society for Industrial; Applied Mathematics.\n\n\nBarbay, Jérémy, Alejandro López-Ortiz, y Tyler Lu. 2006. “Faster adaptive set intersections for text searching”. En Experimental Algorithms: 5th International Workshop, WEA 2006, Cala Galdana, Menorca, Spain, May 24-27, 2006. Proceedings 5, 146–57. Springer.\n\n\nBarbay, Jérémy, Alejandro López-Ortiz, Tyler Lu, y Alejandro Salinger. 2010. “An experimental investigation of set intersection algorithms for text searching”. Journal of Experimental Algorithmics (JEA) 14: 3–7.\n\n\nDemaine, Erik D, Alejandro López-Ortiz, y J Ian Munro. 2001. “Experiments on adaptive set intersections for text retrieval systems”. En Algorithm Engineering and Experimentation: Third International Workshop, ALENEX 2001 Washington, DC, USA, January 5–6, 2001 Revised Papers 3, 91–104. Springer.\n\n\nDemaine, Erik D, Alejandro López-Ortiz, y J Ian Munro. 2000. “Adaptive set intersections, unions, and differences”. En Proceedings of the eleventh annual ACM-SIAM symposium on Discrete algorithms, 743–52.\n\n\nHwang, Frank K., y Shen Lin. 1971. “Optimal merging of 2 elements with n elements”. Acta Informatica 1 (2): 145–58.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Algoritmos de intersección de conjuntos con representación de listas ordenadas</span>"
    ]
  },
  {
    "objectID": "refs.html",
    "href": "refs.html",
    "title": "References",
    "section": "",
    "text": "Baeza-Yates, Ricardo. 2004. “A Fast Set Intersection Algorithm for\nSorted Sequences.” In Combinatorial Pattern Matching: 15th\nAnnual Symposium, CPM 2004, Istanbul, Turkey, July 5-7, 2004.\nProceedings 15, 400–408. Springer.\n\n\nBaeza-Yates, Ricardo, and Alejandro Salinger. 2005. “Experimental\nAnalysis of a Fast Intersection Algorithm for Sorted Sequences.”\nIn International Symposium on String Processing and Information\nRetrieval, 13–24. Springer.\n\n\nBarbay, Jérémy, and Claire Kenyon. 2002. “Adaptive Intersection\nand t-Threshold Problems.” In Proceedings of the Thirteenth\nAnnual ACM-SIAM Symposium on Discrete Algorithms, 390–99. SODA ’02.\nUSA: Society for Industrial; Applied Mathematics.\n\n\nBarbay, Jérémy, Alejandro López-Ortiz, and Tyler Lu. 2006. “Faster\nAdaptive Set Intersections for Text Searching.” In\nExperimental Algorithms: 5th International Workshop, WEA 2006, Cala\nGaldana, Menorca, Spain, May 24-27, 2006. Proceedings 5, 146–57.\nSpringer.\n\n\nBarbay, Jérémy, Alejandro López-Ortiz, Tyler Lu, and Alejandro Salinger.\n2010. “An Experimental Investigation of Set Intersection\nAlgorithms for Text Searching.” Journal of Experimental\nAlgorithmics (JEA) 14: 3–7.\n\n\nBentley, Jon L., and Catherine C. McGeoch. 1985. “Amortized\nAnalyses of Self-Organizing Sequential Search Heuristics.”\nCommun. ACM 28 (4): 404–11. https://doi.org/10.1145/3341.3349.\n\n\nBentley, Jon Louis, and Andrew Chi-Chih Yao. 1976. “An Almost\nOptimal Algorithm for Unbounded Searching.” Information\nProcessing Letters 5 (3): 82–87. https://doi.org/https://doi.org/10.1016/0020-0190(76)90071-5.\n\n\nCook, Curtis R, and Do Jin Kim. 1980. “Best Sorting Algorithm for\nNearly Sorted Lists.” Communications of the ACM 23 (11):\n620–24.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, and Clifford\nStein. 2022. Introduction to Algorithms. MIT press.\n\n\nDemaine, Erik D, Alejandro López-Ortiz, and J Ian Munro. 2001.\n“Experiments on Adaptive Set Intersections for Text Retrieval\nSystems.” In Algorithm Engineering and Experimentation: Third\nInternational Workshop, ALENEX 2001 Washington, DC, USA, January 5–6,\n2001 Revised Papers 3, 91–104. Springer.\n\n\nDemaine, Erik D, Alejandro López-Ortiz, and J Ian Munro. 2000.\n“Adaptive Set Intersections, Unions, and Differences.” In\nProceedings of the Eleventh Annual ACM-SIAM Symposium on Discrete\nAlgorithms, 743–52.\n\n\nEstivill-Castro, Vladmir, and Derick Wood. 1992. “A Survey of\nAdaptive Sorting Algorithms.” ACM Computing Surveys\n(CSUR) 24 (4): 441–76.\n\n\nHwang, Frank K., and Shen Lin. 1971. “Optimal Merging of 2\nElements with n Elements.” Acta Informatica 1 (2):\n145–58.\n\n\nKnuth, Donald. 1998. The Art of Computer Programming, Vol. 3 (2nd\nEd): Sorting and Searching. Vol. 3. Redwood City, CA, USA.: Addison\nWesley Longman Publishing Co. Inc.\n\n\nLoeser, Rudolf. 1974. “Some Performance Tests of\n‘Quicksort’ and Descendants.” Communications of\nthe ACM 17 (3): 143–52.\n\n\nPugh, William. 1990. “Skip Lists: A Probabilistic Alternative to\nBalanced Trees.” Commun. ACM 33 (6): 668–76. https://doi.org/10.1145/78973.78977.\n\n\nScott, Jennifer, and Miroslav Tůma. 2023. “An Introduction to\nSparse Matrices.” In Algorithms for Sparse Linear\nSystems, 1–18. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-25820-6_1.\n\n\nSedgewick, Robert. 1998. Algorithms in c++, Parts 1-4: Fundamentals,\nData Structure, Sorting, Searching. Addison-Wesley-Longman, 1998.",
    "crumbs": [
      "References"
    ]
  }
]