[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "",
    "text": "Prefacio\nEl An√°lisis de algoritmos es una disciplina formativa enfocada en el desempe√±o de los algoritmos bajo una cierta entrada. Su estudio nos permite identificar el problema algor√≠tmico subyacente dentro de problemas reales, y por tanto, ser capaces de seleccionar, adaptar o construir una soluci√≥n eficiente y eficaz para dicho problema. Una soluci√≥n adecuada sobre una ingenua nos permite mejorar de manera significativa los recursos computacionales, que pueden llevar a reducci√≥n de costos de operaci√≥n en un sistema o la posibilidad de procesar grandes cantidades de informaci√≥n de manera m√°s eficiente.\nEl dise√±o, implementaci√≥n y an√°lisis de algoritmos es fundamental para formar el criterio del cient√≠fico de datos. Los conocimientos adquiridos servir√°n para obtener las herramientas y la intuici√≥n necesaria para plantear la soluci√≥n a un problema basado en un modelo de c√≥mputo y resolverlo de manera eficiente y escalable cuando sea posible.\nA lo largo de los temas se abordar√°n los algoritmos y estructuras de manera te√≥rica y pr√°ctica, y se motivar√° al estudiante a realizar sus propias implementaciones. Al terminar este curso, se pretende que el alumno sea competente para seleccionar, dise√±ar, implementar y analizar algoritmos sobre secuencias, conjuntos y estructuras de datos para resolver problemas optimizando los recursos disponibles, en particular, memoria y tiempo de c√≥mputo. Durante el curso se estudiaran problemas y algoritmos simples, que suelen formar parte de algoritmos m√°s complejos, y por lo tanto, si somos capaces de seleccionar adecuadamente estos bloques m√°s simples, afectaremos directamente el desempe√±o de los sistemas.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#contenido-del-libro",
    "href": "index.html#contenido-del-libro",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "Contenido del libro",
    "text": "Contenido del libro\nEste libro esta dise√±ado para ser impartido en un semestre de licenciatura o maestr√≠a con un enfoque experimental, de Ingenier√≠a en Computaci√≥n o Ciencias de la Computaci√≥n, as√≠ como Ciencia de Datos. Los algoritmos que se van develando desentra√±an los algoritmos cl√°sicos de Recuperaci√≥n de Informaci√≥n, algoritmos detr√°s de grandes m√°quinas de b√∫squeda, sistemas de informaci√≥n basados en similitud, retrieval augmented generation (RAG), as√≠ como de los m√©todos detr√°s de la aceleraci√≥n de otras t√©cnicas de an√°lisis de datos como agrupamiento y reducci√≥n de dimensi√≥n no-lineal.\n\nEl Cap.¬†1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos se dedica a revisar el lenguaje de programaci√≥n Julia, desde un punto de vista de alguien que podr√≠a no conocer el lenguaje, pero que definitivamente sabe programar y esta familiarizado con los conceptos generales de un lenguaje de programaci√≥n moderno.\nEl Cap.¬†2¬† Introducci√≥n al an√°lisis de algoritmos con Julia introduce los conceptos de an√°lisis asint√≥tico y compara ordenes de crecimiento con la idea de formar intuici√≥n.\nEn el Cap.¬†3¬† Estructuras de datos elementales nos encontramos con las estructuras de datos elementales como son las estructuras de datos lineales y de acceso aleatorio, y su organizaci√≥n en memoria.\nEl Cap.¬†4¬† Algoritmos de ordenamiento esta dedicado a algoritmos de ordenamiento en el modelo de comparaci√≥n, estudia algoritmos tanto de peor caso como aquellos que toman ventaja de la distribuci√≥n de entrada.\nEn el Cap.¬†5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n abordamos algoritmos de b√∫squeda en arreglos ordenados en el modelo de comparaci√≥n. De nueva cuenta se abordan algoritmos de peor caso y algoritmos que pueden sacar ventaja de instancias f√°ciles.\nFinalmente, el Cap.¬†6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n estudia algoritmos de intersecci√≥n de conjuntos, los cuales son la base de sistemas de informaci√≥n capaces de manipular cantidades enormes de datos.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#trabajo-en-progreso",
    "href": "index.html#trabajo-en-progreso",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "Trabajo en progreso",
    "text": "Trabajo en progreso\nEste libro es un trabajo en progreso, que se pretende t√©rminar durante el primer semestre de 2025, mientras se imparte el curso An√°lisis de algoritmos en la Maestr√≠a en Ciencia de Datos e Informaci√≥n de INFOTEC, M√©xico. El perfil de ingreso de la maestr√≠a es multidisciplinario, y esto es parte esencial del dise√±o de este libro.\nEn particular, los cap√≠tulos 1, 2, y 3 tienen un avance significativo, aunque no estan terminados. El resto de los cap√≠tulos ese encuentran en un estado incipiente.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Curso Introductorio al An√°lisis de Algoritmos con Julia",
    "section": "Licencia",
    "text": "Licencia\n\nEsta obra est√° bajo una Licencia Creative Commons Atribuci√≥n-CompartirIgual 4.0 Internacional",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "cap1-julia.html",
    "href": "cap1-julia.html",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "",
    "text": "1.1 El lenguaje de programaci√≥n Julia\nNuestro objetivo trabajar sobre algoritmos, por lo que cualquier lenguaje que pueda expresar todo lo computable, puede ser adecuado. Pero dado que nuestro enfoque ser√° experimental, y nuestra metodolog√≠a incluye medir la factibilidad y desempe√±o de cada algoritmo en t√©rminos reales, entonces necesitamos un lenguaje donde las instrucciones, los acceso a memoria, y la manipulaci√≥n de la misma sea controlable. En este caso, y mediando con la f√°cilidad de aprendizaje y la productividad, este curso utiliza el lenguaje de programaci√≥n Julia.1 Pero no hay porque preocuparse por aprender un nuevo lenguaje, el curso utiliza ejemplos en Julia y utiliza una variante de su sintaxis como pseudo-c√≥digo, pero las actividades se esperan tanto en Julia como en Python.\nAmbos lenguajes de programaci√≥n son f√°ciles de aprender y altamente productivos. Python es un lenguaje excelente para realizar prototipos, o para cuando existen bibliotecas que resuelvan el problema que se este enfrentando. Por otro lado, cuando se necesita control sobre las operaciones que se estan ejecutando, o la memoria que se aloja, Python no es un lenguaje que nos permita trabajar en ese sentido. Julia esta dise√±ado para ser veloz y a la vez mantener el din√°mismo que se espera de un lenguaje moderno, adicionalmente, es posible conocer los tipos de instrucciones que realmente se ejecutan, as√≠ como tambi√©n es posible controlar la alojaci√≥n de memoria, ya se mediante la utilizaci√≥n de patrones que as√≠ nos lo permitan, o mediante instrucciones que nos lo aseguren.\nEste curso esta escrito en Quarto, y se esperan reportes de de tareas y actividades tanto en Quarto https://quarto.org como en Jupyter https://jupyter.org/. La mayor√≠a de los ejemplos estar√°n empotrados en el sitio, y en principio, deber√≠an poder replicarse copiando, pegando, y ejecutando en una terminal de Julia.\nEs importante clarificar que este cap√≠tulo introducir√° el lenguaje de programaci√≥n Julia hasta el nivel que se requiere en este curso, ignorando una gran cantidad de capacidades que no son de inter√©s para nuestro curso. Se recomienda al alumno interesado la revisi√≥n del manual y la documentaci√≥n oficial para un estudio m√°s profundo del lenguaje.\nJulia es un lenguaje singular, es un lenguaje din√°mico y de alto nivel, tiene de tipado fuerte y compila a c√≥digo m√°quina para cada una de las instrucciones que se dan. Su interfaz m√°s com√∫n es un REPL o , esto es que puede ser utilizado de manera interactiva, adem√°s de la ejecuci√≥n en scripts o notebooks como los que estaremos usando para reportar.\nEs homoic√≥nico, que significa que la manera en que se representan sus programas coincide con las estructuras de datos b√°sicas, lo cual permite crear programas validos mediante programas. De manera pr√°ctica, tambi√©n le permite la reescritura de los programas utilizando otro programa utilizando macros, los cuales son funciones que modifican el c√≥digo y empiezan con el simbolo @. Estaremos viendo una serie de macros con prop√≥sitos muy espec√≠ficos, crear macros y la manipulaci√≥n autom√°tica de c√≥digo cae fuera de nuestro curso.\nEl lenguaje tiene estructuras de datos b√°sicas como rangos, vistas, tuplas, arreglos, estructuras, diccionarios, conjuntos, cadenas de caracteres, as√≠ como expresiones de c√≥digo como datos y controla la ejecuci√≥n mediante condicionales, ciclos y funciones. Tiene un sistema de tipos de datos muy poderoso, que le permite entre otras cosas generar c√≥digo espec√≠fico para dichos tipos. El c√≥digo se organiza en scripts, y a nivel l√≥gico en m√≥dulos y paquetes. Una de sus caracter√≠sticas importantes el despacho m√∫ltiple en las funciones, esto es, que para cada conjunto de tipos de argumentos, compilar√° una funci√≥n especializada. Este patr√≥n puede ser muy poderoso para escribir c√≥digo gen√©rico que pueda ser muy eficiente, a costa de m√∫ltiples c√≥digos de m√°quina para una funci√≥n. Esta estrateg√≠a tambi√©n viene con el problema que la primera vez que se ejecuta una funci√≥n con un conjunto espec√≠fico de tipos de argumentos, dicha funci√≥n ser√° especializada y compilada, lo cual puede representar un costo inicial importante en algunos casos donde no se pretenda procesar grandes cantidades de informaci√≥n. En particular, este problema se ha venido reduciendo en las versiones m√°s nuevas de Julia haciendo uso una estrateg√≠a de precompilaci√≥n para datos t√≠picos.\nEntre los tipos de datos es capaz de manera enteros y n√∫meros de punto flotante de diferentes precisiones, caracteres, cadenas de caracteres, y simbolos. Los arreglos son realmente importantes en Julia, y soportan de manera nativa vectores, matrices y tensores, estaremos tocando apenas esta parte del lenguaje. El resto de esta unidad esta dedicada a precisar la sintaxis del lenguaje y anotaciones de importancia sobre su funcionamiento, y en particular, en el manejo que nos permitir√° generar c√≥digo eficiente que limite el alojamiento de memoria.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#el-lenguaje-de-programaci√≥n-julia",
    "href": "cap1-julia.html#el-lenguaje-de-programaci√≥n-julia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "",
    "text": "1.1.1 Funciones\nLas funciones son centrales en Julia, y son definidas mediante la sintaxis\n```{julia}\n1function fun(arg1, arg2...)\n    # ... expresiones ...\nend\n\n2function fun(arg1, arg2...; kwarg1=valor1, kwargs2...)\n    # ... expresiones ...\nend\n\n3fun(arg1, arg2...; kwarg1=valor1, kwargs2...) = expresion\n\n4(arg1, arg2...; kwarg1=valor1, kwargs2...) -&gt; expresion\n\n5fun() do x\n    x^2 # ... expresiones ...\nend\n```\n\n1\n\nDefinici√≥n de una funci√≥n simple, los tipos de los argumentos se utilizan para generar m√∫ltiples versiones de una funci√≥n.\n\n2\n\nTambi√©n se soportan argumentos nombrados, los cuales van despu√©s de ;, se debe tener en cuenta que los tipos de los argumentos nombrados no son utilizados para determinar si una funci√≥n debe compilarse. Los argumentos nombrados pueden o no tener valores por omisi√≥n.\n\n3\n\nSi la funci√≥n tiene una estructura simple, de una expresi√≥n, es posible ignorar function y end, usando ‚Äò=‚Äô para definirla.\n\n4\n\nMuchas veces es √∫til definir funciones an√≥nimas, que suelen pasarse a otras funciones de orden superior.\n\n5\n\nUn embellecedor √∫til para generar una funci√≥n an√≥nima (definida entre do...end) que se pasa como primer argumento a fun, e.g., es equivalente a fun(x-&gt;x^2).\n\n\nEl √°mbito o scope de las variables en Julia es sint√°ctico, que significa que se hereda del c√≥digo donde las funciones fueron definidas, y no din√°mico (que se hereda desde d√≥nde se ejecuta la funci√≥n). Aunque es el comportamiento de la mayor√≠a de los lenguajes modernos, es importante conocerlo sobre todo para la creaci√≥n de cerraduras sint√°cticas en funciones.\nUna funci√≥n se ejecuta con la sintaxis nombre(arg1...). Conviene profundizar en las expresiones y dem√°s componentes del lenguaje antes del ir a m√°s ejemplos sobre funciones.\n\n\n1.1.2 Hola mundo\nUno de los programas m√°s comunes es el siguiente\n\nprintln(\"¬°Hola üåé!\")\n\n¬°Hola üåé!\n\n\n\n\n1.1.3 Expresiones y operadores\nLas expresiones son la forma m√°s gen√©rica de expresar el c√≥digo en Julia, comprenden operaciones aritm√©ticas, asignaci√≥n y declaraci√≥n de variables, definiciones de bloques de c√≥digo, llamadas de funciones, entre otras.\nCada linea suele ser una expresi√≥n, a menos que se extienda por m√∫ltiples lineas por medio de un agrupador de c√≥digo o datos, estos pueden ser begin...end, let...end, (...), [...], [...], for...end, while...end, if...end, function...end, try...end, entre las m√°s utilizadas.\nLas definiciones de variables tienen la sintaxis variable = valor; las variables comunmente comienzan con una letra o _, las letras pueden ser caracteres unicode, no deben contener espacios ni puntuaciones como parte del nombre; valor es el resultado de evaluar o ejecutar una expresi√≥n.\nLos operadores m√°s comunes son los aritm√©ticos +, -, *, /, √∑, %, \\, ^, con precedencia y significado t√≠pico. Existen maneras compuestas de modificar una variable anteponiendo el operador aritm√©tico al simbolo de asignaci√≥n, e.g., variable += valor, que se expande a variable = variable + valor. Esto implica que variable debe estar previamente definida previo a la ejecuci√≥n.\nLos operadores l√≥gicos tambi√©n tienen el significado esperado.\n\n\n\noperaci√≥n\ndescripci√≥n\n\n\n\n\na && b\nAND l√≥gico\n\n\na || b\nOR l√≥gico\n\n\na ‚äª b\nXOR l√≥gico\n\n\n!a\nnegaci√≥n l√≥gica\n\n\na &lt; b\ncomparaci√≥n a es menor que b\n\n\na &gt; b\ncomparaci√≥n a es mayor que b\n\n\na &lt;= b\ncomparaci√≥n a es menor o igual que b\n\n\na &gt;= b\ncomparaci√≥n a es mayor o igual que b\n\n\na == b\ncomparaci√≥n de igualdad\n\n\na === b\ncomparaci√≥n de igualdad (a nivel de tipo)\n\n\na != b\ncomparaci√≥n de desigualdad\n\n\na !== b\ncomparaci√≥n de desigualdad (a nivel de tipo)\n\n\n\nEn particular && y || implementan corto circuito de c√≥digo, por lo que pueden usarse para el control de que operaciones se ejecutan. Cuando se compara a nivel de tipo 0 (entero) ser√° diferente de 0.0 (real).\nTambi√©n hay operadores l√≥gicos a nivel de bit, los argumentos son enteros.\n\n\n\noperaci√≥n\ndescripci√≥n\n\n\n\n\na & b\nAND a nivel de bits\n\n\na | b\nOR a nivel de bits\n\n\na ‚äª b\nXOR a nivel del bits\n\n\n~a\nnegaci√≥n l√≥gica a nivel de bits\n\n\n\n\n\n1.1.4 Literales\nDado que existen m√∫ltiples tipos de datos existen diferentes formas de definirlas; una de ellas, probablemente la que m√°s estaremos usando son los literales, es decir, escribir los datos directamente en el c√≥digo.\nLos n√∫meros enteros se definen sin punto decimal, es posible usar _ como separador y dar m√°s claridad al c√≥digo. Los enteros pueden tener 8, 16, 32, o 64 bits; por omisi√≥n, se empaquetan en variables del tipo Int (Int64). Los valores hexadecimales se interpretan como enteros sin signo, y adem√°s se empaquetan al n√∫mero de bits necesario minimo para contener. El comportamiento para valores en base 10 es el de hexadecimal es congruente con un lenguaje para programaci√≥n de sistemas.\n\na = 100\nprintln((a, sizeof(a)))\nb = Int8(100)\nprintln((b, sizeof(b)))\nc = 30_000_000\nprintln((c, sizeof(c)))\nd = 0xffff\nprintln((d, sizeof(d)))\n\n(100, 8)\n(100, 1)\n(30000000, 8)\n(0xffff, 2)\n\n\n\n\nExisten n√∫meros enteros de precisi√≥n 128 pero las operaciones al d√≠a de hoy no son implementadas de manera nativa por los procesadores; as√≠ mismo se reconocen n√∫meros de punto flotante de precisi√≥n media Float16 pero la mayor√≠a de los procesadores no tienen soporte nativo para realizar operaciones con ellos, aunque los procesadores de √∫ltima generaci√≥n si lo tienen.\nSi la precisi√≥n esta en duda o el contexto lo am√©rita, deber√° especificarlo usando el constructor del tipo e.g., Int8(100), UInt8(100), Int16(100), UInt16(100), Int32(100), UInt32(100), Int64(100), UInt64(100).\nLos n√∫meros de punto flotante tienen diferentes formas de definirse, teniendo diferentes efectos. Para n√∫meros de precision simple, 32 bits, se definen con el sufijo f0 como 3f0. El sufijo e0 tambi√©n se puede usar para definir precisi√≥n doble (64 bit). El cero del sufijo en realidad tiene el objetivo de colocar el punto decimal, en notaci√≥n de ingenier√≠a, e.g., \\(0.003\\) se define como \\(3f-3\\) o \\(3e-3\\), dependiendo del tipo de dato que se necesite. Si se omite sufijo y se pone solo punto decimal entonces se interpretar√° como precision doble. Los tipos son Float32 y Float64.\nLos datos booleanos se indican mediante true y false para verdadero y falso, respectivamente.\nLos caracteres son s√≠mbolos para √≠ndicar cadenas, se suelen representar como enteros peque√±os en memoria. Se especifican con comillas simples 'a', 'z', '!' y soporta simbolos unicode 'ü§†'.\nLas cadenas de caracteres son la manera de representar textos como datos, se guardan en zonas contiguas de memoria. Se especifican con comillas dobles y tambi√©n soportan s√≠mbolos unicode, e.g., \"hola mundo\", \"pato es un üê∑\".\n\n\nJulia guarda los simbolos de manera especial y pueden ser utilizados para realizar identificaci√≥n de datos eficiente, sin embargo, no es buena idea saturar el sistema de manejo de s√≠mbolos por ejemplo para crear un vocabulario ya que no liberar√° la memoria despu√©s de definirlos ya que es un mec√°nismo dise√±ado para la representaci√≥n de los programas, pero lo suficientemente robusto y bien definido para usarse en el dise√±o e implementaci√≥n de programas de los usuarios.\nEn Julia existe la noci√≥n de s√≠mbolo, que es una cadena que adem√°s solo existe en una posici√≥n en memoria se usa el prefijo : para denotarlos.\n\nprintln(:hola === :hola)\nprintln(typeof(:hola))\nprintln(Symbol(\"hola mundo\"))\n\ntrue\nSymbol\nhola mundo\n\n\n\n\n1.1.5 Control de flujo\nEl control de flujo nos permite escoger que partes del c√≥digo se ejecutaran como consecuencia de la evaluaci√≥n de una expresi√≥n, esto incluye repeticiones.\nLas condicionales son el control de flujo m√°s simple.\n\na = 10\n1if a % 2 == 0\n2    \"par\"\nelse\n3    \"impar\"\nend\n\n\n1\n\nExpresi√≥n condicional.\n\n2\n\nExpresi√≥n a ejecutarse si (1) es verdadero.\n\n3\n\nExpresi√≥n a evaluarse si (1) es falso.\n\n\n\n\n\"par\"\n\n\nSe puede ignorar la clausula else dando solo la opci√≥n de evaluar (2) si (1) es verdadero. Finalmente, note que la condicional es una expresi√≥n y devuelve un valor.\n\na = 10\nif log10(a) == 1\n    \"es 10\"\nend\n\n\"es 10\"\n\n\nTambi√©n pueden concatenarse m√∫ltiples expresiones condicionales con elseif como se muestra a continuaci√≥n.\n\na = 9\nif a % 2 == 0\n    println(\"divisible entre 2\")\nelseif a % 3 == 0\n    println(\"divisible entre 3\")\nelse\n    println(\"no divisible entre 2 y 3\")\nend\n\ndivisible entre 3\n\n\nEs com√∫n utilizar la sintaxis en Julia (short circuit) para control de flujo:\n\na = 9\n\n1println(a % 2 == 0 && \"es divisible entre dos\")\n2println(a % 3 == 0 && \"es divisible entre tres\")\n\n\n1\n\nEl resultado de la condici√≥n es falso, por lo que no se ejecutar√° la siguiente expresi√≥n.\n\n2\n\nEl resultado es verdadero, por lo que se ejecutar√° la segunda expresi√≥n.\n\n\n\n\nfalse\nes divisible entre tres\n\n\nFnalmente, existe una condicional de tres vias expresion ? expr-verdadero : expr-falso\n\na = 9\n\nprintln(a % 2 == 0 ? \"es divisible entre dos\" : \"no es divisible entre dos\")\nprintln(a % 3 == 0 ? \"es divisible entre tres\" : \"no es divisible entre tres\")\n\nno es divisible entre dos\nes divisible entre tres\n\n\n\n1.1.5.1 Ciclos\nLos ciclos son expresiones de control de flujo que nos permiten iterar sobre una colecci√≥n o repetir un c√≥digo hasta que se cumpla alguna condici√≥n. En Julia existen dos expresiones de ciclos:\n\nfor x in colecci√≥n ...expresiones... end y\nwhile condici√≥n ...expresioens... end\n\nEn el caso de for, la idea es iterar sobre una colecci√≥n, esta colecci√≥n puede ser un rango, i.e., inicio:fin, inicio:paso:fin, o una colecci√≥n como las tuplas, los arreglos, o cualquiera que cumpla con la interfaz de colecci√≥n iterable del lenguaje.\n\nfor i in 1:5\n    println(\"1er ciclo: \", i =&gt; i^2)\nend\n\nfor i in [10, 20, 30, 40, 50]\n    println(\"2do ciclo: \", i =&gt; i/10)\nend\n\n1er ciclo: 1 =&gt; 1\n1er ciclo: 2 =&gt; 4\n1er ciclo: 3 =&gt; 9\n1er ciclo: 4 =&gt; 16\n1er ciclo: 5 =&gt; 25\n2do ciclo: 10 =&gt; 1.0\n2do ciclo: 20 =&gt; 2.0\n2do ciclo: 30 =&gt; 3.0\n2do ciclo: 40 =&gt; 4.0\n2do ciclo: 50 =&gt; 5.0\n\n\nAl igual que en otros lenguajes modernos, se define la variante completa o comprehensive for que se utiliza para transformar la colecci√≥n de entrada en otra colecci√≥n cuya sintaxis se ejemplifica a continuaci√≥n:\n\na = [i =&gt; i^2 for i in 1:5]\nprintln(a)\n\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nTambi√©n es posible definir un generador, esto es, un c√≥digo que puede generar los datos, pero que no los generar√° hasta que se les solicite.\n\na = (i =&gt; i^2 for i in 1:5)\nprintln(a)\nprintln(collect(a))\n\nBase.Generator{UnitRange{Int64}, var\"#3#4\"}(var\"#3#4\"(), 1:5)\n[1 =&gt; 1, 2 =&gt; 4, 3 =&gt; 9, 4 =&gt; 16, 5 =&gt; 25]\n\n\nOtra forma de hacer ciclos de intrucciones es repetir mientras se cumpla una condici√≥n:\n\ni = 0\nwhile i &lt; 5\n    i += 1\n    println(i)\nend\n\ni\n\n1\n2\n3\n4\n5\n\n\n5\n\n\n\n\n\n1.1.6 Tuplas y arreglos en Julia\nUna tupla es un conjunto ordenado de datos que no se puede modificar y que se desea esten contiguos en memoria, la sintaxis en memoria es como sigue:\n\n1a = (2, 3, 5, 7)\nb = (10, 20.0, 30f0)\nc = 100 =&gt; 200\n2println(typeof(a))\nprintln(typeof(b))\nprintln(typeof(c))\n3a[1], a[end], b[3], c.first, c.second\n\n\n1\n\nDefine las tuplas.\n\n2\n\nImprime los tipos de las tuplas.\n\n3\n\nMuestra como se accede a los elementos de las tuplas. Julia indexa comenzando desde 1, y el t√©rmino end tambi√©n se utiliza para indicar el √∫ltimo elemento en una colecci√≥n ordenada.\n\n\n\n\nNTuple{4, Int64}\nTuple{Int64, Float64, Float32}\nPair{Int64, Int64}\n\n\n(2, 7, 30.0f0, 100, 200)\n\n\nLa misma sintaxis puede generar diferentes tipos de tuplas. En el caso NTuple{4, Int4} nos indica que el tipo maneja cuatro elementos de enteros de 64 bits, los argumentos entre {} son parametros que especifican los tipos en cuesti√≥n. En el caso de Tuple se pueden tener diferentes tipos de elementos. La tupla Pair es especial ya que solo puede contener dos elementos y es b√°sicamente para embellecer o simplificar las expresiones; incluso se crea con la sintaxis key =&gt; value y sus elementos pueden accederse mediante dos campos nombrados.\nLos arreglos son datos del mismo tipo contiguos en memoria, a diferencia de las tuplas, los elementos se pueden modificar, incluso pueden crecer o reducirse. Esto puede implicar que se alojan en zonas de memoria diferente (las tuplas se colocan en el stack y los arreglos en el heap, ver la siguiente unidad para m√°s informaci√≥n). Desde un alto nivel, los arreglos en Julia suelen estar asociados con vectores, matrices y tensores, y un arsenal de funciones relacionadas se encuentran definidas en el paquete LinearAlgebra, lo cual esta m√°s all√° del alcance de este curso.\n\n1a = [2, 3, 5, 7]\nb = [10, 20.0, 30f0]\n2println(typeof(a))\nprintln(typeof(b))\n3a[1], a[end], b[3], b[2:3]\n\n\n1\n\nDefine los arreglos a y b.\n\n2\n\nMuestra los tipos de los arreglos, note como los tipos se promueven al tipo m√°s g√©nerico que contiene la definici√≥n de los datos.\n\n3\n\nEl acceso es muy similar a las tuplas para arreglos unidimensionales, note que es posible acceder rangos de elementos con la sintaxis ini:fin.\n\n\n\n\nVector{Int64}\nVector{Float64}\n\n\n(2, 7, 30.0, [20.0, 30.0])\n\n\n\na = [2 3;\n1     5 7]\n2display(a)\n3display(a[:, 1])\n4display(a[1, :])\n\n\n1\n\nDefinici√≥n de un arreglo bidimensional, note como se ignora la coma , en favor de la escritura por filas separadas por ;.\n\n2\n\nLa variable a es una matriz de 2x2.\n\n3\n\nEs posible acceder una columna completa usando el s√≠mbolo : para indicar todos los elementos.\n\n4\n\nDe igual forma, es posible acceder una fila completa.\n\n\n\n\n2√ó2 Matrix{Int64}:\n 2  3\n 5  7\n\n\n2-element Vector{Int64}:\n 2\n 5\n\n\n2-element Vector{Int64}:\n 2\n 3\n\n\n\n\n1.1.7 Diccionarios y conjuntos en Julia\nUn diccionario es un arreglo asociativo, i.e., guarda pares llave-valor. Permite acceder de manera eficiciente al valor por medio de la llave, as√≠ como tambi√©n verificar si hay una entrada dentro del diccionario con una llave dada. La sintaxis es como sigue:\n\n1a = Dict(:a =&gt; 1, :b =&gt; 2, :c =&gt; 3)\n2a[:b] = 20\nprintln(a)\n3a[:d] = 4\nprintln(a)\n4delete!(a, :a)\na\n\n\n1\n\nDefinici√≥n del diccionario a que mapea simbolos a enteros.\n\n2\n\nCambia el valor de :b por 20.\n\n3\n\nA√±ade :d =&gt; 4 al diccionario a.\n\n4\n\nBorra el par con llave :a.\n\n\n\n\nDict(:a =&gt; 1, :b =&gt; 20, :c =&gt; 3)\nDict(:a =&gt; 1, :b =&gt; 20, :d =&gt; 4, :c =&gt; 3)\n\n\nDict{Symbol, Int64} with 3 entries:\n  :b =&gt; 20\n  :d =&gt; 4\n  :c =&gt; 3\n\n\nEs posible utilizar diferentes tipos siempre y cuando el tipo en cuesti√≥n defina de manera correcta la funci√≥n hash sobre la llave y la verificaci√≥n de igualdad ==.\nUn conjunto se representa con el tipo Set, se implementa de manera muy similar al diccionario pero solo necesita el elemento (e.g., la llave). Como conjunto implementa las operaciones clasificaci√≥n de operaciones de conjuntos\n\n1a = Set([10, 20, 30, 40])\n2println(20 in a)\n3push!(a, 50)\nprintln(a)\n4delete!(a, 10)\nprintln(a)\n5println(intersect(a, [20, 35]))\n6union!(a, [100, 200])\nprintln(a)\n\n\n1\n\nDefinici√≥n del conjunto de n√∫meros enteros.\n\n2\n\nVerificaci√≥n de membresia al conjunto a.\n\n3\n\nA√±ade 50 al conjunto.\n\n4\n\nSe borra el elemento 10 del conjunto.\n\n5\n\nIntersecci√≥n de a con una colecci√≥n, no se modifica el conjunto a.\n\n6\n\nUni√≥n con otra colecci√≥n, se modifica a.\n\n\n\n\ntrue\nSet([50, 20, 10, 30, 40])\nSet([50, 20, 30, 40])\nSet([20])\nSet([50, 200, 20, 30, 40, 100])",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#el-flujo-de-compilaci√≥n-de-julia",
    "href": "cap1-julia.html#el-flujo-de-compilaci√≥n-de-julia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.2 El flujo de compilaci√≥n de Julia",
    "text": "1.2 El flujo de compilaci√≥n de Julia\nBasta con escribir una linea de c√≥digo en el REPL de Julia y esta se compilar√° y ejecutar√° en el contexto actual, usando el √°mbito de variables. Esto es conveniente para comenzar a trabajar, sin embargo, es importante conocer el flujo de compilaci√≥n para tenerlo en cuenta mientras se c√≥difica, y as√≠ generar c√≥digo eficiente. En particular, la creaci√≥n de funciones y evitar la inestabilidad de los tipos de las variables es un paso hacia la generaci√≥n de c√≥digo eficiente. Tambi√©n es importante evitar el alojamiento de memoria din√°mica siempre que sea posible. A continuaci√≥n se mostrar√° el an√°lisis de un c√≥digo simple a diferentes niveles, mostrando que el lenguaje nos permite observar la generaci√≥n de c√≥digo, que √∫ltimadamente nos da cierto control y nos permite verificar que lo que se esta implementando es lo que se espec√≠fica en el c√≥digo. Esto no es posible en lenguajes como Python.\n\nlet\n    e = 1.1\n    println(e*e)\n    @code_typed e*e\nend\n\n1.2100000000000002\n\n\nCodeInfo(\n1 ‚îÄ %1 = Base.mul_float(x, y)::Float64\n‚îî‚îÄ‚îÄ      return %1\n) =&gt; Float64\n\n\nEn este c√≥digo, se utiliza la estructa de agrupaci√≥n de expresiones let...end. Cada expresi√≥n puede estar compuesta de otras expresiones, y casi todo es una expresi√≥n en Julia. La mayoria de las expresiones ser√°n finalizadas por un salto de linea, pero las compuestas como let, begin, function, if, while, for, do, module estar√°n finalizadas con end. La indentaci√≥n no importa la indentaci√≥n como en Python, pero es aconsejable para mantener la legibilidad del c√≥digo. La linea 2 define e inicializa la variable e; la linea 3 llama a la funci√≥n println, que imprimir√° el resultado de e*e en la consola. La funci√≥n println esta dentro de la biblioteca est√°ndar de Julia y siempre esta visible. La linea 4 es un tanto diferente, es una macro que toma la expresi√≥n e*e y realiza algo sobre la expresi√≥n misma, en particular @code_type muestra como se reescribe la expresi√≥n para ser ejecutada. Note como se har√° una llamada a la funci√≥n Base.mul_float que recibe dos argumentos y que regresar√° un valor Float64. Esta informaci√≥n es necesaria para que Julia pueda generar un c√≥digo veloz, el flujo de compilaci√≥n llevar√≠a esta informaci√≥n a generar un c√≥digo intermedio de Low Level Virtual Machine (LLVM), que es el compilador empotrado en Julia, el cual estar√≠a generando el siguiente c√≥digo LLVM (usando la macro @code_llvm):\n\n\n;  @ float.jl:411 within `*`\ndefine double @\"julia_*_1779\"(double %0, double %1) #0 {\ntop:\n  %2 = fmul double %0, %1\n  ret double %2\n}\n\n\nEste c√≥digo ya no es espec√≠fico para Julia, sino para la maquinar√≠a LLVM. Observe la especificidad de los tipos y lo corto del c√≥digo. El flujo de compilaci√≥n requerir√≠a generar el c√≥digo nativo, que puede ser observado a continuaci√≥n mediante la macro @code_native:\n\n\n    .text\n    .file   \"*\"\n    .globl  \"julia_*_1818\"                  # -- Begin function julia_*_1818\n    .p2align    4, 0x90\n    .type   \"julia_*_1818\",@function\n\"julia_*_1818\":                         # @\"julia_*_1818\"\n; ‚îå @ float.jl:411 within `*`\n# %bb.0:                                # %top\n    push    rbp\n    mov rbp, rsp\n    vmulsd  xmm0, xmm0, xmm1\n    pop rbp\n    ret\n.Lfunc_end0:\n    .size   \"julia_*_1818\", .Lfunc_end0-\"julia_*_1818\"\n; ‚îî\n                                        # -- End function\n    .section    \".note.GNU-stack\",\"\",@progbits\n\n\nEn este caso podemos observar c√≥digo espec√≠fico para la computadora que esta generando este documento, es posible ver el manejo de registros y el uso de instrucciones del CPU en cuesti√≥n.\nEste c√≥digo puede ser eficiente dado que los tipos y las operaciones son conocidos, en el caso que esto no puede ser, la eficiencia esta perdida. Datos no nativos o la imposibilidad de determinar un tipo causar√≠an que se generar√° m√°s c√≥digo nativo que terminar√≠a necesitanto m√°s recursos del procesador. Una situaci√≥n similar ocurre cuando se aloja memoria de manera din√°mica. Siempre estaremos buscando que nuestro c√≥digo pueda determinar el tipo de datos para que el c√≥digo generado sea simple, si es posible usar datos nativos, adem√°s de no manejar o reducir el uso de memor√≠a din√°mica.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#ejemplos-de-funciones",
    "href": "cap1-julia.html#ejemplos-de-funciones",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.3 Ejemplos de funciones",
    "text": "1.3 Ejemplos de funciones\nLas funciones ser√°n una parte central de nuestros ejemplos, por lo que vale la pena retomarlas y dar ejemplos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#recursos-para-aprender-python-y-julia",
    "href": "cap1-julia.html#recursos-para-aprender-python-y-julia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.4 Recursos para aprender Python y Julia",
    "text": "1.4 Recursos para aprender Python y Julia\n\n1.4.1 Python\n\nPython, se recomieda utilizar la distribuci√≥n de https://www.anaconda.com/download/\nDocumentaci√≥n oficial, comenzar por el tutorial https://docs.python.org/3/\nDocumentaci√≥n oficial https://docs.julialang.org/en/stable/\n\n\n\n1.4.2 Julia\n\nInformaci√≥n sobre como instalar Julia y flujos de trabajo simples (e.g., REPL, editores, etc.) para trabajar con este lenguaje de programaci√≥n: Modern Julia Workflows https://modernjuliaworkflows.github.io/.\nLibro sobre julia Think Julia: How to Think Like a Computer Scientist https://benlauwens.github.io/ThinkJulia.jl/latest/book.html.\nCurso Introduction to computational thinking https://computationalthinking.mit.edu/Fall20/",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#licencia",
    "href": "cap1-julia.html#licencia",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "1.5 Licencia",
    "text": "1.5 Licencia\n\nEsta obra est√° bajo una Licencia Creative Commons Atribuci√≥n-CompartirIgual 4.0 Internacional",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap1-julia.html#footnotes",
    "href": "cap1-julia.html#footnotes",
    "title": "1¬† Julia como lenguaje de programaci√≥n para un curso de algoritmos",
    "section": "",
    "text": "Se recomienda utilizar la versi√≥n 1.10 o superior, y puede obtenerse en https://julialang.org/.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Julia como lenguaje de programaci√≥n para un curso de algoritmos</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html",
    "href": "cap2-analisis.html",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "",
    "text": "2.1 Concepto de algoritmo y estructura de datos\nEste cap√≠tulo introduce a los fundamentos de an√°lisis de algoritmos. Se introduce el concepto de modelo de c√≥mputo y la notaci√≥n asint√≥tica, preparandonos para usar el lenguaje com√∫n en el an√°lisis de algoritmos. Tambi√©n se mostrar√°n algunos de los ordenes de crecimiento m√°s representativos, que nos permitir√°n comparar algoritmos que resuelvan una tarea dada, as√≠ como catalogarlos con respecto a los recursos de computo necesarios para ejecutarlos.\nLos algoritmos son especificaciones formales de los pasos u operaciones que deben aplicarse a un conjunto de entradas para resolver un problema, obteniendo una soluci√≥n correcta a dicho problema. Establecen los fundamentos de la programaci√≥n y delinean la manera en como se dise√±an los programas de computadoras.\nEs com√∫n encontrar que un problema puede ser resuelto por m√∫ltiples algoritmos, cada uno de ellos con sus diferentes particularidades. As√≠ mismo, un problema suele estar conformado por una cantidad enorme de instancias de dicho problema, por ejemplo, para una lista de \\(n\\) n√∫meros, existen \\(n!\\) formas de acomodarlos, de tal forma que puedan ser la entrada a un algoritmo cuya entrada sea una lista de n√∫meros donde el orden es importante. En ocasiones, los problemas pueden tener infinitas de instancias. En este curso nos enfocaremos en problemas que pueden ser simplificados a una cantidad finita instancias.\nCada paso u operaci√≥n en un algoritmo esta bien definido y puede ser aplicado o ejecutado para producir un resultado. A su vez, cada operaci√≥n suele tener un costo, dependiente del m√≥delo de computaci√≥n. Conocer el n√∫mero de operaciones necesarias para transformar la entrada en la salida esperada, i.e., resolver el problema, es de vital importancia para seleccionar el mejor algoritmo para dicho problema, o aun m√°s, para instancias de dicho problema que cumplen con ciertas caracter√≠sticas.\nUna estructura de datos es una abstracci√≥n en memoria de entidades matem√°ticas y l√≥gicas que nos permite organizar, almacenar y procesar datos en una computadora. El objetivo es que la informaci√≥n representada puede ser manipulada de manera eficiente en un contexto espec√≠fico, adem√°s de simplificar la aplicaci√≥n de operaciones para la aplicaci√≥n de algoritmos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#modelos-de-c√≥mputo",
    "href": "cap2-analisis.html#modelos-de-c√≥mputo",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.2 Modelos de c√≥mputo",
    "text": "2.2 Modelos de c√≥mputo\nUn modelo de c√≥mputo es una abstracci√≥n matem√°tica de una computadora o marco de trabajo algor√≠tmico que nos permite estudiar y medir los costos de los algoritmos funcionando en este modelo de tal forma que sea m√°s simple que una computadora f√≠sica real. Ejemplos de estos modelos:\n\nLa m√°quina de Turing.\nFunciones recursivas.\nC√°lculo lambda.\nM√°quina de acceso aleatorio (RAM).\n\nTodas estos modelos son equivalentes en sus capacidades, pero sus diferentes planteamientos permiten enfocarse en diferentes aspectos de los problemas.\n\n2.2.1 M√°quina de Turing\nEs un m√≥delo creado por Alan Turing a principios del siglo XX; la idea es un dispositivo que podr√≠a ser implementada de manera mec√°nica si se tuvieran recursos infinitos; esta m√°quina puede leer y escribir mediante un cabezal en una cinta infinita (ver Figura¬†2.1) una cantidad de s√≠mbolos predeterminada para cada problema siguiendo una serie de reglas simples sobre lo que lee y escribe, dichas reglas y la cienta, forman una m√°quina de estados y memoria, que pueden realizar cualquier c√°lculo.\n\n\n\n\n\n\n\n\nTuringTape\n\n\ncluster_tape\n\ncinta\n\n\n\nstart\n\n\n\n\n01\n\n0\n\n\n\n\n02\n\n0\n\n\n\n\n03\n\n0\n\n\n\n\n11\n\n1\n\n\n\n\n12\n\n1\n\n\n\n\n13\n\n1\n\n\n\n\nend\n\n\n\n\n\nhead\n\ncabezal\n\n\n\nhead-&gt;01\n\n\n\n\n\n\n\n\nFigura¬†2.1: Cabezal y cinta.\n\n\n\n\n\nUna m√°quina de Turing se puede escribir como una tupla de 7 elementos \\(M=(Q, \\Sigma, \\Gamma, s, \\epsilon, F, \\delta)\\) donde:\n\n\\(Q\\) es un conjunto finito de estados.\n\\(\\Sigma\\) es el alfabeto de entrada, i.e., un conjunto finito de s√≠mbolos que no incluye el espacio en blanco.\n\\(\\Gamma\\) es el alfabeto de la cinta , i.e., un conjunto finito de s√≠mbolos \\(\\Sigma \\subseteq \\Gamma\\).\n\\(s \\in Q\\) es el estado inicial.\n\\(\\epsilon \\in \\Gamma\\) es un s√≠mbolo especial denominado blanco; y puede llenar la cinta al infinito.\n\\(F \\subseteq Q\\) conjunto de estados finales de aceptaci√≥n.\n\\(\\delta: Q \\times \\Gamma \\rightarrow Q \\times \\Gamma \\times \\{L, R\\}\\), es la funci√≥n de transici√≥n, i.e., una funci√≥n parcial que √≠ndica que se debe hacer al leer un s√≠mbolo en la posici√≥n actual de lectura, esto es, qu√© se escribe, hacia que estado se cambia, y la direcci√≥n de movimiento de la cinta (siempre se mueve en una celda).\n\nHay muchas variantes de la definici√≥n de m√°quina de Turing, por ejemplo, una cinta especial para lectura y una para escritura, diferentes formas de definir las transiciones, s√≠mbolos para no moverse, etc. Hasta ahora, todas las formas son a lo m√°s equivalentes en t√©rminos de poder de c√≥mputo, la diferencia viene en la expresividad para definir soluciones.\nEs c√≥mun plantear los problemas en forma de lenguajes; esto es, en t√©rminos de dada la cadena S ¬øla m√°quina \\(M\\) la acepta?, d√≥nde acepta quiere decir que la m√°quina es capaz de ir desde el estado inicial al estado de aceptaci√≥n leyendo/transformando \\(S\\). Si \\(M\\) no termina en un estado de aceptaci√≥n, entonces se implica el fallo o respuesta negativa.\n\n\n\n\n\n\nNota\n\n\n\nAlgunas causas de fallo son que la funci√≥n de transici√≥n no este definida para un estado y s√≠mbolo particular y el no alcanzar un estado de salida aceptaci√≥n.\n\n\nPor ejemplo, sea \\(M_{01}\\) una m√°quina capaz de detectar \\(n \\geq 0\\) ceros terminados por un √∫nico \\(1\\). Entonces\n\\[M_{01} = (\\{q_0, q_1, q_2\\}, \\{\\mathtt{0}, \\mathtt{1}\\}, \\{\\mathtt{0}, \\mathtt{1}, \\mathtt{X}, \\mathtt{\\epsilon} \\}, q_0, \\mathtt{\\epsilon}, \\{q_2\\}, \\delta_{01})\\]\ndonde la funci√≥n de transici√≥n se define como:\n\\[\\begin{align}\n\\delta_{01}(q_0, \\mathtt{0}) &= (q_0, \\mathtt{X}, \\mathtt{R}) \\\\\n\\delta_{01}(q_0, \\mathtt{1}) &= (q_1, \\mathtt{X}, \\mathtt{R}) \\\\\n\\delta_{01}(q_1, \\mathtt{\\epsilon}) &= (q_2, \\mathtt{\\epsilon}, \\mathtt{R}) \\\\\n\\end{align}\\]\nDada la regularidad de la funci√≥n de transici√≥n, es com√∫n escribirla como una tabla:\n\n\n\nentrada\nsalida\n\n\n\n\n\\((q_0, \\mathtt{0})\\)\n\\((q_0, \\mathtt{X}, \\mathtt{R})\\)\n\n\n\\((q_0, \\mathtt{1})\\)\n\\((q_1, \\mathtt{X}, \\mathtt{R})\\)\n\n\n\\((q_1, \\mathtt{\\epsilon})\\)\n\\((q_2, \\mathtt{\\epsilon}, \\mathtt{R})\\)\n\n\n\nUna m√°quina de Turing se puede representar mediante un aut√≥mata\n\n\n\n\n\n\n\n\nG\n\n\n\nq0\n\n\nq0\n\n\n\nq0-&gt;q0\n\n\n0 ‚Üí X, R\n\n\n\nq1\n\nq1\n\n\n\nq0-&gt;q1\n\n\n1 ‚Üí X, R\n\n\n\nq2\n\n\nq2\n\n\n\nq1-&gt;q2\n\n\nœµ ‚Üí œµ, R\n\n\n\n\n\n\nFigura¬†2.2: Ejemplo de m√°quina de Turing que reconoce cadenas \\(0^n 1\\)\n\n\n\n\n\nSupongamos ahora el problema de reconocer cadenas \\(0^n 1^n\\); para esto podemos definir la siguiente m√°quina de Turing \\[M = (\\{q_0, q_1, q_2, q_3, q_4\\}, \\{\\mathtt{0}, \\mathtt{1}\\}, \\{\\mathtt{0}, \\mathtt{1}, \\mathtt{X}, \\mathtt{Y}, \\mathtt{\\epsilon}\\}, q_0, \\mathtt{\\epsilon}, \\{q_4\\}, \\delta),\\] donde la funci√≥n de transici√≥n es como sigue:\n\\[\\begin{align*}\n\\delta(q_0, \\mathtt{0}) &= (q_1, \\mathtt{X}, \\mathtt{R}) \\\\\n\\delta(q_0, \\mathtt{Y}) &= (q_3, \\mathtt{Y}, \\mathtt{R}) \\\\\n\\delta(q_1, \\mathtt{0}) &= (q_1, \\mathtt{0}, \\mathtt{R}) \\\\\n\\delta(q_1, \\mathtt{1}) &= (q_2, \\mathtt{Y}, \\mathtt{L}) \\\\\n\\delta(q_1, \\mathtt{Y}) &= (q_1, \\mathtt{Y}, \\mathtt{R}) \\\\\n\\delta(q_2, \\mathtt{0}) &= (q_2, \\mathtt{0}, \\mathtt{L}) \\\\\n\\delta(q_2, \\mathtt{X}) &= (q_0, \\mathtt{X}, \\mathtt{R}) \\\\\n\\delta(q_2, \\mathtt{Y}) &= (q_2, \\mathtt{Y}, \\mathtt{L}) \\\\\n\\delta(q_3, \\mathtt{Y}) &= (q_3, \\mathtt{Y}, \\mathtt{R}) \\\\\n\\delta(q_3, \\mathtt{\\epsilon}) &= (q_4, \\mathtt{\\epsilon}, \\mathtt{R}) \\\\\n\\end{align*}\\]\n\n\n\n\n\n\n\n\nG\n\n\n\nq0\n\n\nq0\n\n\n\nq1\n\nq1\n\n\n\nq0-&gt;q1\n\n\n0 ‚Üí X, R\n\n\n\nq3\n\nq3\n\n\n\nq0-&gt;q3\n\n\nY ‚Üí Y, R\n\n\n\nq1-&gt;q1\n\n\n0 ‚Üí 0, R\n\n\n\nq1-&gt;q1\n\n\nY ‚Üí Y, R\n\n\n\nq2\n\nq2\n\n\n\nq1-&gt;q2\n\n\n1 ‚Üí Y, L\n\n\n\nq2-&gt;q0\n\n\nX ‚Üí X, R\n\n\n\nq2-&gt;q2\n\n\nY ‚Üí Y, L\n\n\n\nq2-&gt;q2\n\n\n0 ‚Üí 0, L\n\n\n\nq3-&gt;q3\n\n\nY ‚Üí Y, R\n\n\n\nq4\n\n\nq4\n\n\n\nq3-&gt;q4\n\n\nœµ ‚Üí œµ, R\n\n\n\n\n\n\nFigura¬†2.3: Ejemplo de m√°quina de Turing que reconoce cadenas \\(0^n 1^n\\)\n\n\n\n\n\nTodo inicia con una cadena de la forma esperada, e.g., \\(\\mathtt{000111}\\), la idea general del algoritmo es aparear \\(\\mathtt{0}\\)‚Äôs y \\(\\mathtt{1}\\)‚Äôs, ya que solo es valido si ambas subcadenas tienen igual longitud. Para esto se marcan los \\(\\mathtt{0}\\)‚Äôs vistos con \\(\\mathtt{X}\\) y los \\(\\mathtt{1}\\)‚Äôs con \\(\\mathtt{Y}\\). La m√°quina estar√° entonces marcando las primeras ocurrencias y moviendose a traves de la cinta para encontrar los correspondientes.\n\n\n\n\n\n\nImportante\n\n\n\nLas m√°quinas de Turing son capaces del representar cualquier problema c√≥mputable con una analog√≠a mec√°nica, lo cual hace evidente su implementaci√≥n en el mundo f√≠sico.\n\n\n\n\n2.2.2 Modelos funcionales\n\nFunciones recursivas. Se basa en funciones que trabajan sobre los n√∫meros naturales y que definen en conjunto el espacio de funciones computables. Son una herramienta abstracta que permite a los te√≥ricos de la l√≥gica y computaci√≥n establecer los l√≠mites de lo computable.\nC√°lculo lambda. Es un m√≥delo creado por Alonzo Church y Stephen Kleene a principios del siglo XX, al igual que las funciones recursivas, se fundamenta en el uso de funciones y es una herramienta abstracta con pr√≥positos similares, sin embargo el c√°lculo lambda no se limita a recursiones, y se enfoca en diferentes reglas de reducci√≥n y composici√≥n de funciones, y es natural la inclusi√≥n de operadores de alto nivel, aunque estos mismos sean definidos mediante un esquema funcional.\n\n\n\n2.2.3 M√°quina de acceso aleatorio (RAM)\nEs un m√≥delo que describe una computadora con registros. A diferencia de una computadora f√≠sica, no tienen limitaci√≥n en su capacidad, ni en la cantidad de registros, ni en la precisi√≥n de los mismos. Cada registro puede ser identicado de manera √∫nica y su contenido le√≠do y escrito mediante reglas o instrucciones formando un programa. En particular reconoce las diferencias entre registros de los programas y registros de datos, i.e., arquitectura harvard. Existe un n√∫mero m√≠nimo de instrucciones necesarias (i.e., incremento, decremento, poner a cero, copiar, salto condicional, parar) pero es com√∫n construir esquemas m√°s complejos basados en estas primitivas. Se necesita un registro especial que indica el registro de programa siendo ejecutado. Los accesos a los registros tienen un tiempo constante a diferencia de otros esquemas; es el modelo m√°s cercano a como funciona una computadora moderna entre los que se hemos revisado.\n\nUna computadora moderna difieres de una m√°quina RAM, por ejemplo, a diferencia de una computadora f√≠sica se suponen infinitos registros con precisi√≥n infinita. Debido a los costos de los semiconductores y la energ√≠a necesar√≠a, es conveniente construir computadoras con una jerarqu√≠a de memoria: los niveles con mayores prestaciones (e.g., r√°pidez) son los m√°s escasos. Es importante sacar provecho de esta jerarqu√≠a siempre que sea posible. Las operaciones tambi√©n tienen costos diferentes, dependiendo de su implementaci√≥n a nivel de circuiter√≠a, as√≠ como tambi√©n existe cierto nivel de paralelizaci√≥n que no esta presente en una m√°quina RAM, tanto a nivel de procesamiento y lectura de datos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#sobre-la-importancia-del-modelo-de-c√≥mputo-en-el-curso",
    "href": "cap2-analisis.html#sobre-la-importancia-del-modelo-de-c√≥mputo-en-el-curso",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.3 Sobre la importancia del modelo de c√≥mputo en el curso",
    "text": "2.3 Sobre la importancia del modelo de c√≥mputo en el curso\nEn este curso nos enfocaremos en especificaciones de alto nivel, donde los algoritmos son convenientes para una computadora f√≠sica. Sin embargo, estaremos contando operaciones de inter√©s pensando en costos constantes en el acceso a memoria y en una selecci√≥n de operaciones, al estilo de una m√°quina RAM.\nLa selecci√≥n de operaciones de inter√©s tiene el esp√≠ritu de simplificar el an√°lisis, focalizando nuestros esfuerzos en operaciones que acumulan mayor costo y que capturan la din√°mica del resto. Adicionalmente al conteo de operaciones nos interesa el desempe√±o de los algoritmos en tiempo como magnitud f√≠sica medible, as√≠ como en la cantidad de memoria consumida, por lo que se aboradar√° el costo realizando mediciones experimentales. Se contrastar√° con el an√°lisis basado en conteo de operaciones siempre que sea posible.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#tipos-de-an√°lisis",
    "href": "cap2-analisis.html#tipos-de-an√°lisis",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.4 Tipos de an√°lisis",
    "text": "2.4 Tipos de an√°lisis\nLa pregunta inicial ser√≠a ¬øqu√© nos interesa saber de un algoritmo que resuelve un problema? probablemente, lo primero ser√≠a saber si produce resultados correctos. Despu√©s, entre el conjunto de las alternativas que producen resultados correctos, es determinante obtener su desempe√±o para conocer cu√°l es m√°s conveniente para resolver un problema.\nEn ese punto, es necesario reconocer que para un problema, existen diferentes instancias posibles, esto es el espacio de instancias del problema, y que cada una de ellas exigir√≠an soluciones con diferentes costos para cada algoritmo. Por tanto existen diferentes tipos de an√°lisis y algoritmos.\n\nAn√°lisis de mejor caso. Obtener el m√≠nimo de resolver cualquier instancia posible, puede parecer poco √∫til desde el punto de vista de decisi√≥n para la selecci√≥n de un algoritmo, pero puede ser muy √∫til para conocer un problema o un algoritmo.\nAn√°lisis de peor caso. Obtener el costo m√°ximo necesario para resolver cualquier instancia posible del problema con un algoritmo, este es un costo que si nos puede apoyar en la decisi√≥n de selecci√≥n de un algoritmo; sin embargo, en muchas ocasiones, puede ser poco informativo o innecesario ya que tal vez hay pocas instancias que realmente lo am√©riten.\nAn√°lisis promedio. Se enfoca en obtener un an√°lisis promedio basado en la poblaci√≥n de instancias del problema para un algoritmo dado.\nAn√°lisis amortizado. Se enfoca en an√°lisis promedio pero para una secuencia de instancias.\nAn√°lisis adaptativo. Para un subconjunto bien caracterizado del espacio de instancias de un problema busca an√°lizar los costos del algoritmo en cuesti√≥n. La caracterizaci√≥n suele estar en t√©rminos de una medida de complejidad para el problema; y la idea general es medir si un algoritmo es capaz de sacar provecho de instancias f√°ciles.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#notaci√≥n-asint√≥tica",
    "href": "cap2-analisis.html#notaci√≥n-asint√≥tica",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.5 Notaci√≥n asint√≥tica",
    "text": "2.5 Notaci√≥n asint√≥tica\nRealizar un conteo de operaciones y mediciones es un asunto complejo que requiere focalizar los esfuerzos. Para este fin, es posible contabilizar solo algunas operaciones de importancia, que se supondr√≠an ser√≠an las m√°s costosas o que de alguna manera capturan de manera m√°s fiel la din√°mica de costos.\nEl comportamiento asint√≥tico es otra forma de simplificar y enfocarnos en los puntos de importancia, en este caso, cuando el tama√±o de la entrada es realmente grande. Es importante mencionar, que no se esperan entradas de tama√±o descomunal, ni tampoco se espera cualquier tipo de entrada.\n\n2.5.1 Notaci√≥n \\(\\Theta\\)\nPara una funci√≥n dada \\(g(n)\\) denotamos por \\(\\Theta(g(n))\\) el siguiente conjunto de funciones:\n\\[\\begin{align}\n\\Theta(g(n)) &=  \\left\\{ f(n) \\mid \\text{ existen las constantes positivas }c_1, c_2 \\text{ y } n_0 \\text{ tal que } \\right.\\\\\n    ~ & \\left. 0 \\leq c_1 g(n) \\leq f(n) \\leq c_2 g(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nesto es, una funci√≥n \\(f(n)\\) pertenece al conjunto \\(g(n)\\) si \\(c_1 g(n)\\) y \\(c_2 g(n)\\) pueden cubrirla por abajo y por arriba, para esto deben existen las constantes positivas \\(c_1\\) y \\(c_2\\) y una \\(n\\) lo suficientemente larga, e.g., para eso la constante \\(n_0\\). La notaci√≥n propiamente de conjuntos puede usarse \\(f(n) \\in \\Theta(g(n))\\) pero es com√∫n en el √°rea usar \\(f(n) = \\Theta(g(n))\\) para expresar la pertenencia; este abuso de la notaci√≥n tiene ventaja a la hora de plantear los problemas de an√°lisis.\n\n\n2.5.2 Notaci√≥n \\(O\\)\nSe utiliza para indicar una cota asint√≥tica superior. Una funci√≥n \\(f(n)\\) se dice que esta en \\(O(g(n))\\) si esta en el siguiente conjunto:\n\\[\\begin{align}\nO(g(n)) &=  \\left\\{ f(n)  \\mid \\text{ existen las constantes positivas }c \\text{ y } n_0 \\text{ tal que } \\right.\\\\\n    ~& \\left. 0 \\leq f(n) \\leq c g(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nLa notaci√≥n \\(O\\) se usa para dar una cota superior, dentro de un factor constante. Al escribir \\(f(n) = O(g(n))\\) se indica que \\(f(n)\\) es miembro del conjunto \\(O(g(n))\\); hay que notar que \\(f(n) = \\Theta(g(n))\\) implica que \\(f(n) = O(g(n))\\), i.e., \\(\\Theta(g(n)) \\subseteq O(g(n))\\).\n\n\n2.5.3 Notaci√≥n \\(\\Omega\\)\nAl contrario de \\(O\\), la notaci√≥n \\(\\Omega\\) da una cota asint√≥tica inferior. Una funci√≥n \\(f(n)\\) se dice que esta en \\(\\Omega(g(n))\\) si esta en el siguiente conjunto:\n\\[\\begin{align}\n\\Omega(g(n)) = & \\left\\{ f(n)  \\mid \\text{ existen las constantes positivas }c \\text{ y } n_0 \\text{ tal que } \\right. \\\\\n    & \\left. 0 \\leq c g(n) \\leq f(n) \\text{ para todo } n \\geq n_0 \\right\\} \\\\\n\\end{align}\\]\nDado que la \\(\\Omega\\) define una cota superior, basicamente si \\(f(n) = \\Omega(g(n))\\), entonces \\(f(n)\\) debe estar por encima de \\(g(n)\\) con las constantes \\(c\\) y \\(n_0\\) adecuadas. Al igual que la notaci√≥n \\(O\\), la notaci√≥n \\(\\Omega\\) es menos estricta que \\(\\Theta\\), esto es \\(f(n) = \\Theta(g(n))\\) implica que \\(f(n) = \\Omega(g(n))\\), por lo que \\(\\Theta(g(n)) \\subseteq \\Omega(g(n))\\).\nPor tanto, si \\(f(n) = O(g(n))\\) y \\(f(n) = \\Omega(g(n))\\) entonces \\(f(n) \\in \\Theta(g(n))\\).\n\nEs importante conocer los ordenes de crecimiento m√°s comunes de tal forma que podamos realizar comparaciones r√°pidas de costos, y dimensionar las diferencias de recursos entre diferentes tipos de costos. La notaci√≥n asint√≥tica hace uso extensivo de la diferencia entre diferentes ordenes de crecimiento para ignorar detalles y simplificar el an√°lisis de algoritmos.\n\n\n\n2.5.4 Apoyo audio-visual\nEn los siguientes videos se profundiza sobre los modelos de c√≥mputo y los diferentes tipos de an√°lisis sobre algoritmos.\n\nParte 1: \nParte 2: \nParte 3: \n\n\n\n2.5.5 Ordenes de crecimiento\n\n\nDado que la idea es realizar un an√°lisis asint√≥tico, las constantes suelen ignorarse, ya que cuando el tama√±o de la entrada es suficientemente grande, los t√©rminos con mayor orden de magnitud o crecimiento dominar√°n el costo. Esto es, es una simplificaci√≥n necesar√≠a.\nLos ordenes de crecimiento son maneras de categorizar la velocidad de crecimiento de una funci√≥n, y para nuestro caso, de una funci√≥n de costo. Junto con la notaci√≥n asimpt√≥tica nos permite concentrarnos en razgos gruesos que se mantienen para entradas grandes, m√°s que en los detalles, y no perder el punto de inter√©s. A continuaci√≥n veremos algunas funciones con crecimientos paradigm√°ticos; las observaremos de poco en poco para luego verlos en conjunto.\n\n2.5.5.1 Costo constante, logaritmo y lineal\nLa siguiente figura muestra un crecimiento nulo (constante), logaritmico y lineal. Note como la funci√≥n logar√≠tmica crece lentamente.\n\nusing Plots, LaTeXStrings\nn = 300 # 300 puntos\n\nplot(1:n, [10 for x in 1:n], label=L\"c\")\nplot!(1:n, [log2(x) for x in 1:n], label=L\"\\log{n}\")\nplot!(1:n, [x for x in 1:n], label=L\"n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.5.2 Costo \\(n \\log n\\) y polinomial\nA continuaci√≥n veremos tres funciones, una funci√≥n con \\(n\\log n\\) y una funci√≥n cuadr√°tica y una c√∫bica. Note como para valores peque√±os de \\(n\\) las diferencias no son tan apreciables para como cuando comienza a crecer \\(n\\); as√≠ mismo, observe los valores de \\(n\\) de las figuras previas y de la siguiente, este ajuste de rangos se hizo para que las diferencias sean apreciables.\n\nn = 7 # note que se usan menos puntos porque 300 ser√≠an demasiados para el rango\n\nplot(1:n, [x * log2(x) for x in 1:n], label=L\"n\\log_2{n}\")\nplot!(1:n, [x^2 for x in 1:n], label=L\"n^2\")\nplot!(1:n, [x^3 for x in 1:n], label=L\"n^3\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.5.3 Exponencial\nA continuaci√≥n se compara el crecimiento de una funci√≥n exponencial con una funci√≥n polinomial. Note que la funci√≥n polinomial es de grado 4 y que la funci√≥n exponencial tiene como base 2; a√∫n cuando para n√∫meros menores de aproximadamente 16 la funci√≥n polinomial es mayor, a partir de ese valor la funci√≥n \\(2^n\\) supera rapidamente a la polinomial.\n\nn = 20\n\nplot(1:n, [x^4 for x in 1:n], label=L\"n^4\")\nplot!(1:n, [2^x for x in 1:n], label=L\"2^n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.5.4 Crecimiento factorial\nVease como la funci√≥n factorial crece mucho m√°s r√°pido que la funci√≥n exponencial para una \\(n\\) relativamente peque√±a. Vea las magnitudes que se alcanzan en el eje \\(y\\), y comparelas con aquellas con los anteriores crecimientos.\n\nn = 20\n\nplot(1:n, [2^x for x in 1:n], label=L\"2^n\")\nplot!(1:n, [factorial(x) for x in 1:n], label=L\"n!\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.5.5 Un poco m√°s sobre funciones de muy alto costo\n\nn = 10\n\nplot(1:n, [factorial(x) for x in 1:n], label=L\"n!\")\nplot!(1:n, [x^x for x in Int128(1):Int128(n)], label=L\"n^n\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVea la figura anterior, donde se compara \\(n!\\) con \\(n^n\\), observe como es que cualquier constante se vuelve irrelevante rapidamente; aun para \\(n^n\\) piense en \\(n^{n^n}\\).\nNote que hay problemas que son realmente costosos de resolver y que es necesario conocer si se comporta as√≠ siempre, si es bajo determinado tipo de entradas. Hay problemas en las diferentes √°reas de la ciencia de datos, donde veremos este tipo de costos, y habr√° que saber cuando es posible solucionarlos, o cuando se deben obtener aproximaciones que nos acerquen a las respuestas correctas con un costo manejable, es decir, mediar entre exactitud y costo. En este curso se abordaran problemas con un costo menor, pero que por la cantidad de datos, i.e., \\(n\\), se vuelven muy costosos y veremos como aprovechar supuestos como las distribuciones naturales de los datos para mejorar los costos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#el-enfoque-experimental",
    "href": "cap2-analisis.html#el-enfoque-experimental",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.6 El enfoque experimental",
    "text": "2.6 El enfoque experimental\nLa notaci√≥n asint√≥tica nos permite alcanzar un lenguaje com√∫n y preciso sobre los costos de problemas y algoritmos; es de especial importancia para la evaluaci√≥n de las alternativas en la literatura especializada, y elegir algoritmos a√∫n sin la necesidad de implementaci√≥n. El an√°lisis asint√≥tico da la posibilidad de conocer el desempe√±o desde diferentes perspectivas como peor caso o caso promedio, utilizando un m√≥delo de computaci√≥n, y siempre pensando en entradas lo suficientemente grandes.\nEn la pr√°ctica, existe una m√∫ltitud de razones por los cuales los problemas que se resuelven podrian no ser tan grandes como para que un algoritmo domine a otros de manera asint√≥tica, las instancias podr√≠an no ser tan generales como para preocuparse en el peor caso, o el caso promedio general. En muchas situaciones, es importante sacar provecho de los casos f√°ciles, sobre todo cuando el problema a resolver podr√≠a asegurar que dichos casos simples sean abundantes. Dada la complejidad detr√°s de definir sub-conjuntos de instancias y llevar a cabo un an√°lisis formal, se vuelve imperativo realizar pruebas experimentales.\nPor otra parte, dada la complejidad de una computadora moderna, es necesario realizar evaluaciones experimentales de los algoritmos que tengan una complejidad similar. Las computadoras reales tienen una jerarquia de memoria con tama√±os y velocidades de acceso divergentes entre s√≠, con optimizaciones integradas sobre la predicci√≥n de acceso y cierto nivel de paralelismo. Incluso, cada cierto tiempo se obtienen optimizaciones en los dispositivos que podr√≠an mejorar los rendimientos, por lo que es posible que con una generaci√≥n a otra, lo que sabemos de los algoritmos y su desempe√±o en computadoras y cargas de trabajo reales cambie.\n\n2.6.1 Metodolog√≠a experimental\nAlgunos de los algoritmos que se ver√°n en este libro son sumamente rapidos en la pr√°ctica para resolver una instancia pr√°ctica por lo que medir el desempe√±o de instancias solas podr√≠a no tener sentido. La acumulaci√≥n de operaciones es fundamental, as√≠ como la diversidad de las instancias tambi√©n lo es. Caracterizar las entradas es de vital importancia ya que la adaptabilidad a las instancias es parte de los objetivos.\nEntonces, estaremos probando conjuntos de instancias, caracterizadas y estaremos utilizando tiempos promedios. Tambi√©n estaremos usando conteo de operaciones, por lo que los algoritmos en cuesti√≥n muchas veces ser√°n adaptados para poder realizar este conteo.\nEn Julia etaremos utilizando las siguientes instrucciones:\n\n@time expr macro que mide el tiempo en segundo utilizado por expr, tambi√©n reporta el n√∫mero de alojaciones de memoria. Note que reducir la cantidad de memoria alojada puede significar reducir el tiempo de una implementaci√≥n, ya que el manejo de memoria din√°mica es costoso.\n@benchmark expr params macro del paquete BenchmarkTools que automatiza la repetici√≥n de expr para obtener diferentes mediciones y hacer un reporte, params permite manipular la forma en que se reliza la evaluaci√≥n.\n@btime expr params macro del paquete BenchmarkTools que mimetiza la salida de @time.\n\n\na = rand(Float32, 3, 3)\n1@time a * a\n2@time a * a\n\n\n1\n\nTodas las fuciones se deben compilar, la primera llamada uncluye los costos de compilaci√≥n.\n\n2\n\nEl costo sin compilaci√≥n, hay una alojaci√≥n que es la matriz donde se guarda el resultado.\n\n\n\n\n  0.841567 seconds (2.01 M allocations: 136.608 MiB, 3.33% gc time, 99.97% compilation time)\n  0.000005 seconds (1 allocation: 96 bytes)\n\n\n3√ó3 Matrix{Float32}:\n 0.635295  0.150821  0.310147\n 1.02056   0.23071   0.674775\n 1.71173   0.369326  1.20393\n\n\nTanto @benchmark como @btime aceptan interpolaci√≥n de variables con el prefijo $ para controlar la evaluaci√≥n de una expresi√≥n se debe contar como parte de lo que se quiere medir o no. Se puede combinar con el parametro setup para controlar de manera precisa las entradas para evaluar cada una de las repeticiones de expr.\n\nusing BenchmarkTools\n\n@benchmark a * a setup=(a=rand(Float32, 3, 3))\n\nBenchmarkTools.Trial: 10000 samples with 985 evaluations.\n Range (min ‚Ä¶ max):  46.417 ns ‚Ä¶  2.232 Œºs  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 96.36%\n Time  (median):     48.330 ns              ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   51.039 ns ¬± 35.694 ns  ‚îä GC (mean ¬± œÉ):  2.23% ¬±  3.83%\n\n  ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ                                ‚ñÇ\n  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ ‚ñà\n  46.4 ns      Histogram: log(frequency) by time      67.6 ns &lt;\n\n Memory estimate: 96 bytes, allocs estimate: 1.\n\n\n\n\na = rand(Float32, 3, 3)\n@btime a * a setup=(a=$a)\n\n  47.875 ns (1 allocation: 96 bytes)\n\n\n3√ó3 Matrix{Float32}:\n 0.575313  0.847652  0.395764\n 0.417129  0.719546  0.322025\n 0.375838  0.367533  0.22682\n\n\nEl parametro sample controla el n√∫mero m√°ximo de muestras que se tomar√°n para el an√°lisis, y seconds limita el tiempo sobre el cual se tomar√°n muestras; se asegura que al menos se tomar√° una muestra, se debe tener en cuenta que puede costar m√°s que seconds.1\n\na = rand(Float32, 3, 3)\nb = rand(Float32, 3, 3)\n@benchmark a * b setup=(a=$a, b=$b) samples=1000 seconds=0.33\n\nBenchmarkTools.Trial: 1000 samples with 980 evaluations.\n Range (min ‚Ä¶ max):  63.631 ns ‚Ä¶ 880.123 ns  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 89.30%\n Time  (median):     70.518 ns               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   77.375 ns ¬±  38.616 ns  ‚îä GC (mean ¬± œÉ):  1.79% ¬±  3.96%\n\n  ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ                                                   \n  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ ‚ñà\n  63.6 ns       Histogram: log(frequency) by time       209 ns &lt;\n\n Memory estimate: 96 bytes, allocs estimate: 1.\n\n\n\n\n2.6.2 Ejemplo del c√°lculo de m√°ximo de un arreglo y diferentes tipos de costo.\n‚Äì\n\n\n1function maximo(col)\n    maxpos = 1\n    actualizaciones = 1\n    i = 2\n\n    while i &lt; length(col)\n        if col[maxpos] &lt; col[i]\n            maxpos = i\n            actualizaciones += 1\n        end\n        i += 1\n    end\n\n    maxpos, actualizaciones\nend\n\n\n1\n\nFunci√≥n que encuentra el m√°ximo en una secuencia y devuelve su posici√≥n, y adem√°s devuelve el n√∫mero de veces que se actualiz√≥ el m√°ximo en el recorrido.\n\n\n\n\nmaximo (generic function with 1 method)\n\n\n\na = rand(UInt32, 128)\n1@benchmark maximo($a) samples=100 seconds=3\n\n\n1\n\nUn an√°lisis de desempe√±o usando @benchmark; probando con m√°ximo 100 samples en 3 segundos.\n\n\n\n\nBenchmarkTools.Trial: 100 samples with 875 evaluations.\n Range (min ‚Ä¶ max):  154.687 ns ‚Ä¶ 215.714 ns  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 0.00%\n Time  (median):     160.295 ns               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   162.588 ns ¬±   8.815 ns  ‚îä GC (mean ¬± œÉ):  0.00% ¬± 0.00%\n\n  ‚ñà        ‚ñÇ         ‚ñÅ                                           \n  ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ ‚ñÉ\n  155 ns           Histogram: frequency by time          188 ns &lt;\n\n Memory estimate: 0 bytes, allocs estimate: 0.\n\n\nNote que aunque se tiene un an√°lisis muy detallado del desempe√±o, otras medidas de costo caen fuera del dise√±o del paquete, por lo que es necesario hacerlas por otros medios. Por ejemplo, suponga que el n√∫mero de actualizaciones es nuesta medida de desempe√±o, un c√≥digo donde se capturen las actualizaciones\n\n1using StatsBase\n2a = [maximo(rand(UInt32, 128))[2] for i in 1:100]\n3quantile(a, [0.0, 0.25, 0.5, 0.75, 1.0])\n\n\n1\n\nInclusi√≥n de un paquete para c√°lculo de estad√≠sticas b√°sicas.\n\n2\n\nDefinici√≥n de 100 experimentos que calculan maximo sobre arreglos aleatorios.\n\n3\n\nC√°lculo del m√≠nimo, cuantiles 0.25, 0.5, 0.75, y el m√°ximo, para determinar el desempe√±o.\n\n\n\n\n5-element Vector{Float64}:\n 1.0\n 4.0\n 5.0\n 6.0\n 9.0",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#actividades",
    "href": "cap2-analisis.html#actividades",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.7 Actividades",
    "text": "2.7 Actividades\nComparar mediante simulaci√≥n en un notebook de Jupyter o Quarto los siguientes √≥rdenes de crecimiento:\n\n\\(O(1)\\) vs \\(O(\\log n)\\)\n\\(O(n)\\) vs \\(O(n \\log n)\\)\n\\(O(n^2)\\) vs \\(O(n^3)\\)\n\\(O(a^n)\\) vs \\(O(n!)\\)\n\\(O(n!)\\) vs \\(O(n^n)\\)\nEscoja los rangos adecuados para cada comparaci√≥n, ya que como ser√° evidente despu√©s, no es pr√°ctico fijar los rangos.\nCree una figura por comparaci√≥n, i.e., cinco figuras. Discuta lo observado por figura.\nCree una tabla donde muestre tiempos de ejecuci√≥n simulados para algoritmos ficticios que tengan los √≥rdenes de crecimiento anteriores, suponiendo que cada operaci√≥n tiene un costo de 1 nanosegundo.\n\nUse diferentes tama√±os de entrada \\(n=100\\), \\(n=1000\\), \\(n=10000\\) y \\(n=100000\\).\nNote que para algunas f√≥rmulas, los n√∫meros pueden ser muy grandes, tome decisiones en estos casos y defiendalas en el reporte.\n\nDiscuta las implicaciones de costos de c√≥mputo necesarios para manipular grandes vol√∫menes de informaci√≥n, en el mismo notebook.\n\n\n2.7.1 Entregable\nSu trabajo se entregar√° en PDF y con el notebook fuente; deber√° estar plenamente documentado, con una estructura que permita a un lector interesado entender el problema, sus experimentos y metodolog√≠a, as√≠ como sus conclusiones. Tenga en cuenta que los notebooks pueden alternar celdas de texto y c√≥digo.\nNo olvide estructurar su reporte, en particular el reporte debe cubrir los siguientes puntos:\n\nT√≠tulo del reporte, su nombre.\nIntroducci√≥n.\nC√≥digo cercano a la presentaci√≥n de resultados.\nFiguras y comparaci√≥n de los √≥rdenes de crecimiento.\nAn√°lisis y simulaci√≥n de costo en formato de tabla.\nConclusi√≥n. Debe abordar las comparaciones hechas y la simulaci√≥n; tambi√©n toque el tema de casos extremos y una \\(n\\) variable y asint√≥ticamente muy grande.\nLista de referencias. Nota, una lista de referencias que no fueron utilizadas en el cuerpo del texto ser√° interpretada como una lista vac√≠a.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#bibliograf√≠a",
    "href": "cap2-analisis.html#bibliograf√≠a",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "2.8 Bibliograf√≠a",
    "text": "2.8 Bibliograf√≠a\nCormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2022). Introduction to Algorithms (2nd ed.). MIT Press.\n\nParte I: Cap. 1, 2, 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap2-analisis.html#footnotes",
    "href": "cap2-analisis.html#footnotes",
    "title": "2¬† Introducci√≥n al an√°lisis de algoritmos con Julia",
    "section": "",
    "text": "Se recomienda visitar el sitio https://juliaci.github.io/BenchmarkTools.jl/stable/ para m√°s informaci√≥n sobre el paquete BenchmarkTools, y en particular para sus parametros, como guardar informaci√≥n de corridas.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introducci√≥n al an√°lisis de algoritmos con Julia</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html",
    "href": "cap3-estructuras.html",
    "title": "3¬† Estructuras de datos elementales",
    "section": "",
    "text": "Objetivo\nImplementar, aplicar y caracterizar el desempe√±o de algoritmos en peor caso y adaptativos para b√∫squeda en arreglos ordenados. Se discutir√°n estructuras de datos b√°sicas que ser√°n de gran utilidad al momento de construir programas y de resolver problemas m√°s complejos; nos enfocaremos en las estructuras de datos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#introducci√≥n",
    "href": "cap3-estructuras.html#introducci√≥n",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.1 Introducci√≥n",
    "text": "3.1 Introducci√≥n\nEn esta unidad se discutir√°n las propiedades y operaciones b√°sicas de estructuras como conjuntos, listas, pilas, colas, arreglos, vectores, matrices y matrices dispersas. Los ejemplos de c√≥digo se muestran en el lenguaje de programaci√≥n Julia, pero que puede ser traducido f√°cilmente en otros lenguajes de programaci√≥n.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#conjuntos",
    "href": "cap3-estructuras.html#conjuntos",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.2 Conjuntos",
    "text": "3.2 Conjuntos\nLos conjuntos son estructuras abstractas que representan una colecci√≥n de elementos, en particular, dado las posibles aplicaciones un conjunto puede tener contenido inmutable o mutable. Un conjunto puede estar vacio (\\(\\emptyset\\)) o contener elementos, e.g., \\(\\{a, b, c\\}\\). La operaci√≥n uni√≥n \\(\\cup\\) construye un nuevo conjunto a partir de otros \\(\\{a, b\\} \\cup \\{c\\} = \\{a, b, c\\}\\); la intersecci√≥n se indica con el operador \\(\\cap\\), e.g.¬†\\(\\{a, b, c\\} \\cap \\{b, d\\} = \\{b\\}\\). El tama√±o de una colecci√≥n lo representamos con barras, e.g., \\(|\\{a, b\\}| = 2\\). Tambi√©n es √∫til consultar por membresia \\(a \\in \\{a, b, c\\}\\) o por su negaci√≥n, i.e., \\(d \\not\\in \\{a, b, c\\}\\). Es com√∫n usar conjuntos mutables en diferentes algoritmos, esto es, que permitan inserciones y borrados sobre la misma estructura; desde el punto de vista de eficiencia, esto puede reducir las operaciones de manipulaci√≥n de datos as√≠ como de la gesti√≥n de memoria. Suponga el conjunto \\(S = \\{a, b, c\\}\\), la funci√≥n \\(pop!(S, b)\\) resultar√≠a en \\(\\{a, c\\}\\), y la funci√≥n \\(push!(S, d)\\) resultar√≠a en \\(\\{a, c, d\\}\\) al encadenar estas operaciones. Note que el s√≠mbolo \\(!\\) solo se esta usando en cooncordancia con el lenguaje de programaci√≥n Julia para indicar que la funci√≥n cambiar√≠a el argumento de entrada; es una convenci√≥n, no un operador en s√≠ mismo. Note que estamos usando una sintaxis muy sencilla \\(fun(arg1, arg2, ...)\\) para indicar la aplicaci√≥n de una funci√≥n u operaci√≥n a una serie de argumentos.\nHay m√∫ltiples formas de representar conjuntos ya que los requerimientos de los algoritmos son diversos y tener la representaci√≥n correcta puede ser una diferencia importante en el rendimiento. Las implementaciones y algoritmos alrededor pueden llegar a ser muy sofisticados, dependiendo de las caracter√≠sticas que se desean, algunas de las cuales ser√°n el centro de estudio de este curso.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#tuplas-y-estructuras",
    "href": "cap3-estructuras.html#tuplas-y-estructuras",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.3 Tuplas y estructuras",
    "text": "3.3 Tuplas y estructuras\nLas tuplas son colecciones abstractas ordenadas, donde incluso puede haber repetici√≥n, pueden verse como una secuencia de elementos, e.g., \\(S = (a, b, c)\\); podemos referirnos a la \\(i\\)√©sima posici√≥n de la forma \\(S_i\\), o incluso \\(S[i]\\), si el contexto lo amerita, e.g., pseudo-c√≥digo que pueda ser transferido a un lenguaje de programaci√≥n m√°s f√°cilmente. Es com√∫n que cada parte de la tupla pueda contener cierto tipo de dato, e.g., enteros, n√∫meros de punto flotante, s√≠mbolos, cadenas de car√°cteres, etc. Una tupla es muy amena para ser representada de manera contigua en memoria. En el lenguaje de programaci√≥n Julia, las tuplas se representan entre par√©ntesis, e.g., \\((1, 2, 3)\\).\n\nt = (10, 20, 30)\n\nt[1] * t[3] - t[2]\n\n280\nDefinici√≥n y acceso a los campos de una tupla en Julia\n\n\n\n\nEn algunos lenguajes de programaci√≥n como Julia, una tupla puede enviarse como valor (copiar) cuando se utiliza en una funci√≥n; por lo mismo, puede guardarse en el stack, que es la memoria inmediata que se tiene en el contexto de ejecuci√≥n de una funci√≥n. En esos casos, se puede optimizar el manejo de memoria (alojar y liberar), lo cu√°l puede ser muy beneficioso para un algoritmo en la pr√°ctico. El otro esquema posible es el heap, que es una zona de memoria que debe gestionarse (memoria din√°mica); es m√°s flexible y duradera entre diferentes llamadas de funciones en un programa. Los patrones esperados son dispersos y puede generar fragmentaci√≥n.\nUna estructura es una tupla con campos nombrados; es muy √∫tilizada en lenguajes de programaci√≥n, por ejemplo, en Julia la siguiente estructura puede representar un punto en un plano:\n\nstruct Point\n  x::Float32\n  y::Float32\nend\n\nNote la especificaci√≥n de los tipos de datos que en conjunto describir√°n como dicha estructura se maneja por una computadora, y que en t√©rminos pr√°cticos, es determinante para el desempe√±o. Es com√∫n asignar valores satelitales en programas o algoritmos, de tal forma que un elemento simple sea manipulado o utilizado de manera explicita en los algoritmos y tener asociados elementos secundarios que se vean afectados por las operaciones. Los conjuntos, tuplas y las estructuras son excelentes formas de representar datos complejos de una manera sencilla.\nEn Julia, es posible definir funciones o m√©todos al rededor del tipo de tuplas y estructuras.\n\n\nEs importante saber que si algunos de los campos o datos de una tupla o estructura estan en el heap entonces solo una parte estar√° en el stack; i.e., en el caso extremo solo ser√°n referencias a datos en el heap. Esto puede llegar a complicar el manejo de memoria, pero tambi√©n puede ser un comportamiento sobre el que se puede razonar y construir.\n\n\"\"\"\n  Calcula la norma de un vector representado\n  como un tupla\n\"\"\"\nfunction norm(u::Tuple)\n  s = 0f0\n  for i in eachindex(u)\n    s = u[i]^2\n  end\n  sqrt(s)\nend\n\n\"\"\"\n  Calcula la norma de un vector de 2 dimensiones\n  representado como una estructura\n\"\"\"\nfunction norm(u::Point)\n  sqrt(u.x^2 + u.y^2)\nend\n\n(norm((1, 1, 1, 1)), norm(Point(1, 1)))\n\n(1.0, 1.4142135f0)\nFunciones sobre diferentes tipos de datos\n\n\nNote que la funci√≥n es diferente para cada tipo de entrada; a este comportamiento se le llamada despacho m√∫ltiple y ser√° un concepto com√∫n este curso. En otros lenguajes de programaci√≥n se implementa mediante orientaci√≥n a objetos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#arreglos",
    "href": "cap3-estructuras.html#arreglos",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.4 Arreglos",
    "text": "3.4 Arreglos\nLos arreglos son estructuras de datos que mantienen informaci√≥n de un solo tipo, tienen un costo constante \\(O(1)\\) para acceder a cualquier elemento (tambi√©n llamado acceso aleatorio) y tipicamente se implementan como memoria contigua en una computadora. Al igual que las tuplas, son colecciones ordenadas, las estaremos accediendo a sus elementos con la misma notaci√≥n. En este curso usaremos arreglos como colecciones representadas en segmentos contiguos de memoria con dimensiones l√≥gicas fijas. A diferencia de las tuplas, es posible reemplazar valores, entonces \\(S_{ij} \\leftarrow a\\), reemplazar√° el contenido de \\(S\\) en la celda especificada por \\(a\\).\n\n\nJulia tiene un soporte para arreglos excepcional, el cual apenas trataremos ya que se enfoca en diferentes √°reas del c√≥mputo num√©rico, y nuestro curso esta orientado a algoritmos. En Python, estructuras similares se encuentra en el paquete Numeric Python o numpy; tenga en cuenta que las afirmaciones sobre el manejo de memoria y representaci√≥n que estaremos usando se apegan a estos modelos, y no a las listas nativas de Python.\nA diferencia de las tuplas, pueden tener m√°s que una dimensi√≥n. La notaci√≥n para acceder a los elementos se extiende, e.g.¬†para una matriz \\(S\\) (arreglo bidimensional) \\(S_{ij}\\) se refiere a la celda en la fija \\(i\\) columna \\(j\\), lo mismo que \\(S[i, j]\\). Si pensamos en datos num√©ricos, un arreglo unidimensional es √∫til para modelar un vector de m√∫ltiples dimensiones, un arreglo bidimensional para representar una m√°triz de tama√±o \\(m \\times n\\), y arreglos de dimensi√≥n mayor pueden usarse para tensores. Se representan en memoria en segmentos contiguos, y los arreglos de m√∫ltiples dimensiones ser√°n representados cuyas partes pueden ser delimitadas mediante aritm√©tica simple, e.g., una matriz de tama√±o \\(m \\times n\\) necesitar√° una zona de memoria de \\(m \\times n\\) elementos, y se puede acceder a la primera columna mediante en la zona \\(1,\\dots,m\\), la segunda columna en \\(m+1,\\dots,2m\\), y la \\(i\\)√©sima en \\((i-1)m+1,\\dots,im\\); esto es, se implementa como el acceso en lotes de tama√±o fijo en un gran arreglo unidimensional que es la memoria.\n\n\nEsta es la manera que en general se manejan los datos en una computadora, y conocerlo de manera expl√≠cita nos permite tomar decisiones de dise√±o e implementaci√≥n.\n\n\n\n\n\n\n\n\nlista\n\n\n\nRAM\n\nmemoria RAM\n\notros\ndatos\n\ncolumna 1 - x[:, 1]\n\nx[1,1]\n\nx[2,1]\n\nx[3,1]\n\nx[4,1]\n\ncolumna 2 - x[:, 2]\n\nx[1,2]\n\nx[2,2]\n\nx[3,2]\n\nx[4,2]\n\ncolumna 3 - x[:, 3]\n\nx[1,3]\n\nx[2,3]\n\nx[3,3]\n\nx[4,3]\n\ncolumna 4 - x[:, 4]\n\nx[1,4]\n\nx[2,4]\n\nx[3,4]\n\nx[4,4]\n\notros\ndatos\n\n\n\n\n\n\nFigura¬†3.1: Esquema de una matriz en memoria.\n\n\n\n\n\nLa representaci√≥n precisa en memoria es significativa en el desempe√±o de operaciones matriciales como pueden ser el producto entre matrices o la inversi√≥n de las mismas. La manera como se acceden los datos es crucial en el dise√±o de los algoritmos.\nEl siguiente ejemplo define un vector \\(u\\) de \\(m\\) elementos y una matriz \\(X\\) de tama√±o \\(m \\times n\\), ambos en un cubo unitario de 4 dimensiones, y define una funci√≥n que selecciona el producto punto m√°ximo del vector \\(u\\) a los vectores columna de \\(X\\):\n\n\nfunction mydot(u, x)\n  s = 0f0\n  for i in eachindex(u, x)\n    s += u[i] * x[i]\n  end\n  s\nend\n\nfunction getmaxdot(u::Vector, X::Matrix)\n  maxpos = 1\n  # en la siguiente linea, @view nos permite controlar que\n  # no se copien los arreglos, y en su lugar, se usen referencias\n  maxdot = mydot(u, @view X[:, 1])\n  # obtiene el n√∫mero de columnas e itera apartir del 2do indice \n  mfilas, ncols = size(X)\n  for i in 2:ncols\n    d = mydot(u, @view X[:, i]) \n    if d &gt; maxdot\n      maxpos = i\n      maxdot = d\n    end\n  end\n\n  (maxpos, maxdot)\nend\n\ngetmaxdot(rand(Float32, 4), rand(Float32, 4, 1000))\n\n(917, 2.3676164f0)\n\n\nEn este c√≥digo puede verse como se separa el c√°lculo del producto punto en una funci√≥n, esto es porque en s√≠ mismo es una operaci√≥n importante; tambi√©n podemos aislar de esta forma la manera que se accede (el orden) a los vectores. La idea fue acceder columna a columna, lo cu√°l asegura el uso apropiado de los accesos a memoria. En la funci√≥n \\(getmaxdot\\) se resuelve el problema de encontrar el m√°ximo de un arreglo, y se puede observar que sin conocimiento adicional, este requiere \\(O(n)\\) comparaciones, para una m√°triz de \\(n\\) columnas. Esto implica que cada producto punto se cuenta como \\(O(1)\\), lo cual simplifica el razonamiento. Por la funci√≥n \\(mydot\\) podemos observar que el producto punto tiene un costo de \\(O(m)\\), por lo que la \\(getmaxdot\\) tiene un costo de \\(O(mn)\\) operaciones l√≥gicas y aritm√©ticas.\nEl producto entre matrices es un caso paradigm√°tico por su uso en la resoluci√≥n de problemas pr√°cticos, donde hay una gran cantidad de trabajo al rededor de los costos necesarios para llevarlo a cabo. En particular, el algoritmo na√Øve, es un algoritmo con costo c√∫bico, como se puede ver a continuaci√≥n:\n\nfunction myprod(A::Matrix, B::Matrix)\n  mA, nA = size(A)\n  mB, nB = size(B)\n  @assert nA == mB\n  C = Matrix{Float32}(undef, mA, nB)\n\n  for i in 1:mA\n    for j in 1:mB\n      rowA = @view A[i, :]\n      colB = @view B[:, i]\n      C[i, j] = mydot(rowA, colB)\n    end\n  end\n\n  C\nend\n\nA = rand(Float32, 5, 3)\nB = rand(Float32, 3, 5)\nC = myprod(A, B)\ndisplay(C)\n\n5√ó5 Matrix{Float32}:\n 0.814961  0.814961  0.814961  4.2092f-41  -2.30383f32\n 0.406502  0.406502  0.406502  7.0f-45      4.2092f-41\n 0.402574  0.402574  0.402574  0.0         -2.30385f32\n 0.344123  0.344123  0.344123  1.0f-44      4.2092f-41\n 1.43786   1.43786   1.43786   0.0         -2.05116f32\nFunciones sobre diferentes tipos de datos\n\n\nSe pueden ver dos ciclos iterando a lo largo de filas y columnas, adicionalmente un producto punto, el cual tiene un costo lineal en la dimensi√≥n del vector, por lo que el costo es c√∫bico. Esta implementaci√≥n es directa con la definici√≥n misma del producto matricial. Existen diferentes algoritmos para hacer esta operaci√≥n m√°s eficiente para diferentes casos o caracter√≠sticas de las matrices, siendo un √°rea de investigaci√≥n activa.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#listas",
    "href": "cap3-estructuras.html#listas",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.5 Listas",
    "text": "3.5 Listas\nLas listas son estructuras de datos ordenadas lineales, esto es, no se asume que los elementos se guardan de manera contigua y los accesos al \\(i\\)-√©simo elemento cuestan \\(O(i)\\). Se soportan inserciones y borrados. Por ejemplo, sea \\(L = [a, b, c, d]\\) una lista con cuatro elementos, \\(L_2 = b\\), \\(insert!(L, 2, z)\\) convertir√° \\(L = [a, z, b, c, d]\\) (note que \\(b\\) se desplaz√≥ y no se reemplaz√≥ como se esperar√≠a en un arreglo). La operaci√≥n \\(deleteat!(L, 2)\\) regresar√° la lista a su valor previo a la inserci√≥n. Estas operaciones que modifican la lista tambi√©n tienen diferentes costos dependiendo de la posici√≥n, e.g., donde el inicio y final de la secuencia (tambi√©n llamados head/cabeza y tail/cola) suelen ser m√°s eficientes que accesos aleatorios, ya que se tienen referencias a estas posiciones en memoria. Es de especial importancia la navegaci√≥n por la lista mediante operaciones de sucesor \\(succ\\) y predecedor \\(pred\\), que pueden encadenarse para obtener acceso a los elementos. A diferencia de un arreglo, las listas no requieren una notaci√≥n simple para acceso aleatorio a los elementos; los accesos t√≠picos son a los extremos de la lista (cabeza y cola), sucesor y predecesor.\n\n\n\n\n\n\n\n\nlista\n\n\n\nlist\n\nhead\n\ntail\n\n\n\na\n\na\n\n \n\n\n\nlist:n-&gt;a:n\n\n\n\n\n\nc\n\nc\n\n \n\n\n\nlist:s-&gt;c:s\n\n\n\n\n\nb\n\nb\n\n \n\n\n\na:c-&gt;b:w\n\n\n\n\n\nb:c-&gt;c:w\n\n\n\n\n\nnothing\n\nnothing\n\n\n\nc:c-&gt;nothing\n\n\n\n\n\n\n\n\nFigura¬†3.2: Una lista ligada simple\n\n\n\n\n\nLa Figura¬†3.2 muestra una lista ligada, que es una implementaci√≥n de lista que puede crecer f√°cilmente, funciona en el heap de memoria por lo que cada bloque requiere memoria din√°mica. Cada bloque es una estructura; se pueden distinguir dos tipos, la lista que contiene referencias al primer nodo y al √∫ltimo nodo. Los nodos de de datos contienen los elementos de la colecci√≥n y referencias al siguiente nodo, tambi√©n llamado sucesor. El nodo nothing es especial y significa que no hay m√°s elementos.\nEl siguiente c√≥digo muestra como la definici√≥n de lista ligada.\n\n\n\n\nListado¬†3.1: C√≥digo para una lista ligada simple\n\n\nstruct Node\n  data::Int\n  next::Union{Node,Nothing}\nend\n\nnode = Node(10, Node(20, Node(30, nothing)))\n\nprintln(node)\n(node.data, node.next.data, node.next.next.data)\n\n\n\n\nNode(10, Node(20, Node(30, nothing)))\n\n\n(10, 20, 30)\n\n\nEn el Listado¬†3.1 se ignora la referencia a tail (head se guarda en node), por lo que las operaciones sobre tail requieren recorrer la lista completa, costando \\(O(n)\\) en el peor caso para una lista de \\(n\\) elementos.\nPor su manera en la cual son accedidos los datos, se tienen dos tipos de listas muy √∫tiles: las colas y las pilas. Las colas son listas que se acceden solo por sus extremos, y emulan la pol√≠tica de el primero en entrar es el primero en salir (first in - first out, FIFO), y es por eso que se les llama colas haciendo referencia a una cola para realizar un tr√°mite o recibir un servicio. Las pilas o stack son listas con la pol√≠tica el √∫ltimo en entrar es el primero en salir (last in - first out, LIFO). Mientras que cualquier lista puede ser √∫til para implementarlas, algunas maneras ser√°n mejores que otras dependiendo de los requerimientos de los problemas siendo resueltos; sin embargo, es importante recordar sus pol√≠ticas de acceso para comprender los algoritmos que las utilicen.\nEntre las operaciones comunes tenemos las siguientes:\n\npush!(L, a): insertar \\(a\\) al final de la lista \\(L\\).\npop!(L): remueve el √∫ltimo elemento en \\(L\\).\ndeleteat!(L, pos): remueve el elemento en la posici√≥n \\(pos\\), se desplazan los elementos.\ninsert!(L, pos, valor): inserta \\(valor\\) en la posici√≥n \\(pos\\) desplazando los elementos anteriores.\n\n\n3.5.0.1 Ejercicios\n\nImplemente insert! y deleteat!\n¬øCu√°l ser√≠a la implementaci√≥n de succ y pred en una lista ligada?\n¬øCuales ser√≠an sus costos?\nA√±adiendo m√°s memoria, como podemos mejorar pred?\n\n\n\n3.5.1 Grafos\nOtras estructuras de datos elementales son los grafos. Un grafo \\(G = (V, E)\\) es una tupla compuesta por un conjunto de vertices \\(V\\) y el conjunto de aristas \\(E\\). Por ejemplo, el grafo con \\(A = (\\{a, b, c, d\\}, \\{(a, b), (b, c), (c, d), (d, a)\\})\\)\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na-&gt;b\n\n\n\n\n\nc\n\nc\n\n\n\nb-&gt;c\n\n\n\n\n\nd\n\nd\n\n\n\nc-&gt;d\n\n\n\n\n\nd-&gt;a\n\n\n\n\n\n\n\n\nFigura¬†3.3: Un grafo dirigido simple\n\n\n\n\n\nLos grafos son herramientas poderosas para representar de manera abstracta problemas que implican relaciones entre elementos. En algunos casos es √∫til asociar funciones a los v√©rtices y las aristas. Tenga en cuenta los siguientes ejemplos:\n\n\\(peso: V \\rightarrow \\mathbb{R}\\), la cual podr√≠a usarse como \\(peso(a) = 1.5\\).\n\\(costo: V \\times V \\rightarrow \\mathbb{R}\\), la cual podr√≠a usarse como \\(costo(a, b) = 2.0\\).\n\nLa estructura del grafo puede accederse mediante las funciones:\n\n\\(in(G, v) = \\{ u \\mid (u, v) \\in E\\}\\)\n\\(out(G, u) = \\{ v \\mid (u, v) \\in E\\}\\)\n\nas√≠ como el n√∫mero de vertices que entran y salen como:\n\n\\(indegree(G, v) = |in(G, v)|\\).\n\\(outdegree(G, u) = |out(G, u)|\\).\n\nUn grafo puede tener aristas no dirigidas, el grafo con \\(B=(\\{a, b, c, d\\}, \\{\\{a, b\\}, \\{b, c\\}, \\{c, d\\}, \\{d, a\\}\\})\\), no reconocer√° orden en las aristas.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\nd\n\nd\n\n\n\nc--d\n\n\n\n\nd--a\n\n\n\n\n\n\n\nFigura¬†3.4: Un grafo cuyas aristas no estan dirigidas\n\n\n\n\n\nPor lo tanto, podremos decir que \\((a, b) \\in E_A\\) pero \\((b, a) \\not\\in E_A\\). Por otro lado tenemos que \\(\\{a, b\\} \\in E_B\\), y forzando un poco la notaci√≥n, \\((a, b) \\in E_B\\), \\((b, a) \\in E_B\\); para los conjuntos de aristas de \\(A\\) y \\(B\\). La estructura puede ser accedida mediante \\(neighbors(G, u) = \\{ v \\mid \\{u, v\\} \\in E \\}\\).\nUn grafo puede estar representado de diferentes maneras, por ejemplo, un arreglo bidimensional (matriz), donde \\(S_{ij} = 1\\) si hay una arista entre los v√©rtices \\(i\\) y \\(j\\); y \\(S_{ij} = 0\\) si no existe una arista. A esta representaci√≥n se le llama matriz de adjacencia. Si el grafo tiene pocos \\(1\\)‚Äôs vale la pena tener una representaci√≥n diferente; este es el caso de las listas de adjacencia, donde se representa cada fila o cada columna de la matriz de adjacencia como una lista de los elementos diferentes de cero.\nExisten otras representaciones como la lista de coordenadas, coordinate lists (COO), o las representaciones dispersas compimidas, sparse row (CSR) y compressed sparse column (CSC) (Scott y T≈Øma 2023). Todas estas representaciones tratan de disminuir el uso de memoria y aprovechar la gran dispersi√≥n para realizar operaciones solo cuando sea estrictamente necesario.\nUn √°rbol es un grafo en el cual no existen ciclos, esto es, no existe forma que en una caminata sobre los v√©rtices, a traves de las aristas y prohibiendo regresarse aristas, es imposible regresar a un v√©rtice antes visto.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na--b\n\n\n\n\nd\n\nd\n\n\n\na--d\n\n\n\n\nc\n\nc\n\n\n\nb--c\n\n\n\n\ne\n\ne\n\n\n\nd--e\n\n\n\n\nf\n\nf\n\n\n\nd--f\n\n\n\n\n\n\n\nFigura¬†3.5: √Årbol con aristas no dirigidas\n\n\n\n\n\nEn algunos casos, es conveniente identificar v√©rtices especiales en un √°rbol \\(T=(V, E)\\). Un v√©rtice es la ra√≠z del √°rbol, \\(root(T)\\), es especial ya que seguramente se utilizar√° como acceso al √°rbol y por tanto contiene un camino a cada uno v√©rtices en \\(V\\). Cada v√©rtice puede tener, o no, hijos \\(children(T, u) = \\{ v \\mid (u, v) \\in E \\}\\). Se dice que \\(u\\) es un hoja (leaf) si \\(children(T, u) = \\emptyset\\), e interno (inner) si no es ni ra√≠z ni hoja.\n\n\n\n\n\n\n\n\nlista\n\n\n\na\n\na\n\n\n\nb\n\nb\n\n\n\na-&gt;b\n\n\n\n\n\nd\n\nd\n\n\n\na-&gt;d\n\n\n\n\n\nc\n\nc\n\n\n\nb-&gt;c\n\n\n\n\n\ne\n\ne\n\n\n\nd-&gt;e\n\n\n\n\n\nf\n\nf\n\n\n\nd-&gt;f\n\n\n\n\n\n\n\n\nFigura¬†3.6: √Årbol con aristas dirigidas, note que es f√°cil saber si hay un v√©rtice o nodo que se distinga como ra√≠z, o nodos que sean hojas.\n\n\n\n\n\nAl igual que en los grafos m√°s generales, en los √°rboles es √∫til definir funciones sobre v√©rtices y aristas, as√≠ como marcar tipos de v√©rtices, e.g., posici√≥n u color, que simplifiquen el razonamiento para con los algoritmos asociados.\nLos nodos y las aristas de un grafo pueden recorrerse de diferentes maneras, donde se aprovechan las relaciones representadas. En un grafo general podr√≠a ser importante solo visitar una vez cada v√©rtice, o guiarse en el recorrido por alguna heur√≠stica o funci√≥n asociada a v√©rtices o aristas.\nEl recorrido primero a lo profundo, Depth First Search (DFS), comienza en un nodo dado y de manera voraz avanzar√° recordando orden de visita y avanzando al ver un nuevo nodo repitiendo el procedimiento hasta que todos los v√©rtices alcanzables sean visitados. El siguiente pseudo-c√≥digo lo implementa:\n#| lst-label: lst-dfs\n#| lst-cap: Psudo-c√≥digo DFS\n\nfunction operaci√≥n!(v√©rtice)\n  #... operaciones sobre el v√©rtice siendo visitado ...\nend\n\nfunction DFS(grafo, v√©rtice, visitados)\n  operaci√≥n!(v√©rtice)\n  push!(visitados, v√©rtice)\n  for v in neighbors(grafo, v√©rtice)\n    if v ‚àâ visitados\n      operaci√≥n!(v)\n      push!(visitados, v)\n      DFS(grafo, v, visitados)\n    end\n  end\nend\n\n# ... c√≥digo de preparaci√≥n del grafo\nvisitados = Set()\nDFS((v√©rtices, aristas), v√©rticeinicial, visitados)\n# ... c√≥digo posterior a la visita DFS\nLas llamadas recursivas a DFS tienen el efecto de memorizar el orden de visita anterior y recordarlo cuando se sale de una visita anidada. Entonces, hay una memoria implicita utilizada, implementanda por el stack de llamadas. La funci√≥n operaci√≥n! es una abstracci√≥n de cualquier cosa que deba hacerse sobre los nodos siendo visitados.\nEl recorrido a lo ancho, Breadth First Search (BSF), visita los v√©rtices locales primero que los alejados contrar√≠o al avance voraz utilizado por DFS.\n#| lst-label: lst-bfs\n#| lst-cap: Psudo-c√≥digo BFS\n\nfunction BFS(grafo, v√©rtice, visitados, cola)\n  operaci√≥n!(v√©rtice)\n  push!(visitados, v√©rtice)\n  push!(cola, v√©rtice)\n\n  while length(cola) &gt; 0\n    u = popfirst!(cola)\n    for v in neighbors(grafo, u)\n      if v ‚àâ visitados\n        operaci√≥n!(v)\n        push!(visitados, v)\n        push!(cola, v)\n      end\n    end\n  end\nend\n\n# ... c√≥digo de preparaci√≥n del grafo\nvisitados = Set()\nBFS((v√©rtices, aristas), v√©rticeinicial, visitados)\n# ... c√≥digo posterior a la visita BFS\nEl BFS hace uso expl√≠cito de la memoria para guardar el orden en que se visitar√°n los v√©rtices (cola); se utiliza un conjunto para marcar v√©rtices ya visitados (visitados) con la finalidad de evitar un recorrido infinito.\n\n3.5.1.1 Ejercicios\n\nImplemente un grafo dirigido mediante listas de adyacencia.\nImplemente un grafo no dirigido mediante lista de adyacencia.\nImplemente el algoritmo de recorrido DFS y BFS con implementaciones de grafos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#actividades",
    "href": "cap3-estructuras.html#actividades",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.6 Actividades",
    "text": "3.6 Actividades\nImplementar los siguientes algoritmos sobre matrices. - Multiplicaci√≥n de matrices - Eliminaci√≥n gaussiana / Gauss-Jordan Compare los desempe√±os de ambos algoritmos contando el n√∫mero de operaciones y el tiempo real para matrices aleatorias de tama√±o ( n n ) para ( n= 100, 300, 1000). Maneje de manera separada los datos de conteo de operaciones (multiplicaciones y sumas escalares) y las de tiempo real. Discuta sus resultados experimentales; ¬øqu√© puede concluir? ¬øCu√°l es el impacto de acceder los elementos contiguos en memoria de una matriz? ¬øQu√© cambiar√≠a si utiliza matrices dispersas? ¬øCu√°les ser√≠an los costos?\nEntregable\nSu trabajo se entregar√° en PDF y con el notebook fuente; deber√° estar plenamente documentado, con una estructura que permita a un lector interesado entender el problema, sus experimentos y metodolog√≠a, as√≠ como sus conclusiones. Tenga en cuenta que los notebooks pueden alternar celdas de texto y c√≥digo.\nNo olvide estructurar su reporte, en particular el reporte debe cubrir los siguientes puntos:\n\nT√≠tulo del reporte, su nombre.\nIntroducci√≥n.\nC√≥digo cercano a la presentaci√≥n de resultados.\nFiguras y tablas\nAn√°lisis de los resultados\nConclusi√≥n, discusiones de las preguntas\nLista de referencias. Nota, una lista de referencias que no fueron utilizadas en el cuerpo del texto ser√° interpretada como una lista vac√≠a.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap3-estructuras.html#bibliograf√≠a",
    "href": "cap3-estructuras.html#bibliograf√≠a",
    "title": "3¬† Estructuras de datos elementales",
    "section": "3.7 Bibliograf√≠a",
    "text": "3.7 Bibliograf√≠a\nCormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2022). Introduction to Algorithms (2nd ed.). MIT Press.\n\nParte III: Cap 10 Elementary Data Structures.\nParte VI: Cap 22 Elementary Graph Algorithms.\nParte VII: Cap 28 Matrix Operations.\n\n\n\n\n\n\n\nScott, Jennifer, y Miroslav T≈Øma. 2023. ‚ÄúAn Introduction to Sparse Matrices‚Äù. En Algorithms for Sparse Linear Systems, 1‚Äì18. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-25820-6_1.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estructuras de datos elementales</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html",
    "href": "cap4-ordenamiento.html",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "",
    "text": "Objetivo\nImplementar y analizar algoritmos de ordenamiento de arreglos con costo √≥ptimo en el peor caso, as√≠ como algoritmos adaptativos a la entrada para caracterizar su desempe√±o bajo un enfoque experimental para la soluci√≥n efectiva de problemas inform√°ticos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#introducci√≥n",
    "href": "cap4-ordenamiento.html#introducci√≥n",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.1 Introducci√≥n",
    "text": "4.1 Introducci√≥n\nEn este tema se aborda el ordenamiento basado en comparaci√≥n, esto es, existe un operador \\(&lt;\\) que es capaz de distinguir si un elemento \\(a\\) es menor que un elemento \\(b\\).\nEl operador cumple con las siguientes propiedades:\n\nsi \\(a &lt; b\\) y \\(b &lt; c\\) entonces \\(a &lt; c\\) (transitividad); e.g., \\(1 &lt; 10\\) y \\(10 &lt; 100\\) entonces \\(1 &lt; 100\\).\ntricotom√≠a:\n\nsi \\(a &lt; b\\) es falso y \\(b &lt; a\\) es falso, entonces \\(a = b\\) (antis√≠metria); dicho de otras formas:\n\nsi \\(a\\) no es menor que \\(b\\) ni \\(b\\) menor que \\(a\\) entonces \\(a\\) es igual a \\(b\\),\ndesvelando variables, \\(1 &lt; 1\\) es falso, el intercambio es obvio, entonces \\(1=1\\).\n\nen otro caso, \\(a &lt; b\\) o \\(a &lt; b\\).\n\n\n\n\nUsar un operador como \\(&lt;\\) es suficiente para crear algoritmos correctos y eficientes, sin embargo, en la pr√°ctica y en una computadora real, tambi√©n es v√°lido utilizar operadores como \\(=\\) o \\(\\leq\\), o intercambiar por \\(&gt;\\) y \\(\\geq\\) seg√∫n convenga. No hay impacto en la eficiencia.\nSin perdida de generalidad, podemos planter el problema de ordenamiento sin permitir repeticiones como sigue: dado un arreglo \\(A[1, n] = a_1, a_2, \\cdots, a_n\\); un algoritmo de ordenamiento obtiene la permutaci√≥n \\(\\pi\\) tal que \\(a_{\\pi(1)} &lt; a_{\\pi(2)} &lt; \\cdots &lt; a_{\\pi(n)}\\).\n\n\nCuando se permiten elementos repetidos, se le llama ordenamiento estable i se asegura que en el arreglo ordenado se preserven el orden original posicional cuando \\(a = b\\). Esta propiedad es importante cuando hay datos sat√©litales asociados a la llave de comparaci√≥n.\nEn t√©rminos pr√°cticos, la idea es reorganizar \\(A\\), mediante el c√°lculo implicito de la permutaci√≥n \\(\\pi\\), de tal forma que despu√©s de terminar el proceso de ordenamiento se obtenga que \\(A\\) esta ordenado, i.e., \\(a_i \\leq a_{i+1}\\). En sistemas reales, el alojar memoria para realizar el ordenamiento implica costos adicionales, y es por esto muchas veces se busca modificar directamente \\(A\\).\n\n\nUtilizar \\(\\pi\\) solo es necesario cuando no es posible modificar \\(A\\). Tambi√©n es muy com√∫n utilizar datos sat√©lite asociados con los valores a comparar, de esta manera es posible ordenar diversos tipos de datos. Un ejemplo de esto es ordenar un dataframe, pero tambi√©n estructuras de datos donde existe un campo especial y el resto de los datos asociados es de importancia para una aplicaci√≥n.\n\n4.1.1 Costo del problema\nPara una entrada de tama√±o \\(n\\) existen \\(n!\\) permutaciones posibles; cada una de estas permutaciones es una instancia del problema de ordenamiento de tama√±o \\(n\\).\nExiste una permutaci√≥n objetivo \\(\\pi^*\\), i.e., que cumple con la definici√≥n de que esta ordenada; ahora pensemos en un grafo donde cada \\(\\pi_i\\) esta conectada con todas las permutaciones en las que se puede transformar haciendo una √∫nica operaci√≥n, e.g., intercambiando un elemento. El algoritmo forma ese grafo con sus posibles decisiones, por lo que el camino m√°s largo i.e., ruta sin ciclos, entre cualquier \\(\\pi_i\\) y la permutaci√≥n \\(\\pi^*\\) es el costo de peor caso del algoritmo.\nAhora, cada operaci√≥n que realicemos en un algoritmo nos acercar√° m√°s a \\(\\pi^*\\), descartando una cierta cantidad de instancias posibles pero no viables; si nuestra funci√≥n de transici√≥n en el grafo viene dada con respecto a colocar cada par de elementos en su orden relativo, entonces, la mitad de las permutaciones se han descartado, ya que ese par no puede estar en el orden contrario. Por tanto, el costo de cualquier algoritmo que realice comparaciones y descarte la mitad del espacio de b√∫squeda, es \\(\\log_2(n!)\\), que usando la aproximaci√≥n de Stirling,1 lo podemos reescribir como sigue:\n\\[\\log_2(n!) = n \\log_2 n - n \\log_2 e + O(\\log_2 n)\\]\nEsto se puede simplemente escribir como \\(O(n \\log n)\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#algoritmos-de-ordenamiento",
    "href": "cap4-ordenamiento.html#algoritmos-de-ordenamiento",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.2 Algoritmos de ordenamiento",
    "text": "4.2 Algoritmos de ordenamiento\nExisten muchos algoritmos que pueden resolver el problema de ordenamiento, es com√∫n contar el n√∫mero de comparaciones ya que produce la informaci√≥n necesaria para la navegaci√≥n en el grafo de instancias; tambi√©n es com√∫n contar las operaci√≥n de intercambiar elementos. Las pruebas y la navegaci√≥n en el grafo determina el costo del algoritmo. Es necesario mencionar que mover datos entre diferentes zonas de memoria puede llegar a ser m√°s costoso que solo acceder a esas zonas por lo que hay una asimetr√≠a en el costo de estas dos operaciones.\nNote que algunos de los algoritmos m√°s simples pueden tener un comportamiento oportunistas y que son capaces de obtener ventaja en instancias sencillas, por lo que no deber√≠a saltarse esas secciones si solo conoce su comportamiento en peor caso.\n\n4.2.1 Bubble sort\nEl algoritmo de ordenamiento de burbuja o bubble sort realiza una gran cantidad de comparaciones, como puede verse en Listado¬†4.1, el algoritmo usa dos ciclos anidados para realizar una comparaci√≥n y una posible transposici√≥n, formando un tri√°ngulo, i.e., \\[ \\sum_{i=1}^{n-1} \\sum_{j=1}^{n-i} O(1);\\] por lo tanto su costo esta dominado por el triangulo formado, i.e., \\(\\sim n^2/2\\) lo que puede escribirse simplemente como \\(O(n^2)\\).\n\n\n\n\nListado¬†4.1: Bubble sort de peor caso\n\n\nfunction bubble_sort!(A)\n  n = length(A)\n  for i in 1:n-1\n    for j in 1:n-i\n      if A[j] &gt; A[j+1]\n        A[j], A[j+1] = A[j+1], A[j]\n      end\n    end\n  end\n  \n  A\nend\n\nbubble_sort!([8, 4, 3, 1, 6, 5, 2, 7])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nCiclo que recorre \\(n-1\\) veces todo el arreglo; y pone el elemento m√°ximo en su posici√≥n final.\nCiclo que recorre \\(n-i\\) veces el arreglo; ya que en cada corrida se pone el m√°ximo en su posici√≥n.\nIntercambio cuando hay pares en desorden.\n\nEl algoritmo mostrado en Listado¬†4.1 es un algoritmo de peor caso, ya que sin importar la complejidad de la instancia (i.e., que tal alejada esta \\(\\pi_i\\) de \\(\\pi^*\\)), se comporta igual.\nEs relativamente f√°cil hacer un bubble sort que tenga en cuenta la complejidad de la instancia, medida como el n√∫mero de intercambios necesarios.\n\n\n\n\nListado¬†4.2: Bubble sort adaptable\n\n\nfunction adaptive_bubble_sort!(A)\n  n = length(A)\n\n  for i in 1:n-1     \n    s = 0            \n    for j in 1:n-i\n      if A[j] &gt; A[j+1]\n        s += 1\n        A[j], A[j+1] = A[j+1], A[j] \n      end\n    end\n    s == 0 && break\n  end\n  \n  A\nend\n\nadaptive_bubble_sort!([7, 8, 4, 3, 1, 6, 5, 2])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nLa idea es que si no hay intercambios en una iteraci√≥n, entonces el arreglo ya esta ordenado.\nContador de intercambios.\nCondici√≥n de paro, i.e., no hubo intercambios.\n\nEn la forma Listado¬†4.2, bubble sort es capaz de t√©rminar en \\(n-1\\) comparaciones si el arreglo esta ordenado; sacando provecho de casos simples en t√©rminos de instancias casi ordenadas.\n\n\n4.2.2 Insertion sort\nEl algoritmo de ordenamiento por inserci√≥n o insertion sort es un algoritmo simple que al igual que bubble sort tiene un mal peor caso y puede aprovechar casos simples\n\n\n\n\nListado¬†4.3: Algoritmo insertion sort\n\n\nfunction insertion_sort!(A)\n  n = length(A)\n  for i in 2:n\n    key = A[i]\n    j = i - 1   \n    while j &gt;= 1 && A[j] &gt; key\n      A[j + 1] = A[j]\n      j -= 1\n    end\n\n    A[j + 1] = key\n  end\n  \n  A\nend\n\ninsertion_sort!([5, 1, 4, 8, 2, 6, 3, 7])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nEl algoritmo comienza en la segunda posici√≥n del arreglo y revisar√° todos los elementos.\nEs importante hacer una copia de key para simplificar la implementaci√≥n.\nLa idea general es ordenar las posiciones de \\(1..i\\), para esto se debe recorrer hacia atr√°s el arreglo completo, para determinar la posici√≥n de inserci√≥n de key.\nIntercambio de elementos para colocar key en su lugar ordenado.\nkey se pone en su lugar final.\n\nPara analizar Listado¬†4.3, es importante notar que el ciclo m√°s externo termina con el subarreglo \\(A[1..i]\\) ordenado; por lo que cuando se comienza el ciclo, si key se prueba estar en su posici√≥n correcta, entonces ya no es necesario revisar el resto del subarreglo, esto determina que un arreglo ordenado tendr√° un costo de \\(O(n)\\) comparaciones; si esta casi ordenado en t√©rminos del n√∫mero de intercambios necesarios, entonces, el algoritmo se adaptar√° sacando provecho de la instancia.\nEn el peor caso de insertion sort, el algoritmo no puede parar de manera prematura, e.g., un arreglo en orden reverso, el ciclo for se ejecutara \\(n-1\\) veces, mientras que el ciclo while deber√° revisar el subarreglo completo en cada iteraci√≥n, sumando un costo de \\(i\\) operaciones en cada iteraci√≥n, i.e., \\(\\sum_{i=1}^n i\\), esta forma produce un tri√°ngulo, resultando en un costo \\(O(n^2)\\).\n\n\n4.2.3 Quick sort\nQuick sort (ver Cormen et¬†al. 2022, cap. 7) es un algoritmo tipo dividir para vencer; esto es, un algoritmo que divide un problema grande en instancias peque√±as m√°s sencillas. Es uno de los algoritmos m√°s veloces en la pr√°ctica por su buen manejo de memoria, aun cuando tiene un peor caso cuadr√°tico, en promedio el costo es \\(O(n \\log n)\\).\n\n\n\n\nListado¬†4.4: Algoritmo quick sort.\n\n\nusing Random\n\nfunction qsort!(A, low=1, high=length(A))\n  if low &lt; high\n      piv = part!(A, low, high)\n      qsort!(A, low, piv - 1)\n      qsort!(A, piv + 1, high)\n  end\n  \n  A\nend\n\nfunction part!(A, low, high)\n  ipiv = rand(low:high)\n  A[ipiv], A[high] = A[high], A[ipiv]\n  piv = A[high]\n\n  i = low - 1  # uno antes porque se accede despu√©s de un i+1\n  for j in low:high - 1\n      if A[j] &lt; piv\n          i += 1\n          A[i], A[j] = A[j], A[i]\n      end\n  end\n  \n  ipiv = i + 1\n  A[ipiv], A[high] = A[high], A[ipiv]\n  ipiv\nend\n\nqsort!([6, 8, 3, 7, 4, 1, 2, 5])\n\n\n\n\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n\n\n\nEl arreglo se divide en 3 partes, ordenadas entre s√≠, un subarreglo izquierdo, un pivote, y un subarreglo derecho; los subarreglos no estan ordenados localmente, pero el pivote esta en su posici√≥n final.\nSe resuelve el problema izquierdo y el problema derecho por separado.\nLa funci√≥n part! particiona el arreglo \\(A[low:end]\\) en 3 partes como se espec√≠fico en el punto 1; para eso selecciona de manera aleatoria un pivote. Lo ponemos al final del arreglo para simplificar el c√≥digo siguiente.\nEste ciclo itera por todo el subarreglo, su objetivo es asegurar que \\(A[i] &lt; piv\\) para todo \\(i \\in low:piv-1\\) y \\(piv &lt; A[i]\\) para todo \\(i \\in piv+1:high\\).\nIntercambia elementos si \\(A[j] &lt; piv\\), hacemos seguimiento de \\(i\\) ya que esta posici√≥n determinar√° al pivote.\nComo piv se encontraba en high, entonces hay que intercambiarlos para que qsort! sepa como manejarlos; recordando que los subarreglos no estan ordenados dentro de s√≠.\n\nEl c√≥digo Listado¬†4.4 es relativamente simple, usa recurrencias sobre qsort! sobre dos partes extremas divididas por un pivote; estos tres elementos son encontrados en part!. La funci√≥n part! es muy eficiente en t√©rminos de memoria, lo que puede hacer la diferencia en la pr√°ctica. La correcta selecci√≥n del pivote es muy importante para evitar casos malos, i.e., costo cuadr√°tico; en esta implementaci√≥n se realiza una selecci√≥n aleator√≠a de pivote que funcionar√° en la mayor√≠a de los casos.\nEl peor de los casos en qsort! es debido a una mala selecci√≥n del pivote, de tal forma que \\[|A[low:piv-1]| \\ll |A[piv+1:high]|,\\] o lo contrario en toda selecci√≥n, en el extremo una de los subarreglos puede verse como de tama√±o constante o cero, i.e., selecci√≥n de pivote como el minimo o el m√°ximo. Esta estrateg√≠a reduce a qsort! a un costo \\(O(n^2)\\).\nSi se realiza un particionado donde \\[|A[low:piv-1]| \\approx |A[piv+1:high]|,\\] entonces tenemos un algoritmo \\(O(n \\log n)\\); ya que hace una divisi√≥n en dos partes casi iguales en cada recurrencia a qsort!, y esto solo puede profundizar a \\(\\log n\\) veces, y en cada nivel part! tiene un costo lineal.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#skip-list",
    "href": "cap4-ordenamiento.html#skip-list",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.3 Skip list",
    "text": "4.3 Skip list\nUna skip list (Pugh 1990) es una lista ligada con capacidades de b√∫squeda eficiente con garant√≠as probabil√≠sticas, esto es que se cumplen con alta probabilidad. Para esto, la idea es que cada dato tiene asociado un arreglo de punteros o referencias hacia nodos sucesores, i.e., los nodos a nivel \\(i\\) se conectan con el siguiente nodo a nivel \\(i\\). En el nivel m√°s bajo, la skip list es una simple lista ligada, mientras que sube, se vuelve m√°s dispersa dando saltos m√°s largos.\n\n\n\n\n\n\n\n\nlista\n\n\n\nhead\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\n(head)\n\n\n\na\n\n(2)\n\n(1)\n\na\n\n\n\nhead:1-&gt;a:1\n\n\n\n\n\nhead:2-&gt;a:2\n\n\n\n\n\n\ne\n\n(3)\n\n(2)\n\n(1)\n\ne\n\n\n\nhead:3-&gt;e:3\n\n\n\n\n\nh\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\nh\n\n\n\nhead:e-&gt;h:w\n\n\n\n\n\nb\n\n(1)\n\nb\n\n\n\na:1-&gt;b:1\n\n\n\n\n\n\nc\n\n(2)\n\n(1)\n\nc\n\n\n\na:2-&gt;c:2\n\n\n\n\n\nb:1-&gt;c:1\n\n\n\n\n\n\nd\n\n(1)\n\nd\n\n\n\nc:1-&gt;d:1\n\n\n\n\n\n\nc:2-&gt;e:2\n\n\n\n\n\nd:1-&gt;e:1\n\n\n\n\n\n\nf\n\n(1)\n\nf\n\n\n\ne:1-&gt;f:1\n\n\n\n\n\n\ng\n\n(2)\n\n(1)\n\ng\n\n\n\ne:2-&gt;g:2\n\n\n\n\n\ne:3-&gt;h:3\n\n\n\n\n\nf:1-&gt;g:1\n\n\n\n\n\n\ng:1-&gt;h:1\n\n\n\n\n\ng:2-&gt;h:2\n\n\n\n\n\n\ni\n\n(1)\n\ni\n\n\n\nh:1-&gt;i:1\n\n\n\n\n\n\nj\n\n(3)\n\n(2)\n\n(1)\n\nj\n\n\n\nh:2-&gt;j:2\n\n\n\n\n\nh:3-&gt;j:3\n\n\n\n\n\ntail\n\n(4)\n\n(3)\n\n(2)\n\n(1)\n\n(tail)\n\n\n\nh:e-&gt;tail:w\n\n\n\n\n\ni:1-&gt;j:1\n\n\n\n\n\n\nj:1-&gt;tail:1\n\n\n\n\n\nj:2-&gt;tail:2\n\n\n\n\n\nj:3-&gt;tail:3\n\n\n\n\n\n\n\n\n\nFigura¬†4.1: Ejemplo de una skip list\n\n\n\n\n\nA diferencia de los algoritmos vistos anteriormente, en este caso, ya se tiene una estructura de datos, que conlleva un costo en memor√≠a expl√≠cito por nodo. Figura¬†4.1 ilustra la estructura.\nLa altura de cada nodo es calculada de manera probabil√≠stica, dada la probababilidad \\(p\\). Un valor com√∫n de \\(p=0.5\\). La altura de cada nodo se calcula como sigue:\n\nfunction levels(p)\n  i = 1\n  while rand() &lt; p\n    i += 1\n  end\n\n  i\nend\n\nlevels (generic function with 1 method)\n\n\nSi tenemos \\(n\\) evaluaciones de levels, Los niveles peque√±os son relativamente probables, mientras que niveles grandes son relativamente poco probables. De hecho, los niveles \\(\\log_{1/p} n\\) son cercanos a una constante, \\(\\log_{1/p}{n} - 1\\) son \\(1/p\\) veces la constante, \\(\\log_{1/p}{n} - 2\\) son \\(1/p^2\\) veces la constante, etc.\nA diferencia de los algoritmos anteriores, una skip list comienza vacia, y se va poblando insertando elementos a la lista. Se va colocando en la posici√≥n que no viola el orden; generando el nodo correspondiente con nivel calculado. Los nodos especiales head y tail siempre tienen el nivel m√°ximo posible. La inserci√≥n de un valor encapsulado en el nodo \\(u\\) comienza por visitar el m√°ximo nivel en head e ir bajando hasta determinar \\(u.dato &gt; head[level].dato\\); en ese momento se debe avanzar al nodo apuntado por \\(head[level]\\) y repetir el algoritmo hasta que \\(level=1\\), en cuyo caso encontramos el lugar de inserci√≥n del nuevo dato. Se procede a reasignar los punteros de los sucesores y ajustar los punteros hacia los nodos sucesores a los niveles que tiene \\(u\\).\nCada inserci√≥n tiene un costo \\(O(\\log_{1/p} n)\\), garant√≠a probabil√≠stica; por lo que insertar \\(n\\) elementos tiene un costo: \\[ \\sum_{i=1}^n O(\\log_{1/p} i) = O(\\log_{1/p} \\prod_{i=1}^n i) = O(\\log_{1/p} {n!}) = O(n \\log n); \\] usando la aproximaci√≥n de Stirling.\nA diferencia de la versi√≥n basada en arreglos, una skip list es capaz de aceptar nuevos elementos y mantener el orden de manera eficiente.\n\n4.3.1 Ejercicios:\n\nInvestigue, implemente y pruebe merge sort. 1.1 ¬øCuales son las ventajas y desventajas de merge sort? 1.2 ¬øPor qu√© merge sort se puede utilizar en algoritmos paralelos y otros pueden tener muchas dificultades? 1.3 ¬øC√≥mo se puede reducir la memoria extra necesaria de merge sort?\nInvestigue, implemente y pruebe heap sort. 2.1 ¬øCuales son las ventajas y desventajas de heap sort?\n¬øCu√°l es el costo en memoria de una skip list?. 3.1 Investigue, implemente y pruebe un skip list.\nInvestigue, implemente y pruebe un √°rbol binario de b√∫squeda.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#lecturas",
    "href": "cap4-ordenamiento.html#lecturas",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.4 Lecturas",
    "text": "4.4 Lecturas\nLas lecturas de este tema corresponden al cap√≠tulo 5 de (Knuth 1998), en espec√≠fico 5.2 Internal sorting. Tambi√©n se recomienda leer y comprender la parte II de (Cormen et¬†al. 2022), que corresponde a Sorting and order statistics, en part√≠cular Cap. 6 y 7, as√≠ como el Cap. 8.1. El art√≠culo de wikipedia https://en.wikipedia.org/wiki/Sorting_algorithm tambi√©n puede ser consultado con la idea de encontrar una explicaci√≥n r√°pida de los algoritmos.\nEn la pr√°ctica, pocos algoritmos son mejores que quicksort. En (Loeser 1974) se detalla una serie de experimentos donde se compara quicksort contra otros algoritmos relacionados; por lo que es una lectura recomendable.\nLa parte adaptable, esto es para algoritmos oportunistas que toman ventaja de instancias simples, esta cubierta por el art√≠culo (Estivill-Castro y Wood 1992). En especial, es muy necesario comprender las secciones 1.1 y 1.2, el resto del art√≠culo debe ser le√≠do aunque no invierta mucho tiempo en comprender las pruebas expuestas si no le son claras. En especial, en las secciones indicadas se establecen las medidas de desorden contra las cuales se mide la complejidad. En (Cook y Kim 1980) realiza una comparaci√≥n del desempe√±o de varios algoritmos para ordenamiento de listas casi ordenadas, esto es, en cierto sentido donde los algoritmos adaptables tienen sentido. Este art√≠culo es anterior a (Estivill-Castro y Wood 1992) pero tiene experimentos que simplifican el entendimiento de los temas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#material-audio-visual-sobre-algoritmos-de-ordenamiento",
    "href": "cap4-ordenamiento.html#material-audio-visual-sobre-algoritmos-de-ordenamiento",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "4.5 Material audio-visual sobre algoritmos de ordenamiento",
    "text": "4.5 Material audio-visual sobre algoritmos de ordenamiento\n\n\n\n\n\n\n\n\nCook, Curtis R, y Do Jin Kim. 1980. ‚ÄúBest sorting algorithm for nearly sorted lists‚Äù. Communications of the ACM 23 (11): 620‚Äì24.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, y Clifford Stein. 2022. Introduction to algorithms. MIT press.\n\n\nEstivill-Castro, Vladmir, y Derick Wood. 1992. ‚ÄúA survey of adaptive sorting algorithms‚Äù. ACM Computing Surveys (CSUR) 24 (4): 441‚Äì76.\n\n\nKnuth, Donald. 1998. The Art Of Computer Programming, vol. 3 (2nd ed): Sorting And Searching. Vol. 3. Redwood City, CA, USA.: Addison Wesley Longman Publishing Co. Inc.\n\n\nLoeser, Rudolf. 1974. ‚ÄúSome performance tests of ‚Äòquicksort‚Äô and descendants‚Äù. Communications of the ACM 17 (3): 143‚Äì52.\n\n\nPugh, William. 1990. ‚ÄúSkip lists: a probabilistic alternative to balanced trees‚Äù. Commun. ACM 33 (6): 668‚Äì76. https://doi.org/10.1145/78973.78977.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap4-ordenamiento.html#footnotes",
    "href": "cap4-ordenamiento.html#footnotes",
    "title": "4¬† Algoritmos de ordenamiento",
    "section": "",
    "text": "Aproximaci√≥n de Stirling https://en.wikipedia.org/wiki/Stirling%27s_approximation.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Algoritmos de ordenamiento</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html",
    "href": "cap5-busqueda.html",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "",
    "text": "Objetivo\nAnalizar algoritmos de b√∫squeda en arreglos ordenados basados en funciones de comparaci√≥n, con el objetivo de localizar elementos y posiciones espec√≠ficas, usando t√©cnicas de peor caso y adaptables a la distribuci√≥n de los datos para una soluci√≥n eficiente de problemas inform√°ticos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#problema",
    "href": "cap5-busqueda.html#problema",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "5.1 Problema",
    "text": "5.1 Problema\nSea \\(A[1..n] = a_1, \\cdots, a_n\\) un arreglo ordenado con \\(n \\geq 1\\) y un operador \\(&lt;\\) (menor que); por simplicidad, tambi√©n usaremos \\(\\leq\\) (menor o igual que). Supondremos que no hay elementos duplicados en \\(A\\), note que esto no implica una perdida de generalidad.\nLa tarea ser√°: dado el valor \\(x\\) a ser localizado en \\(A\\), el problema consiste en determinar la posici√≥n de inserci√≥n \\(p\\) tal que suceda alguna de las siguientes condiciones:\n\nsi \\(p = 1\\) entonces \\(x \\leq A[p]\\).\nsi \\(2 \\leq p \\leq n\\) entonces \\(A[p-1] &lt; x \\leq A[p]\\).\nsi \\(p=n+1\\) entonces \\(A[n] &lt; x\\).\n\n\n5.1.1 Costo de peor caso\nPara \\(A[1..n]\\) y el valor \\(x\\) a localizar su posici√≥n de inserci√≥n, el resultado puede ser cualquiera de las \\(n+1\\) posiciones posibles, i.e., instancias del problema. Un algoritmo na√Øve utilizar√≠a \\(n\\) comparaciones para resolverlo.\n\n\"\"\"\n    seqsearch(A, x, sp=1)\n\nB√∫squeda exhaustiva con inicio\n\"\"\"\nfunction seqsearch(A, x, sp=1)\n    n = length(A)\n    while sp &lt;= n && x &gt; A[sp]\n        sp += 1\n    end\n    \n    sp\nend\n\nlet S=[10, 20, 30, 40, 50, 60, 70]\n    (seqsearch(S, 0), seqsearch(S, 69), seqsearch(S, 70), seqsearch(S, 71))\nend\n\n(1, 7, 7, 8)\n\n\nSin embargo, dado que el arreglo esta ordenado y no hay duplicados, se puede mejorar mucho el tiempo de b√∫squeda.\n\n\nSi se permiten duplicados se pueden mejorar muchos los tiempos; sobre todo si podemos preprocesar el arreglo, i.e., para determinar las zonas con duplicados.\nEl costo de b√∫squeda para cualquier instancia es \\(O(\\log n)\\), y viene de la b√∫squeda binaria:\n\n\"\"\"\n    binarysearch(A, x, sp=1, ep=length(A))\n\nEncuentra la posici√≥n de inserci√≥n de `x` en `A` en el rango `sp:ep`\n\"\"\"\nfunction binarysearch(A, x, sp=1, ep=length(A))\n3    while sp &lt; ep\n1        mid = div(sp + ep, 2)\n        if x &lt;= A[mid]\n2            ep = mid\n        else\n            sp = mid + 1\n        end\n    end\n    \n4    x &lt;= A[sp] ? sp : sp + 1\nend\n\nlet S=[10, 20, 30, 40, 50, 60, 70]\n    (binarysearch(S, 0), binarysearch(S, 69), binarysearch(S, 70), binarysearch(S, 71))\nend\n\n\n1\n\nPara el rango de b√∫squeda \\(sp:ep\\) se determina su punto central \\(mid\\) y se compara con \\(x\\),\n\n2\n\nSi el elemento \\(x\\) esta a la izquierda, se ajusta el limite superior \\(ep,\\) o de lo contrario se ajusta \\(sp\\). Ambos ajustes se hacen tomando en cuenta la posici√≥n comparada.\n\n3\n\nSe itera mientras no se junten los dos extremos del rango.\n\n4\n\nFinalmente, se ajusta para valores fuera del rango.\n\n\n\n\n(1, 7, 7, 8)\n\n\nEste algoritmo es simple y efectivo, y es capaz de resolver cualquier instancia en tiempo logar√≠tmico, y esto lo hace al dividir el rango siempre a la mitad por cada iteraci√≥n. El costo de b√∫squeda binaria es de \\(C_\\text{bin}(n) = \\lfloor \\log n \\rfloor + O(1)\\) comparaciones antes de colapsar el rango donde puede estar la posici√≥n de inserci√≥n.\nEs importante hacer notar que la b√∫squeda binaria es muy eficiente en memor√≠a y tiene un peor caso √≥ptimo, ya que es id√©ntico al costo del problema, i.e., as√≠ lo determinamos. Si fuera posible tener probar varios puntos, i.e., \\(m\\) segmentos en una sola operaci√≥n, el costo estar√≠a acotado en \\(\\lceil \\log_{m} n \\rceil\\). Esto tiene sentido para estructuras de datos que trabajan en diferentes niveles de memor√≠a, donde aunque las comparaciones en hardware moderno sean binarias, la diferencia entre velocidades de los diferentes niveles de memoria se puede pensar que el costo dominante es, por ejemplo, acceder a una zona de disco y obtener una decisi√≥n entre \\(m-1\\) posibles, que particionan los rangos en \\(m\\) divisiones.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#b√∫squeda-no-acotada",
    "href": "cap5-busqueda.html#b√∫squeda-no-acotada",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "5.2 B√∫squeda no acotada",
    "text": "5.2 B√∫squeda no acotada\nCuando el tama√±o del arreglo es demasiado grande, o la relaci√≥n entre \\(p / n\\) es significativamente peque√±a, la b√∫squeda acotada no es la mejor opci√≥n. Aun cuando en la pr√°ctica el l√≠mite superior \\(n\\) podr√≠a estar determinado, y por lo tanto, se pueden resolver b√∫squedas en \\(O(\\log n)\\), es posible obtener una cota relativa a \\(p\\), independiente de \\(n\\), por lo que los casos de inter√©s se ver√°n beneficiados.\nUna estrategia simple y poderosa es la siguiente:\n\nDeterminar un buen rango que contenga la respuesta.\nAplicar b√∫squeda binaria en ese rango para obtener la respuesta.\n\nBentley y Yao (1976) describen a detalle una familia de algoritmos cas√≠ √≥ptimos para la b√∫squeda no acotada siguiendo la estrateg√≠a anteriormente mencionada. En particular, poniendo un enf√°sis importante en la determinaci√≥n del rango. Lo consigue mediante la definici√≥n de algoritmos definidos de manera interesante como sigue en el resto de la secci√≥n.\n\n5.2.1 Algoritmo \\(B_0\\) (b√∫squeda unar√≠a)\nEs el algoritmo m√°s simple, y ya lo vimos con anterioridad, realiza una b√∫squeda exhaustiva de la posici√≥n de inserci√≥n, hacendo pruebas para toda posici√≥n \\(x \\leq A[1], x \\leq A[2], \\cdots, x \\leq A[p+1]\\), por lo que su costo ser√° de \\(p+1\\).\nSea \\(F_0(n)\\) una secuencia de puntos para un arreglo de longitud \\(n\\), donde se har√°n comparaciones para determinar el rango que contenga la respuesta para el algoritmo \\(B_0\\) y \\(C_0(p)\\) el costo de b√∫squeda. Entonces:\n\n\\(F_0(n) = 1, 2, \\cdots, n, n+1\\).\n\\(C_0(p) = p+1\\); no requiere b√∫squeda binaria.\n\n\n\n5.2.2 Algoritmo \\(B_1\\) (b√∫squeda doblada: doubling search/galloping)\nConsiste en comparar las posiciones \\(2^i\\), i.e., \\(2^1, 2^2, 2^3, \\cdots, 2^{\\lfloor \\log_2{p+1} \\rfloor + 1}\\), tal que \\(A[2^{\\lfloor\\log_2{p}\\rfloor+1}] \\leq  x \\leq A[2^{\\lfloor\\log_2{p+1}\\rfloor+1}]\\). De manera similar que para \\(B_0\\) definimos \\(F_1(n)\\) y \\(C_1\\):\n\n\\(F_1(n) = 2^1, 2^2, \\cdots, 2^{\\log \\lfloor n \\rfloor + 1};\\)\n\\(C_1(p) = C_\\text{bin}{(2^{\\log_2{p+1}})} + \\log_2{(p+1)} + 1 &lt; 2\\log_2 p + O(1).\\)\n\nLa explicaci√≥n viene a continuaci√≥n. El n√∫mero de comparaciones para determinar el rango esta determinado por \\(\\lfloor \\log_2{p+1} \\rfloor + 1\\). Una vez determinado el rango la b√∫squeda binaria sobre \\[A[2^{\\lfloor\\log_2{p}\\rfloor+1}:2^{\\lfloor\\log_2{(p+1)}\\rfloor+1}],\\] lo cual corresponde a \\(\\log_2 2^{\\log{(p+1)}+1}/2 = \\log_2{(p+1)}\\). El costo \\(C_1(p)\\) puede ser escrito como \\(2\\log_2 p + O(1)\\), con un poco de manipulaci√≥n algebraica.\nEs importante saber cuando usar un algoritmo u otro, por tanto determinar cuando \\(2\\log_2{p} + O(1) &lt; \\log_2 n + O(1).\\) Para simplificar este an√°lisis ignoraremos algunos detalles de la expresi√≥n: \\[\\begin{align}\n2\\log_2{p} & &lt; \\log_2 n, \\\\\n2^{\\log_2{p^2}} & &lt; 2^{\\log_2 n}, \\\\\np^2              & &lt;  n, \\\\\np               & &lt;  \\sqrt{n}; \\\\\n\\end{align}\\] esto indica que si \\(p\\) es menor a \\(\\sqrt{n}\\) entonces hay una ventaja al usar \\(B_1\\); lo cual nos dice que para posiciones cercanas al inicio el uso de \\(B_1\\) puede llevar a b√∫squedas m√°s veloces. Note que en la pr√°ctica es necesario tener en cuenta la memoria, interesantemente, para \\(p\\) peque√±as es posible que esto beneficie al algoritmo ya que podr√≠a mantener las listas en cache.\nEl siguiente c√≥digo implementa \\(B_1\\)\n\nfunction doublingsearch(A, x, sp=1)\n    n = length(A)\n    p = 0\n    i = 1\n\n1    while sp+i &lt;= n && A[sp+i] &lt; x\n        p = i\n        i += i\n    end\n\n2    binarysearch(A, x, sp + p, min(n, sp+i))\nend\n\nlet S=[10, 20, 30, 40, 50, 60, 70]\n    (doublingsearch(S, 0), doublingsearch(S, 69), doublingsearch(S, 70), doublingsearch(S, 71))\nend\n\n\n1\n\nDeterminaci√≥n del rango.\n\n2\n\nAplicar un algoritmo de b√∫squeda eficiente en el rango que contiene la respuesta.\n\n\n\n\n(1, 7, 7, 8)\n\n\nEs cierto que estos algoritmos son oportunistas, pero hay aplicaciones donde esto realmente sucede. En el peor caso, el costo ser√° apenas dos veces el √≥ptimo.\n\n\n5.2.3 Algoritmo \\(B_2\\) (b√∫squeda doblemente doblada, doubling-doubling search)\nAqu√≠ ser√° m√°s clara la din√°mica. \\(B_2\\) consiste en comparar las posiciones \\(2^{2^i}\\), i.e., \\(2^{4}, 2^{16}, 2^{256}, \\cdots, 2^{2^{\\lfloor \\log_2{\\lfloor\\log_2{p+1}\\rfloor + 1} \\rfloor + 1}}\\), tal que \\[A[2^{2^{\\lfloor\\log_2{\\lfloor\\log_2{p}\\rfloor+1}\\rfloor + 1}}] \\leq  x \\leq A[2^{2^{\\lfloor\\log_2{\\lfloor\\log_2{p+1}\\rfloor+1}\\rfloor + 1}}];\\] La determinaci√≥n de este rango requiere \\(\\lfloor\\log_2{\\lfloor\\log_2{p+1}\\rfloor+1}\\rfloor+1\\) comparaciones; sin embargo, este rango seguramente ser√° muy grande, por el tama√±o de los saltos que se estan dando entre puntos de comparaci√≥n, por lo que no conviene usar busqueda binaria y podemos aplicar \\(B_1\\) para resolver en ese rango acotado.\n\\[\\begin{align}\nF_2(n) &= 2^{2^1}, 2^{2^2}, \\cdots, 2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 n \\rfloor} + 1 \\rfloor + 1}};\\\\\nC_2(p) &= \\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor + 1 + C_1(p') \\\\\n       &&lt; \\log_2 p + 2\\log_2{\\log_2 p} + O(1);\\\\\n\\end{align}\\] donde \\(p' = p - 2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor}}\\), es decir, la posici√≥n de inserci√≥n en el rango ya acotado.\nNote como el t√©rmino de mayor peso es muy similar a \\(B_1\\) pero destaca la inclusi√≥n del t√©rmino \\(\\log\\log\\) que permite adaptarse a \\(p\\) muy grandes con un peque√±o costo adicional, que en t√©rminos pr√°cticos se puede ver como una constante.\nLa idea principal es como sigue: una vez determinado el rango, en lugar de usar b√∫squeda binaria y tener un costo \\(\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor + 1 + C_\\text{bin}(2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor + 1}} - 2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor}})\\) es preferible usar \\(B_1\\) y conseguir un algoritmo que se adapte a la entrada. De manera m√°s precisa, tomar ventaja de \\[C_1(2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor + 1}} - 2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor}}) &lt; C_\\text{bin}(2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor + 1}} - 2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor}})\\] cuando \\[p' &lt; \\sqrt{2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor + 1}} - 2^{2^{\\lfloor \\log_2 {\\lfloor \\log_2 p \\rfloor} + 1 \\rfloor}}}\\].\n\nSimplificando las expresiones, la relaci√≥n que nos describe cuando es mejor usar \\(B_2\\) que la b√∫squeda binaria es como sigue:\n\\[\\begin{align}\n{\\log_2{p}} + 2\\log_2{\\log_2{p}} &&lt; \\log_2 n\\\\\n2^{\\log_2{p} + \\log_2{\\log^2_2{p}}} &&lt; 2^{\\log_2 {n}}\\\\\n2^{\\log_2{(p \\log^2_2{p})}} &&lt; 2^{\\log_2 {n}}\\\\\n2p \\log_2{p} & &lt; n\\\\\np \\log_2{p^2} & &lt; n\\\\\n\\end{align}\\]\nSi \\(p = \\sqrt{n}\\) entonces \\(\\sqrt{n} \\log_2 n\\) claramente es menor que \\(n\\) incluso para valores relativamente peque√±os de \\(n\\), por lo que \\(B_2\\) funciona mejor para \\(p\\) relativamente grandes en comparaci√≥n con \\(B_1\\).\n\n\n5.2.4 Algoritmo \\(B_k\\)\nBentley y Yao (1976) generalizan la estrateg√≠a para cualquier \\(k\\). De manera simplificada:\n\n\\(F_k(n) = 2^{\\cdot^{\\cdot^{\\cdot^{2^i}}}}\\) (exponenciando \\(k\\) veces) para \\(i\\) desde \\(1\\) a \\(\\log_2^{(k)}{n};\\)\n\\(C_k(p) = \\log_2^{(k)}(p) + C_{k-1}(2^{{\\cdot^{\\cdot^{\\cdot^{2^{\\log_2^{(k)}(p)}}}}}} - 2^{{\\cdot^{\\cdot^{\\cdot^{2^{\\log_2^{(k)}(p)-1}}}}}});\\)\n\ndonde \\(\\log_2^{(k)}(n) = \\log_2(\\lfloor \\log_2^{(k-1)}{(n)} \\rfloor + 1)\\), con el caso base de \\(\\log_2^{(1)} n = \\lfloor \\log_2 n \\rfloor + 1\\).\nLa estrategia lleva a que el valor casi √≥ptimo para la b√∫squeda por comparaci√≥n se da cuando \\(k=\\log^\\star_2{n}\\) donde \\(\\log^\\star_2\\) es el logaritmo iterado, que esta definido como las veces que se debe iterar aplicando el logaritmo para obtener un valor de \\(1\\) o menor que \\(1\\), i.e., la \\(k\\) m√°s peque√±a tal que \\(\\log_2^{(k)}n \\leq 1\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#ejercicios",
    "href": "cap5-busqueda.html#ejercicios",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "5.3 Ejercicios",
    "text": "5.3 Ejercicios\n\nImplementar y probar \\(B_2\\).\nDerivar el costo \\(C_2(p)\\).\n¬øCuando \\(B_1\\) es mejor que \\(B_2\\)?\nHaga un pseudo-c√≥digo para \\(B_k\\).\n¬øCu√°l es el costo \\(C_k\\)?\n¬øQu√© es un √°rbol binario de b√∫squeda?\n¬øCu√°l es el costo de b√∫squeda en un √°rbol? ¬øqu√© se debe hacer para asegurar los costos?\n¬øQu√© es un finger tree?\n¬øCu√°l es el costo de b√∫squeda de la skip list?\n¬øC√≥mo se puede hacer la skip list adaptativa? ¬øqu√© otra forma podr√≠a aplicar?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap5-busqueda.html#material-audio-visual",
    "href": "cap5-busqueda.html#material-audio-visual",
    "title": "5¬† Algoritmos de b√∫squeda en el modelo de comparaci√≥n",
    "section": "5.4 Material audio-visual",
    "text": "5.4 Material audio-visual\nEn el siguiente video se adentraran en diferentes estrateg√≠as de b√∫squeda, notoriamente aquellas que llamaremos oportunistas o adaptables (adaptative). Estas t√©cnicas nos permitir√°n tomar provecho de instancias sencillas de problemas e incrementar el desempe√±o en ese tipo de instancias.\nTenga en cuenta que, honrando la literatura, usaremos de forma indiscriminada listas ordenadas como sin√≥nimo de arreglos ordenados.\n\n\n\n\n\n\n\n\nBentley, Jon Louis, y Andrew Chi-Chih Yao. 1976. ‚ÄúAn almost optimal algorithm for unbounded searching‚Äù. Information processing letters 5 (SLAC-PUB-1679).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Algoritmos de b√∫squeda en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html",
    "href": "cap6-intersecciones.html",
    "title": "6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n",
    "section": "",
    "text": "Objetivo\nAnalizar el rendimiento de algoritmos de uni√≥n e intersecci√≥n de conjuntos representados como listas ordenadas parametrizando los algoritmos con los algoritmos internos de b√∫squeda, tama√±o de los conjuntos y la distribuci√≥n de los elementos, bajo un enfoque experimental midiendo los costos en t√©rminos del tiempo de ejecuci√≥n y el uso de memoria.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#problema",
    "href": "cap6-intersecciones.html#problema",
    "title": "6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n",
    "section": "6.1 Problema",
    "text": "6.1 Problema\nC√≥mo se vi√≥ en Cap√≠tulos anteriores, un conjunto es una colecci√≥n de elementos donde no hay repetici√≥n. El uso de conjuntos es fundamental para un gran n√∫mero de problemas. En particular, en este cap√≠tulo representaremos conjuntos como arreglos ordenados de n√∫meros enteros; esto para posicionarlo dentro de un dominio de aplicaci√≥n objetivo, que es la Recuperaci√≥n de Informaci√≥n, como parte de la representaci√≥n de una la matriz dispersa muy grande, llamada √≠ndice invertido.\nEstaremos resolviendo los problemas de intersecci√≥n y uni√≥n de conjuntos. Demaine, L√≥pez-Ortiz, y Munro (2000) demuestra que el costo y procedimiento de las intersecciones y uniones de conjuntos representados como arreglos ordenados, es b√°sicamente el mismo; ya que requieren determinar la misma informaci√≥n. Claramente, colectar los datos para la uni√≥n y la intersecci√≥n, requieren diferentes esfuerzos.\n\n6.1.1 Costo del problema\nEn general, dados dos conjuntos \\(A[1..m] = \\{a_1 &lt; a_2 &lt; \\cdots &lt; a_m \\}\\) y \\(B[1..n] = \\{b_1 &lt; b_2 &lt; \\cdots &lt; b_n \\}\\), el costo de uni√≥n es \\[\\log{m+n \\choose m},\\] ver Hwang y Lin (1971).\nDe manera m√°s detallada, supongamos que \\(A \\cap B = \\emptyset\\), esto es, el conjunto de salida ser√° de tama√±o \\(m+n\\). De manera similar al razonamiento que se utiliz√≥ para el problema de ordenamiento, el problema puede verse como todas las posibles instancias de ordenes o permutaciones de tama√±o \\(n+m\\); removiendo la necesidad de los ordenes parciales, esto es \\({n+m \\choose m}\\) posibles instancias de tama√±o \\(n+m\\), generadas por dos conjuntos de tama√±o \\(n\\) y \\(m\\). Dado que estamos en un modelo basado en comparaciones, y dado el mejor algoritmo \\(s\\) puede dividir el espacio de posibles ordenes en 2, por tanto, dicho algoritmo necesitar√° \\[\\log_2 {n+m \\choose m}\\] comparaciones para resolver la uni√≥n de cualquier par de conjuntos de tama√±o \\(m\\) y \\(n\\).\nUsando la aproximaci√≥n de Stirling para coefficientes binomiales de MacKay (2003), el costo se convierte en: \\[\\log{m+n \\choose m} = n\\log{\\frac{m+n}{n}} + m \\log\\frac{n+m}{m} \\]\n\n\nRecuerde que \\(\\log_2 x = \\frac{\\log_e x}{\\log e}\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#algoritmos",
    "href": "cap6-intersecciones.html#algoritmos",
    "title": "6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n",
    "section": "6.2 Algoritmos",
    "text": "6.2 Algoritmos\nSe puede observar que si \\(m \\approx n\\), entonces el costo se convierte en \\(O(m + n)\\), esto es, lo m√°s eficiente ser√≠a tomar el siguiente algoritmo:\n\n\nfunction merge2!(C, A, B)\n    i = j = 1\n    m, n = length(A), length(B)\n    \n    @inbounds while i &lt;= m ||  j &lt;= n\n        a, b = A[i], B[j]\n        if a == b\n            push!(C, a)\n            i += 1\n            j += 1\n        elseif a &lt; b\n            push!(C, a)\n            i += 1\n        else\n            push!(C, b)\n            j += 1\n        end\n    end\n\n    C\nend\n\nmerge2! (generic function with 1 method)\n\n\n\n6.2.1 Ejercicio\n\nEscriba y pruebe el algoritmo de intersecci√≥n de merge para \\(n \\approx m\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#algoritmos-para-arreglos-de-tama√±o-muy-diferente",
    "href": "cap6-intersecciones.html#algoritmos-para-arreglos-de-tama√±o-muy-diferente",
    "title": "6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n",
    "section": "6.3 Algoritmos para arreglos de tama√±o muy diferente",
    "text": "6.3 Algoritmos para arreglos de tama√±o muy diferente\nSi \\(m \\ll n\\), el costo tender√° a \\(O(m \\log n)\\), por lo que se pueden realizar \\(m\\) b√∫squedas binarias directas para localizar la posici√≥n de inserci√≥n en \\(B\\).\n\n\n\n\n\n\n\n\nlista\n\n\nA\n\n\n\nB\n\n\n\n\na1\n\n1\n\n\n\na2\n\n2\n\n\n\n\na3\n\n3\n\n\n\n\na4\n\n4\n\n\n\n\na5\n\n5\n\n\n\n\na6\n\n6\n\n\n\n\na7\n\n7\n\n\n\n\na8\n\n8\n\n\n\n\na9\n\n9\n\n\n\n\na10\n\n10\n\n\n\n\na11\n\n11\n\n\n\n\na12\n\n12\n\n\n\n\na13\n\n13\n\n\n\n\na15\n\n15\n\n\n\n\na16\n\n16\n\n\n\n\n1\n\n1\n\n\n\n2\n\n2\n\n\n\n\n3\n\n3\n\n\n\n\n4\n\n4\n\n\n\n\n5\n\n5\n\n\n\n\n6\n\n6\n\n\n\n\n7\n\n7\n\n\n\n\n8\n\n8\n\n\n\n\n9\n\n9\n\n\n\n\n10\n\n10\n\n\n\n\n11\n\n11\n\n\n\n\n12\n\n12\n\n\n\n\n13\n\n13\n\n\n\n\n15\n\n15\n\n\n\n\n16\n\n16\n\n\n\n\n\n\n\nFigura¬†6.1: Dos listas alineadas donde los nodos sombreados son elementos de los conjuntos.\n\n\n\n\n\nSe hace notar que \\(A\\) y \\(B\\) estan ordenados, y por lo tanto, localizar \\(A[i]\\) en \\(B[j]\\) significa que \\(B[j-1] &lt; A[i]\\), por lo que intentar localizar \\(A[i+1]\\) puede comenzar en \\(B[j+1]\\). A continuaci√≥n se muestra el c√≥digo de un algoritmo de intersecci√≥n usando algoritmos de b√∫squeda con memoria de la posici√≥n anterior.\n\nfunction intsearch!(C, A, B, algosearch=doublingsearch)\n    if length(B) &lt; length(A)\n        A, B = B, A\n    end\n\n    p = 1\n    for (i, a) in enumerate(A)\n        p = algosearch(B, a, p)\n        p &gt; length(B) && break\n        if a == B[p]\n            p += 1\n            push!(C, a)\n        end\n    end\n\n    C\nend\n\nHwang y Lin (1971) propone otro algoritmo que funciona para casos similares:\n\nDivide \\(B\\) en bloques de tama√±o \\(m\\), define un arreglo virtual \\(B'[1..n/m]\\) donde \\(B'[i] = B[i \\cdot m]\\)\nSe b√∫sca la posici√≥n de inserci√≥n \\(p\\) de cada \\(a \\in A\\) en \\(B'\\), costando \\(\\log n/m\\) para cada b√∫squeda.\nDespu√©s se localiza dentro del \\(B\\) en el \\(p\\)-√©simo bloque, i.e., \\(B[(p-1)m + 1 .. p\\cdot m]\\), por la posici√≥n de inserci√≥n del bloque, con un costo de \\(\\log m\\).\n\nEntonces, se obtiene un costo de \\(O(m \\log{n/m} + m \\log m)\\); esto es equivalente en el peor caso a b√∫squedas directas, i.e., las posiciones de inserci√≥n de \\(a \\in A\\) se encuentran distribuidas de manera uniforme en \\(B\\). Sin embargo, es posible mejorar si se descartan bloques en el paso 1. Esto es, si se hay concentraci√≥n de elementos de \\(A\\) en bloques de \\(B\\). Para esto, es necesario un an√°lisis de costo promedio, el cual se muestra en el art√≠culo.\nIncluso cuando hay concentraci√≥n, podemos recordar la \\((i-1)\\) posici√≥n de inserci√≥n para iniciar la \\(i\\)-√©sima b√∫squeda, y sacar provecho de posiciones esperadas cercanas de la posici√≥n inicial de b√∫squeda, i.e., podemos utilizar algoritmos de b√∫squeda adaptables para mejorar el desempe√±o.\n\n6.3.1 Algoritmo de Baeza Yates\nBaeza-Yates (2004) propone un algoritmo eficiente para intersecciones de dos conjuntos. El algoritmo tiene una estrateg√≠a dividir para vencer:\n\nSe toma la mediana \\(M\\) de \\(A\\) y se busca en \\(B\\) obteniendo su posici√≥n de inserci√≥n \\(p\\).\nEl problema entonces se divide en 3 subproblemas: \\[\\begin{align}\nC_&lt; &= \\{A[1..M-1] \\cap B[1..p-e]\\} \\\\\nC_= &= \\{A[M]\\} \\cap \\{B[p]\\} \\\\\nC_&gt; &= \\{A[M+1..m] \\cap B[p+e..n]\\} \\\\\n\\end{align}\\] donde \\(e=1\\) si \\(A[M] = B[p]\\) y \\(e=0\\) cuando \\(A[M] \\not= B[p]\\).\nLa uni√≥n de estos tres conjuntos es la soluci√≥n \\(C_&lt; \\cup C_= \\cup C_&gt;\\).\nEl problema \\(C_=\\) es trivial, y \\(C_&lt;\\) y \\(C_&gt;\\) se implementan recurriendo, ajustando los rangos de trabajo.\n\nA continuaci√≥n se muestra el c√≥digo en Julia, usando los algoritmos de b√∫squeda del Cap. 5.\n\n# Adaptado de https://github.com/sadit/Intersections.jl\n\n1function baezayates!(output, A, B, findpos::Function=binarysearch)\n    baezayates!(output, A, 1, length(A), B, 1, length(B), findpos)\nend\n\nfunction baezayates!(output, A, a_sp::Int, a_ep::Int, B, b_sp::Int, b_ep::Int, findpos::Function)\n    (a_ep &lt; a_sp || b_ep &lt; b_sp) && return output\n    imedian = ceil(Int, (a_ep + a_sp) / 2)\n    median = A[imedian]\n    ## our findpos returns n + 1 when median is larger than B[end]\n2    medpos = min(findpos(B, median, b_sp), b_ep)\n    \n    matches = median == B[medpos] \n3    baezayates!(output, A, a_sp, imedian - 1, B, b_sp, medpos - matches, findpos)\n4    matches && push!(output, median)\n5    baezayates!(output, A, imedian + 1, a_ep, B, medpos + matches, b_ep, findpos)\n    output\nend\n\n\n1\n\nPunto de entrada.\n\n2\n\nB√∫squeda de la posici√≥n de inserci√≥n de la mediana de \\(A\\) en \\(B\\).\n\n3\n\nRecurrencia para el problema \\(C_&lt;\\).\n\n4\n\nA√±adir al resultado el valor de la mediana si es que se encontr√≥ en \\(B\\); es importante que este paso este entre las recurrencias para que output sea un arreglo ordenado.\n\n5\n\nRecurencia para el problema \\(C_&gt;\\).\n\n\n\n\nEl algoritmo de Baeza Yates es √≥ptimo en el peor caso y es capaz de aprovechar casos donde \\(C_&lt;\\) o \\(C_&gt;\\) se convierten en triviales, lo cual da muy buenos casos en algunas distribuciones.\n\n\n6.3.2 Ejercicios\n\nImplemente la uni√≥n con el algoritmo de Baeza Yates.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#operaciones-con-tres-o-m√°s-conjuntos",
    "href": "cap6-intersecciones.html#operaciones-con-tres-o-m√°s-conjuntos",
    "title": "6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n",
    "section": "6.4 Operaciones con tres o m√°s conjuntos",
    "text": "6.4 Operaciones con tres o m√°s conjuntos\nLos algoritmos y costos hasta ahora revisados se cumplen para dos conjuntos; se mencionaron diferentes algoritmos, algunos de ellos especializados por caracter√≠sticas como las proporciones de los conjuntos de entrada.\nEn particular, es importante hacer notar que ni el problema ni las aplicaciones estan limitadas a dos conjuntos, y por tanto, es importante algoritmos y estrateg√≠as para resolver \\(\\bigcup_i A_i\\) as√≠ como \\(\\bigcap_i A_i\\).\n\n6.4.1 Algoritmo SvS\nDado \\(C = A \\cap B\\) es un hecho que \\(|C| \\leq min \\{|A|, |B|\\}\\). Recordando, que hay maneras relativamente simples y eficientes de resolver la intersecci√≥n cuando \\(m \\ll n\\); por tanto, cuando tenemos m√°s de dos conjuntos podemos aplicar la estrateg√≠a Small vs Small (SvS), que consisten en intersectar los \\(k\\) conjuntos por pares intersectando el par de arreglos m√°s peque√±os cada vez.\n\n# Adaptado de https://github.com/sadit/Intersections.jl\n\nfunction svs(L::Vector{T}, in2::Function=baezayates!) where T\n    prev, curr = eltype(T)[], eltype(T)[]\n    sort!(L, by=length, rev=true)\n    curr = pop!(L)\n\n    while length(L) &gt; 0\n        empty!(prev)\n        isize = in2(prev, curr, pop!(L))\n        isize == 0 && return prev\n        prev, curr = curr, prev\n    end\n\n    curr\nend\n\n\n\n6.4.2 Algoritmo de Barbay y Kenyon\nExiste otra familia de algoritmos, basados en b√∫squedas adaptativas que pueden llegar a mejorar el desempe√±o bajo cierto tipo de entradas. Demaine, L√≥pez-Ortiz, y Ian Munro (2001), Barbay, L√≥pez-Ortiz, y Lu (2006), y Barbay et¬†al. (2010) muestran algoritmos de intersecci√≥n basados en b√∫squeda adaptables para aprovechar instancias simples. Estos estudios se basan en contribuciones te√≥ricas de los mismos autores: Demaine, L√≥pez-Ortiz, y Munro (2000), Demaine, L√≥pez-Ortiz, y Ian Munro (2001), Barbay y Kenyon (2002) y Baeza-Yates (2004).\nEl algoritmo de Barbay, L√≥pez-Ortiz, y Lu (2006) trabaja sobre los \\(k\\) conjuntos de entrada, representados como arreglos ordenados de n√∫meros enteros. Es un algoritmo simple pero poderoso: hace uso de b√∫squedas adaptivas con memoria para guardar las posiciones donde se avanza, de tal forma que no se recalculen posiciones. Las diferentes estrategias para revisar los conjuntos pueden dar diferentes desempe√±os, como se valida en Barbay et¬†al. (2010), donde adem√°s de hacer una gran variedad de experimentos sobre diferentes algoritmos de b√∫squeda, se introducen variantes en el orden de acceso de cada conjunto.\nA continuaci√≥n se muestra el c√≥digo del algoritmo base:\n\n# Adaptado de https://github.com/sadit/Intersections.jl\n\nfunction bk!(output, L::AbstractVector, findpos::Function=doublingsearch)\n    P = ones(Int, length(L))\n    bk!(output, L, P, findpos)\nend\n \n1function bk!(output, L, P, findpos::Function=doublingsearch)\n2    n = length(L)\n3    el = L[1][1]\n4    c = 0\n\n    @inbounds while true\n        for i in eachindex(P)\n5            P[i] = findpos(L[i], el, P[i])\n            P[i] &gt; length(L[i]) && return output\n            pval = L[i][P[i]]\n            if pval == el\n                c += 1\n6                if c == n\n                    push!(output, el)\n7                    c = 0\n                    P[i] += 1\n                    P[i] &gt; length(L[i]) && return output\n                    el = L[i][P[i]]\n                end\n            else\n                c = 0\n                el = pval\n            end\n        end\n    end\n\n    output\nend\n\n\n1\n\nEl algoritmo de Barbay & Kenyon recibe: i) output el conjunto de salida. ii) L la lista de conjuntos (representados como arreglos ordenados). iii) P arreglo de posiciones actuales para cada arreglo. iv) findpos` funci√≥n de b√∫squeda.\n\n2\n\nN√∫mero de conjuntos en L.\n\n3\n\nel es el elemento siendo b√∫scado en todos los arreglos.\n\n4\n\nc n√∫mero de listas que contienen el.\n\n5\n\nB√∫scando la posici√≥n de inserci√≥n de el en L[i], comenzando en P[i].\n\n6\n\nEsta igualdad implica que hay interecci√≥n.\n\n7\n\nReiniciando el y c y actualizando P[i].\n\n\n\n\nDe manera particular, Barbay et¬†al. (2010) presentan un estudio experimental sobre los algoritmos presentados en el √°rea durante la decada de 2000 a 2010, dichos algoritmos se parametrizaron de maneras que nos permiten aprender diferentes caracter√≠sticas de cada uno de ellos, dependiendo de los algoritmos de b√∫squeda que usan, la arquitectura computacional donde se eval√∫a, y el n√∫mero de conjuntos siendo procesados.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#recursos-audio-visuales-de-la-unidad",
    "href": "cap6-intersecciones.html#recursos-audio-visuales-de-la-unidad",
    "title": "6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n",
    "section": "6.5 Recursos audio-visuales de la unidad",
    "text": "6.5 Recursos audio-visuales de la unidad\nParte 1: Algoritmos de intersecci√≥n (y uni√≥n) de listas ordenadas \nParte 2: Algoritmos de intersecci√≥n y algunas aplicaciones",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "cap6-intersecciones.html#actividades",
    "href": "cap6-intersecciones.html#actividades",
    "title": "6¬† Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n",
    "section": "6.6 Actividades",
    "text": "6.6 Actividades\nImplementaci√≥n y comparaci√≥n de diferentes algoritmos de intersecci√≥n de conjuntos.\nLea cuidadosamente las instrucciones y desarrolle las actividades. Entregue el reporte correspondiente en tiempo.\n\n\n\n\n\n\nBaeza-Yates, Ricardo. 2004. ‚ÄúA fast set intersection algorithm for sorted sequences‚Äù. En Combinatorial Pattern Matching: 15th Annual Symposium, CPM 2004, Istanbul, Turkey, July 5-7, 2004. Proceedings 15, 400‚Äì408. Springer.\n\n\nBarbay, J√©r√©my, y Claire Kenyon. 2002. ‚ÄúAdaptive intersection and t-threshold problems‚Äù. En Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms, 390‚Äì99. SODA ‚Äô02. USA: Society for Industrial; Applied Mathematics.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, y Tyler Lu. 2006. ‚ÄúFaster adaptive set intersections for text searching‚Äù. En Experimental Algorithms: 5th International Workshop, WEA 2006, Cala Galdana, Menorca, Spain, May 24-27, 2006. Proceedings 5, 146‚Äì57. Springer.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, Tyler Lu, y Alejandro Salinger. 2010. ‚ÄúAn experimental investigation of set intersection algorithms for text searching‚Äù. Journal of Experimental Algorithmics (JEA) 14: 3‚Äì7.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, y J Ian Munro. 2001. ‚ÄúExperiments on adaptive set intersections for text retrieval systems‚Äù. En Algorithm Engineering and Experimentation: Third International Workshop, ALENEX 2001 Washington, DC, USA, January 5‚Äì6, 2001 Revised Papers 3, 91‚Äì104. Springer.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, y J Ian Munro. 2000. ‚ÄúAdaptive set intersections, unions, and differences‚Äù. En Proceedings of the eleventh annual ACM-SIAM symposium on Discrete algorithms, 743‚Äì52.\n\n\nHwang, Frank K., y Shen Lin. 1971. ‚ÄúOptimal merging of 2 elements with n elements‚Äù. Acta Informatica 1 (2): 145‚Äì58.\n\n\nMacKay, David JC. 2003. Information theory, inference and learning algorithms. Cambridge university press.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Algoritmos de intersecci√≥n y uni√≥n de conjuntos en el modelo de comparaci√≥n</span>"
    ]
  },
  {
    "objectID": "refs.html",
    "href": "refs.html",
    "title": "References",
    "section": "",
    "text": "Baeza-Yates, Ricardo. 2004. ‚ÄúA Fast Set Intersection Algorithm for\nSorted Sequences.‚Äù In Combinatorial Pattern Matching: 15th\nAnnual Symposium, CPM 2004, Istanbul, Turkey, July 5-7, 2004.\nProceedings 15, 400‚Äì408. Springer.\n\n\nBarbay, J√©r√©my, and Claire Kenyon. 2002. ‚ÄúAdaptive Intersection\nand t-Threshold Problems.‚Äù In Proceedings of the Thirteenth\nAnnual ACM-SIAM Symposium on Discrete Algorithms, 390‚Äì99. SODA ‚Äô02.\nUSA: Society for Industrial; Applied Mathematics.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, and Tyler Lu. 2006. ‚ÄúFaster\nAdaptive Set Intersections for Text Searching.‚Äù In\nExperimental Algorithms: 5th International Workshop, WEA 2006, Cala\nGaldana, Menorca, Spain, May 24-27, 2006. Proceedings 5, 146‚Äì57.\nSpringer.\n\n\nBarbay, J√©r√©my, Alejandro L√≥pez-Ortiz, Tyler Lu, and Alejandro Salinger.\n2010. ‚ÄúAn Experimental Investigation of Set Intersection\nAlgorithms for Text Searching.‚Äù Journal of Experimental\nAlgorithmics (JEA) 14: 3‚Äì7.\n\n\nBentley, Jon Louis, and Andrew Chi-Chih Yao. 1976. ‚ÄúAn Almost\nOptimal Algorithm for Unbounded Searching.‚Äù Information\nProcessing Letters 5 (SLAC-PUB-1679).\n\n\nCook, Curtis R, and Do Jin Kim. 1980. ‚ÄúBest Sorting Algorithm for\nNearly Sorted Lists.‚Äù Communications of the ACM 23 (11):\n620‚Äì24.\n\n\nCormen, Thomas H, Charles E Leiserson, Ronald L Rivest, and Clifford\nStein. 2022. Introduction to Algorithms. MIT press.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, and J Ian Munro. 2001.\n‚ÄúExperiments on Adaptive Set Intersections for Text Retrieval\nSystems.‚Äù In Algorithm Engineering and Experimentation: Third\nInternational Workshop, ALENEX 2001 Washington, DC, USA, January 5‚Äì6,\n2001 Revised Papers 3, 91‚Äì104. Springer.\n\n\nDemaine, Erik D, Alejandro L√≥pez-Ortiz, and J Ian Munro. 2000.\n‚ÄúAdaptive Set Intersections, Unions, and Differences.‚Äù In\nProceedings of the Eleventh Annual ACM-SIAM Symposium on Discrete\nAlgorithms, 743‚Äì52.\n\n\nEstivill-Castro, Vladmir, and Derick Wood. 1992. ‚ÄúA Survey of\nAdaptive Sorting Algorithms.‚Äù ACM Computing Surveys\n(CSUR) 24 (4): 441‚Äì76.\n\n\nHwang, Frank K., and Shen Lin. 1971. ‚ÄúOptimal Merging of 2\nElements with n Elements.‚Äù Acta Informatica 1 (2):\n145‚Äì58.\n\n\nKnuth, Donald. 1998. The Art of Computer Programming, Vol. 3 (2nd\nEd): Sorting and Searching. Vol. 3. Redwood City, CA, USA.: Addison\nWesley Longman Publishing Co. Inc.\n\n\nLoeser, Rudolf. 1974. ‚ÄúSome Performance Tests of\n‚ÄòQuicksort‚Äô and Descendants.‚Äù Communications of\nthe ACM 17 (3): 143‚Äì52.\n\n\nMacKay, David JC. 2003. Information Theory, Inference and Learning\nAlgorithms. Cambridge university press.\n\n\nPugh, William. 1990. ‚ÄúSkip Lists: A Probabilistic Alternative to\nBalanced Trees.‚Äù Commun. ACM 33 (6): 668‚Äì76. https://doi.org/10.1145/78973.78977.\n\n\nScott, Jennifer, and Miroslav T≈Øma. 2023. ‚ÄúAn Introduction to\nSparse Matrices.‚Äù In Algorithms for Sparse Linear\nSystems, 1‚Äì18. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-25820-6_1.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "galeria-actividades.html",
    "href": "galeria-actividades.html",
    "title": "Galer√≠a de actividades MCDI",
    "section": "",
    "text": "Semestre 2025-1\nEste curso se imparti√≥ en este formato en MCDI-2025-1; el plan es modificar las actividades ligeramente con forme pasan los semestres y que la galer√≠a apoye a los nuevos estudiantes para tener ejemplos claros de lo que se solicita.",
    "crumbs": [
      "Ap√©ndices",
      "Galer√≠a de actividades MCDI"
    ]
  },
  {
    "objectID": "galeria-actividades.html#semestre-2025-1",
    "href": "galeria-actividades.html#semestre-2025-1",
    "title": "Galer√≠a de actividades MCDI",
    "section": "",
    "text": "Alumno\nSitio\n\n\n\n\nAlma Diana Herrera Ortiz\nhttps://aldihero.github.io/datascience_foundations/\n\n\nArif Narv√°ez de la O\nhttps://arifnvz.github.io/about.html\n\n\nBrigitte Rarinka Godinez Montoya\nhttps://github.com/Programadari/analisis-de-algoritmos-2025-1/\n\n\nDavid Segundo Garcia\nhttps://davidsg24.github.io/An-lisis-de-algoritmos/\n\n\nIsaac Hern√°ndez Ram√≠rez\nhttps://isaachr141522.github.io/reportes_algoritmos/\n\n\nJos√© Alberto Villegas D√≠az Disciplina\nhttps://albertovillegas07.github.io/AnalisisAlgoritmos2025/\n\n\nJos√© Francisco C√°zarez Marroqu√≠n\nhttps://dsfrankcaza.github.io/Analsis-de-Algoritmos/\n\n\nJuan Antonio Velasquez Martinez\nhttps://juan21javm.github.io/proyecto-analisis-de-algoritmos/\n\n\nLuis Alberto Rodr√≠guez Catana\nhttps://albertocat.github.io/Algoritmos/\n\n\nSantiago Botero Sierra\nhttps://sboteros.com/about.html",
    "crumbs": [
      "Ap√©ndices",
      "Galer√≠a de actividades MCDI"
    ]
  }
]