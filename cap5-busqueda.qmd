---
engine: julia
lang: es-MX
---

# Algoritmos de búsqueda en el modelo de comparación {#sec-busqueda}

## Objetivo {.unnumbered}
Analizar algoritmos de búsqueda en arreglos ordenados basados en funciones de comparación, con el objetivo de localizar elementos y posiciones específicas, usando técnicas de peor caso y adaptables a la distribución de los datos para una solución eficiente de problemas informáticos.

## Problema

Sea $A[1..n] = a_1, \cdots, a_n$ un arreglo ordenado con $n \geq 1$ y un operador $<$ (menor que); por simplicidad, también usaremos $\leq$ (menor o igual que). Supondremos que no hay elementos duplicados en $A$, note que esto no implica una perdida de generalidad.

La tarea será: dado el valor $x$ a ser localizado en $A$, el problema consiste en determinar la posición de inserción $p$ tal que suceda alguna de las siguientes condiciones:

- si $p = 1$ entonces $x \leq A[p]$.
- si $2 \leq p \leq n$ entonces $A[p-1] < x \leq A[p]$.
- si $p=n+1$ entonces $A[n] < x$.

### Costo de peor caso
Para $A[1..n]$ y el valor $x$ a localizar su posición de inserción, el resultado puede ser cualquiera de las $n+1$ posiciones posibles, i.e., instancias del problema. Un algoritmo naïve utilizaría $n$ comparaciones para resolverlo.

```{julia}
"""
	seqsearch(A, x, sp=1)

Búsqueda exhaustiva con inicio
"""
function seqsearch(A, x, sp=1)
	n = length(A)
	while sp <= n && x > A[sp]
		sp += 1
	end
	
	sp
end

let S=[10, 20, 30, 40, 50, 60, 70]
    (seqsearch(S, 0), seqsearch(S, 69), seqsearch(S, 70), seqsearch(S, 71))
end
```

Sin embargo, dado que el arreglo esta ordenado y no hay duplicados, se puede mejorar mucho el tiempo de búsqueda.  ::: {.column-margin}
Si se permiten duplicados se pueden mejorar muchos los tiempos; sobre todo si podemos preprocesar el arreglo, i.e., para determinar las zonas con duplicados.
:::

El costo de búsqueda para cualquier instancia es $O(\log n)$, y viene de la búsqueda binaria:

```{julia}
"""
	binarysearch(A, x, sp=1, ep=length(A))

Encuentra la posición de inserción de `x` en `A` en el rango `sp:ep`
"""
function binarysearch(A, x, sp=1, ep=length(A))
	while sp < ep             # <3>
		mid = div(sp + ep, 2) # <1>
		if x <= A[mid]        # <1>
			ep = mid          # <2>
		else
			sp = mid + 1      # <2>
		end
	end
	
    x <= A[sp] ? sp : sp + 1 # <4>
end

let S=[10, 20, 30, 40, 50, 60, 70]
    (binarysearch(S, 0), binarysearch(S, 69), binarysearch(S, 70), binarysearch(S, 71))
end
```
1. Para el rango de búsqueda $sp:ep$ se determina su punto central $mid$ y se compara con $x$,
2. Si el elemento $x$ esta a la izquierda, se ajusta el limite superior $ep,$ o de lo contrario se ajusta $sp$. Ambos ajustes se hacen tomando en cuenta la posición comparada.
3. Se itera mientras no se junten los dos extremos del rango.
4. Finalmente, se ajusta para valores fuera del rango. 

Este algoritmo es simple y efectivo, y es capaz de resolver cualquier instancia en tiempo logarítmico, y esto lo hace al dividir el rango siempre a la mitad por cada iteración, por lo que no puede hacer más que $O(\log n)$ comparaciones antes de cerrar el rango donde puede estar la posición de inserción. 

Es importante hacer notar que la búsqueda binaria es muy eficiente en memoría y tiene un peor caso óptimo, ya que es idéntico al costo del problema, i.e., así lo determinamos. Si fuera posible tener probar varios puntos, i.e., $m$ segmentos en una sola operación, el costo estaría acotado en $\lceil \log_{m} n \rceil$. Esto tiene sentido para estructuras de datos que trabajan en diferentes niveles de memoría, donde aunque las comparaciones en hardware moderno sean binarias, la diferencia entre velocidades de los diferentes niveles de memoria se puede pensar que el costo dominante es, por ejemplo, acceder a una zona de disco y obtener una decisión entre $m-1$ posibles, que particionan los rangos en $m$ divisiones.

## Búsqueda _no_ acotada
Cuando el tamaño del arreglo es demasiado grande, o la relación entre $p / n$ es significativamente pequeña, la búsqueda acotada no es la mejor opción. Aun cuando en la práctica el límite superior $n$ podría estar determinado, y por lo tanto, se pueden resolver búsquedas en $O(\log n)$, es posible obtener una cota relativa a $p$, independiente de $n$, por lo que los casos de interés se verán beneficiados.

Una estrategia simple y poderosa es la siguiente:

1. Determinar un _buen_ rango que contenga la respuesta.
2. Aplicar búsqueda binaria en ese rango para obtener la respuesta.

@bentley1976almost describen a detalle una familia de algoritmos casí óptimos para la búsqueda no acotada siguiendo la estrategía anteriormente mencionada. En particular, poniendo un enfásis importante en la determinación del rango. Lo consigue mediante la definición de algoritmos definidos de manera interesante como sigue en el resto de la sección.

### Algoritmo $B_0$ (búsqueda unaría)
Es el algoritmo más simple, y ya lo vimos con anterioridad, realiza una búsqueda exhaustiva de la posición de inserción, hacendo pruebas para toda posición $x \leq A[1]$, $x \leq A[2]$, \cdots $x \leq A[p+1]$, por lo que su costo será de $p+1$.

### Algoritmo $B_1$ (búsqueda doblada: _doubling search/galloping_)
Consiste en comparar las posiciones $2^i$, i.e., $2^1, 2^2, 2^3, \cdots, 2^{\lfloor \log_2{p+1} \rfloor + 1}$, tal que $A[2^{\lfloor\log_2{p}\rfloor+1}] \leq  x \leq A[2^{\lfloor\log_2{p+1}\rfloor+1}]$; claramente, el número de comparaciones para determinar el rango esta determinado por $\lfloor \log_2{p+1} \rfloor + 1$. Una vez determinado el rango la búsqueda binaria sobre $A[2^{\lfloor\log_2{p}\rfloor+1}:2^{\lfloor\log_2{p+1}\rfloor+1}]$, lo cual corresponde a $\log_2 2^{\lfloor\log{p+1}\rfloor} = \lfloor\log_2{p+1}\rfloor$. Por tanto el costo total de $B_1$ es $\lfloor 2\log_2{p+1} \rfloor + 1$ esto puede ser escrito como $O(\log_2 p)$.

Un punto de interés es saber cuando $\lfloor 2\log_2{p+1} \rfloor + 1 < \lfloor \log_2 n \rfloor + 1$, esto es, cuando $B_1$ es mejor que la búsqueda binaria. Para simplificar este análisis ignoraremos algunos detalles de la expresión.

\begin{align}
 2\log_2{p+1}        & <  \log_2 n, \\
 2^{\log_2{(p+1)^2}} & <  2^{\log_2 n}, \\
 2^{\log_2{(p+1)^2}} & <  2^{\log_2 n}, \\
 (p + 1)^2           & <  n, \\
 p                   & <  \sqrt{n} - 1; \\
\end{align}

Esto indica que sí $p$ es menor que $\sqrt{n}-1$ hay una ventaja al usar $B_1$; lo cual nos dice que para posiciones cercanas al inicio el uso de $B_1$ puede llevar a búsquedas más veloces. Note que en la práctica es necesario tener en cuenta la memoria, interesantemente, para $p$ pequeñas es posible que esto beneficie al algoritmo ya que podría mantener las listas en cache.

El siguiente código implementa $B_1$

```{julia}
function doublingsearch(A, x, sp=1)
    n = length(A)
	p = 0
    i = 1

    while sp+i <= n && A[sp+i] < x # <1>
		p = i
		i += i
    end

    binarysearch(A, x, sp + p, min(n, sp+i)) # <2>
end

let S=[10, 20, 30, 40, 50, 60, 70]
    (doublingsearch(S, 0), doublingsearch(S, 69), doublingsearch(S, 70), doublingsearch(S, 71))
end
```
1. Determinación del rango.
2. Aplicar un algoritmo de búsqueda eficiente en el rango que contiene la respuesta.

Es cierto que estos algoritmos son oportunistas, pero hay aplicaciones donde esto realmente sucede. En el peor caso, el costo será apenas dos veces el óptimo.

### Algoritmo $B_2$ (búsqueda doblemente doblada, _doubling-doubling search_)
Aquí será más clara la dinámica. $B_2$ consiste en comparar las posiciones $2^{2^i}$, i.e., $2^{4}, 2^{16}, 2^{256}, \cdots, 2^{2^{\lfloor \log_2{p+1} \rfloor + 1}}$, tal que 
$$A[2^{2^{\lfloor\log_2{\lfloor\log_2{p}\rfloor+1}\rfloor + 1}}] \leq  x \leq A[2^{2^{\lfloor\log_2{\lfloor\log_2{p+1}\rfloor+1}\rfloor + 1}}];$$
La determinación de este rango requiere $\lfloor\log_2{\lfloor\log_2{p+1}\rfloor+1}\rfloor+1$ comparaciones; sin embargo, este rango seguramente será muy grande, por el tipo de saltos que se estan dando entre puntos de comparación, por lo que no conviene usar busqueda binaria y podemos aplicar $B_1$ para resolver en ese rango acotado.

Simplificando la expresión, el costo es como sigue:

$$\lfloor\log_2{\lfloor\log_2{p+1}\rfloor+1}\rfloor + 2\log_2{2^{2^{\lfloor\log_2{\lfloor\log_2{p+1}\rfloor+1}\rfloor}}} + O(1)$$
$$\lfloor\log_2{(\lfloor\log_2{p+1}\rfloor+1)}\rfloor + {2\lfloor\log_2{2(p+1)}\rfloor} + O(1)$$


claramente, el número de comparaciones para determinar el rango esta determinado por $\lfloor \log_2{p+1} \rfloor + 1$. Una vez determinado el rango la búsqueda binaria sobre $A[2^{\lfloor\log_2{p}\rfloor+1}:2^{\lfloor\log_2{p+1}\rfloor+1}]$, lo cual corresponde a $\log_2 2^{\lfloor\log{p+1}\rfloor} = \lfloor\log_2{p+1}\rfloor$. Por tanto el costo total de $B_1$ es $\lfloor 2\log_2{p+1} \rfloor + 1$ esto puede ser escrito como $O(\log_2 p)$.

### Algoritmo $B_k$

## Ejercicios
- ¿Cuando $B_2$ es mejor que $B_1$?
- ¿Cuando $B_2$ es mejor que búsqueda binaria?
- Haga un pseudo-código para $B_k$.

### Algoritmo $B_k$
### Listas ordenadas
En esta unidad se aborda la búsqueda en arreglos ordenados, y abusando del término, muchas veces les llamaremos _listas ordenadas_. Recuerde que a lo largo de este curso, esta será nuestra representación para conjuntos.

En la literatura es común que se aborde el tema con un modelo de costo basado en comparaciones, esto es, cada comparación $\le$ provoca costo constante $O(1)$. Este curso no es la excepción.
La comparación como unidad de costo es un excelente factorizador de las operaciones satelitales en los algoritmos de búsqueda; esto debería quedar claro una vez que se comprendan los algoritmos.

Utilizaremos como base el artículo [@Bentley76], que es de lectura forzosa. Nos apoyaremos en una serie de lecturas adicionales para comprender y madurar el concepto.

## Material audio-visual
En el siguiente video se adentraran en diferentes estrategías de búsqueda, notoriamente aquellas que llamaremos oportunistas o adaptables (adaptative). Estas técnicas nos permitirán tomar provecho de instancias sencillas de problemas e incrementar el desempeño en ese tipo de instancias.

Tenga en cuenta que, honrando la literatura, usaremos de forma indiscriminada listas ordenadas como sinónimo de arreglos ordenados.

### Búsqueda
<iframe width="560" height="315" src="https://www.youtube.com/embed/VZHlcPPKW5A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

