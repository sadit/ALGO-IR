---
title: "Algoritmos de intersección y unión de conjuntos en el modelo de comparación"
lang: es-MX
engine: julia

---


## Objetivo {.unnumbered}
Analizar el rendimiento de algoritmos de unión e intersección de conjuntos representados como listas ordenadas parametrizando los algoritmos con los algoritmos internos de búsqueda, tamaño de los conjuntos y la distribución de los elementos, bajo un enfoque experimental midiendo los costos en términos del tiempo de ejecución y el uso de memoria.

## Problema

Cómo se vió en Capítulos anteriores, un conjunto es una colección de elementos donde no hay repetición. El uso de conjuntos es fundamental para un gran número de problemas. En particular, en este capítulo representaremos conjuntos como arreglos ordenados de números enteros; esto para posicionarlo dentro de un dominio de aplicación objetivo, que es la Recuperación de Información, como parte de la representación de una la matriz dispersa muy grande, llamada _índice invertido_. 

Estaremos resolviendo los problemas de intersección y unión de conjuntos. @DLOM2000 demuestra que el costo y procedimiento de las intersecciones y uniones de conjuntos representados como arreglos ordenados, es básicamente el mismo; ya que requieren determinar la misma información. Claramente, colectar los datos para la unión y la intersección, requieren diferentes esfuerzos.

### Costo del problema
En general, dados dos conjuntos $A[1..m] = \{a_1 < a_2 < \cdots < a_m \}$ y $B[1..n] = \{b_1 < b_2 < \cdots < b_n \}$, el costo de unión es $$\log{m+n \choose m},$$ ver @hwang1971optimal.

De manera más detallada, supongamos que $A \cap B = \emptyset$, esto es, el conjunto de salida será de tamaño $m+n$. De manera similar al razonamiento que se utilizó para el problema de ordenamiento, el problema puede verse como todas las posibles instancias de ordenes o permutaciones de tamaño $n+m$; removiendo la necesidad de los ordenes parciales, esto es ${n+m \choose m}$ posibles instancias de tamaño $n+m$, generadas por dos conjuntos de tamaño $n$ y $m$. Dado que estamos en un modelo basado en comparaciones, y dado el mejor algoritmo $s$ puede dividir el espacio de posibles ordenes en 2, por tanto, dicho algoritmo necesitará $$\log_2 {n+m \choose m}$$ comparaciones para resolver la unión de cualquier par de conjuntos de tamaño $m$ y $n$.

Usando la aproximación de Stirling para coefficientes binomiales de @mackay2003information, el costo se convierte en:
$$\log{m+n \choose m} = n\log{\frac{m+n}{n}} + m \log\frac{n+m}{m} $$

::: {.column-margin}
Recuerde que $\log_2 x = \frac{\log_e x}{\log e}$.

:::

## Algoritmos
Se puede observar que si $m \approx n$, entonces el costo se convierte en $O(m + n)$, esto es, lo más eficiente sería tomar el siguiente algoritmo:

```{julia}

function merge2!(C, A, B) # <1>
    i = j = 1
    m, n = length(A), length(B)
    
    @inbounds while i <= m ||  j <= n # <2>
        a, b = A[i], B[j]
        if a == b
            push!(C, a)
            i += 1
            j += 1
        elseif a < b
            push!(C, a)
            i += 1
        else
            push!(C, b)
            j += 1
        end
    end

    C
end
```

### Ejercicio
- Escriba y pruebe el algoritmo de intersección de merge para $n \approx m$.

```{julia}
#| echo: false
#| output: false
@assert 1:8 == merge2!(Int[], [1, 3, 4, 6, 8], [2, 5, 7])
@assert 0:9 == merge2!(Int[], [1, 3, 4, 6, 8], [0, 2, 5, 7, 9])
@assert 1:10 == merge2!(Int[], 1:5, 6:10)
```

## Algoritmos para arreglos de tamaño muy diferente
Si $m \ll n$, el costo tenderá a $O(m \log n)$, por lo que se pueden realizar $m$ búsquedas binarias _directas_ para localizar la posición de inserción en $B$. 

```{dot}
//| label: fig-interseccion
//| echo: false
//| fig-width: 100%
//| fig-cap: |
//|   Dos listas alineadas donde los nodos sombreados son elementos de los conjuntos.
digraph lista {
  //layout=neato;
  rankdir=LR;
  graph [pad="0.5", nodesep="0.5", ranksep="0.5"];
  
  //{rank=same; a; b; c; nothing;}
  splines="true";
  //node [style="invis"];
  subgraph A {
    cluster=true;
    a1 [label="1"];
    a2 [label="2", style="filled"];
    a3 [label="3"];
    a4 [label="4"];
    a5 [label="5", style="filled"];
    a6 [label="6"];
    a7 [label="7", style="filled"];
    a8 [label="8"];
    a9 [label="9"];
    a10 [label="10"];
    a11 [label="11"];
    a12 [label="12"];
    a13 [label="13"];
    a15 [label="15", style="filled"];
    a16 [label="16"];
  } 
 subgraph B {
    cluster=true;
  1 [label="1", style="filled"];
  2 [label="2"];
  3 [label="3"];
  4 [label="4"];
  5 [label="5", style="filled"];
  6 [label="6"];
  7 [label="7", style="filled"];
  8 [label="8"];
  9 [label="9"];
  10 [label="10", style="filled"];
  11 [label="11"];
  12 [label="12", style="filled"];
  13 [label="13"];
  15 [label="15", style="filled"];
  16 [label="16"];
 }
  edge [style="invis"];
  1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 15 -> 16[weight=30];

  a1 -> a2 -> a3 -> a4 -> a5 -> a6 -> a7 -> a8 -> a9 -> a10 -> a11 -> a12 -> a13 -> a15 -> a16 [weight=30];
  
  //A -> B
  
  //edge [style=""];
  //5 -> a5 [weight=0];
  //7 -> a7 [weight=0];
  //15 -> a15 [weight=0];
}
```

Se hace notar que $A$ y $B$ estan ordenados, y por lo tanto, localizar $A[i]$ en $B[j]$ significa que $B[j-1] < A[i]$, por lo que intentar localizar $A[i+1]$ puede comenzar en $B[j+1]$.
@hwang1971optimal propone otro algoritmo que funciona para casos similares:

1. Divide $B$ en bloques de tamaño $m$, define un arreglo _virtual_ $B'[1..n/m]$ donde $B'[i] = B[i \cdot m]$
2. Se búsca la posición de inserción $p$ de cada $a \in A$ en $B'$, costando $\log n/m$ para cada búsqueda.
3. Después se localiza dentro del $B$ en el $p$-ésimo bloque, i.e., $B[(p-1)m + 1 .. p\cdot m]$, por la posición de inserción del bloque, con un costo de $\log m$.

Entonces, se obtiene un costo de $O(m \log{n/m} + m \log m)$; esto es equivalente en el peor caso a búsquedas directas, i.e., las posiciones de inserción de $a \in A$ se encuentran distribuidas de manera uniforme en $B$. Sin embargo, es posible mejorar si se descartan bloques en el paso 1. Esto es, si se hay concentración de elementos de $A$ en bloques de $B$. 

Incluso cuando hay concentración, podemos recordar la $(i-1)$ posición de inserción para iniciar la $i$-ésima búsqueda, y sacar provecho de posiciones esperadas cercanas de la posición inicial de búsqueda, i.e., podemos utilizar algoritmos de búsqueda adaptables para mejorar el desempeño.

### Algoritmo de Baeza Yates
@BY2004 propone un algoritmo eficiente para intersecciones de dos conjuntos. El algoritmo tiene una estrategía _dividir para vencer_:

1. Se toma la mediana $M$ de $A$ y se busca en $B$ obteniendo su posición de inserción $p$.
2. El problema entonces se divide en 3 subproblemas:
    \begin{align}
    C_< &: \{A[1..M-1] \cap B[1..p-e]\} \\
    C_= &: \{A[M]\} \cap \{B[p]\} \\ 
    C_> &: \{A[M+1..m] \cap B[p+e..n]\} \\
    \end{align}
  donde $e=1$ si $A[M] = B[p]$ y $e=0$ cuando $A[M] \not= B[p]$.
3. La unión de estos tres conjuntos es la solución $C_< \cup C_= \cup C_>$.
4. El problema $C_=$ es trivial, y $C_<$ y $C_>$ se implementan recurriendo, ajustando los rangos de trabajo.

A continuación se muestra el código en Julia, usando los algoritmos de búsqueda del Cap. 5.
```{julia}
#| echo: false
#| output: false
# tomados de cap5
function binarysearch(A, x, sp=1, ep=length(A))
	while sp < ep             # <3>
		mid = div(sp + ep, 2) # <1>
		if x <= A[mid]        # <1>
			ep = mid          # <2>
		else
			sp = mid + 1      # <2>
		end
	end
	
    x <= A[sp] ? sp : sp + 1 # <4>
end

function doublingsearch(A, x, sp=1)
    n = length(A)
	p = 0
    i = 1

    while sp+i <= n && A[sp+i] < x # <1>
		p = i
		i += i
    end

    binarysearch(A, x, sp + p, min(n, sp+i)) # <2>
end
```

```{julia}
#| output: false
# Adaptado de https://github.com/sadit/Intersections.jl

function baezayates!(output, A, B, findpos::Function=binarysearch) # <1> 
    baezayates!(output, A, 1, length(A), B, 1, length(B), findpos)
end

function baezayates!(output, A, a_sp::Int, a_ep::Int, B, b_sp::Int, b_ep::Int, findpos::Function)
    (a_ep < a_sp || b_ep < b_sp) && return output
    imedian = ceil(Int, (a_ep + a_sp) / 2)
    median = A[imedian]
    ## our findpos returns n + 1 when median is larger than B[end]
    medpos = min(findpos(B, median, b_sp), b_ep)  # <2>
    
    matches = median == B[medpos] 
    baezayates!(output, A, a_sp, imedian - 1, B, b_sp, medpos - matches, findpos) # <3>
    matches && push!(output, median) # <4>
    baezayates!(output, A, imedian + 1, a_ep, B, medpos + matches, b_ep, findpos) # <5>
    output
end
```
1. Punto de entrada.
2. Búsqueda de la posición de inserción de la mediana de $A$ en $B$.
3. Recurrencia para el problema $C_<$.
4. Añadir al resultado el valor de la mediana si es que se encontro en $B$; es importante que este paso este entre las recurrencias para que _output_ sea un arreglo ordenado.
5. Recurencia para el problema $C_>$.


```{julia}
#| output: false
#| echo: false
@assert [4, 6] == baezayates!(Int[], [1, 3, 4, 6, 8], [2, 4, 5, 6, 7])
@assert 1:5 == baezayates!(Int[], 1:10, 1:5)
@assert 1:9 == baezayates!(Int[], 0:10, 1:9)
@assert 1:2:9 == baezayates!(Int[], 0:10, 1:2:9)
```

## Operaciones con tres o más conjuntos
Los algoritmos y costos hasta ahora revisados se cumplen para dos conjuntos; se mencionaron diferentes algoritmos, algunos de ellos especializados por características como las proporciones de los conjuntos de entrada. 

En particular, es importante hacer notar que ni el problema ni las aplicaciones estan limitadas a dos conjuntos, y por tanto, es importante algoritmos y estrategías para resolver $\bigcup_i A_i$ así como $\bigcap_i A_i$.

### Algoritmo SvS

### Algoritmo de Barbay y Kenyon



Cuando $k>2$, la intersección se puede realizar usando las $k$ listas a la vez, o se puede hace por pares. Se puede observar que la intersección de dos conjuntos da como resultado un conjunto igual o más pequeño que el más pequeño de los conjuntos intersectados. Adicionalmente, los conjuntos pequeños son "más faciles" de intersectar con un algoritmo _na\"ive_. Por tanto, una estrategía que funciona bien en el peor caso es intersectar los 2 arreglos más pequeños cada vez. Esta una idea muy
popular llamada _Small vs Small (SvS)_.

Existe otra familia de algoritmos, basados en búsquedas adaptativas que pueden llegar a mejorar el desempeño bajo cierto tipo de entradas. En [@DLOPM2001], [@BLOL2006], [@BLOLS2010], y [@BYS2005] se muestran comparaciones experimentales de diversos algoritmos de intersección, entre ellos adaptables, que utilizan de manera creativa algoritmos de búsqueda adaptables para aprovechar instancias simples. Estos estudios se basan en contribuciones teoricas de los mismos autores [@DLOM2000], [@DLOPM2001], [@BK2002], [@BY2004].

## Recursos audio-visuales de la unidad

Parte 1: Algoritmos de intersección (y unión) de listas ordenadas
<iframe width="560" height="315" src="https://www.youtube.com/embed/aDYO39yi-4g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Parte 2: Algoritmos de intersección y algunas aplicaciones
<iframe width="560" height="315" src="https://www.youtube.com/embed/oOd5LoVJcAs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Actividades
Implementación y comparación de diferentes algoritmos de intersección de conjuntos.

Lea cuidadosamente las instrucciones y desarrolle las actividades. Entregue el reporte correspondiente en tiempo.


### Actividad 0 [Sin entrega]

1. Lea y comprenda los artículos relacionados (listados en la introducción).

### Actividad 1 [Con reporte]
1. Cargue el archivo `listas-posteo-100.json` del tema 3. Si lo desea, puede usar listas de posteo generadas con otros conjuntos de datos, usando los scripts de las unidades pasadas. Si es necesario, repase los temas anteriores para recordar la naturaleza y propiedades de las listas.

 - Sea $P^{(2)}$ el conjunto de todos los posibles pares de listas entre las 100 listas de posteo. Seleccione de manera aleatoria $A \subset P^{(2)}$, $|A| = 1000$.
 - Sea $P^{(3)}$ el conjunto de todas las posibles combinaciones de tres listas de posteo entre las 100 listas disponibles, Seleccione de manera aleatoria $B \subset P^{(3)}$, $|B| = 1000$.
 - Sea $P^{(4)}$ el conjunto de todas las posibles combinaciones de cuatro listas de posteo entre las 100 listas disponibles. Seleccione de manera aleatoria $C \subset P^{(4)}$, $|C| = 1000$.

2. Implemente los algoritmos de las secciones 3.1 _Melding Algorithms_ y 3.2 _Search algorithms_ (en especial 3.2.1 y 3.2.2) de [@BLOLS2010].

3. Realice y reporte los siguientes experimentos:
 - Intersecte cada par de listas $a, b \in A$, y reporte de manera acumulada el tiempo en segundos y el número de comparaciones. 
 - Intersecte cada tripleta de listas $a, b, c \in B$, y reporte de manera acumulada el tiempo en segundos y el número de comparaciones. 
 - Intersecte cada tetrapleta de listas $a, b, c, d \in C$, y reporte de manera acumulada el tiempo en segundos y el número de comparaciones.
 - Cree una figura `boxplot` que describa el tiempo en segundos para los tres experimentos.
 - Cree una figura `boxplot` que describa el número de comparaciones para los tres experimentos.
 - Cree una figura `boxplot` que describa las longitudes de las intersecciones resultantes para $A$, $B$, $C$.

### Entregable
El reporte deberá ser en formato notebook y el PDF del mismo notebook. El notebook debe contener las
implementaciones. Recuerde que el reporte debe llevar claramente su nombre, debe incluir una
introducción, la explicación de los métodos usados, la explicación de los experimentos realizados, la discusión de los resultados, y finalizar con sus observaciones y conclusiones.

_Nota sobre la generación del PDF_: Jupyter no genera el PDF directamente, a menos que se tengan instalados una gran cantidad de paquetes, entre ellos una instalación completa de LaTeX. En su lugar, para generar el PDF en Jupyter primero guarde el notebook como HTML y luego genere el PDF renderizando e imprimiendo el HTML con su navegador. En lugar de imprimir, seleccione guardar como PDF.
